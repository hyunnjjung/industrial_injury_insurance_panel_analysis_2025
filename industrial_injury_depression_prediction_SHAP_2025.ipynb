{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "plt.rcParams['axes.unicode_minus'] = False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbAefRQjbZkN",
        "outputId": "52424d4d-0dbb-4491-e9a3-71f73aefa089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-nanum is already the newest version (20200506-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 12 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 로드 및 import\n"
      ],
      "metadata": {
        "id": "7r43ls4ubSIn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ0fessGZOkS",
        "outputId": "8d5d4650-73e3-4448-bd61-d55a59c0680a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rrI2SWtTgjS"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel(r\"/content/drive/MyDrive/df산재/3차코호트 1차년도 산재보험패널조사_V2(공개용).xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qI-Qh9xBmsvx"
      },
      "outputs": [],
      "source": [
        "# 우울증 지수 계산 및 컬럼 제거\n",
        "columns_to_sum = ['G01029001', 'G01029002', 'G01029003', 'G01029004',\n",
        "                  'G01029005', 'G01029006', 'G01029007', 'G01029008',\n",
        "                  'G01029009']\n",
        "\n",
        "# 우울증 지수 생성\n",
        "df['우울증_지수'] = df[columns_to_sum].sum(axis=1)\n",
        "\n",
        "# 사용된 컬럼 제거\n",
        "df = df.drop(columns=columns_to_sum)\n",
        "df['우울증_지수'] = df['우울증_지수']-9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKaiI-ICmuFJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "8a5fe51f-06fc-4f43-af53-f79533a85637"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    3691.000000\n",
              "mean        3.985099\n",
              "std         5.540396\n",
              "min         0.000000\n",
              "25%         0.000000\n",
              "50%         1.000000\n",
              "75%         7.000000\n",
              "max        27.000000\n",
              "Name: 우울증_지수, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>우울증_지수</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3691.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.985099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>5.540396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>27.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "df['우울증_지수'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_vGimOQu_l_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af8233d7-543d-4789-8ffa-2456a51c3620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   연령대(6범주)  최종학력  현재 거주지 권역(7범주)  장해등급(15범주)  요양기간  경제활동유형(3 범주)  최종학교  혼인상태  \\\n",
            "0         3     4               1           1     5             3     4     1   \n",
            "1         3     4               2           3     6             3     6     1   \n",
            "2         3     5               5           1     6             1     5     2   \n",
            "3         3     4               5           1     6             3     4     4   \n",
            "4         3     5               5           3     6             3     6     2   \n",
            "\n",
            "   자격증 보유 개수  최초 의료기관 방문시점  ...  산재로 인한 통증이 일상 및 삶을 방해하는 정도  현재 전반적인 건강상태  \\\n",
            "0        NaN             1  ...                           4             4   \n",
            "1        NaN             1  ...                           3             5   \n",
            "2        NaN             1  ...                           4             4   \n",
            "3        NaN             1  ...                           4             5   \n",
            "4        1.0             1  ...                           3             5   \n",
            "\n",
            "   일상생활 도움 주는 사람 유무  산재 이후 일상생활에서 가족이나 타인의 도움 필요 정도  흡연 여부  1주 평균 운동일 수  \\\n",
            "0                 1                               4      1            0   \n",
            "1                 2                               4      2            0   \n",
            "2                 1                               3      1            5   \n",
            "3                 1                               4      2            0   \n",
            "4                 1                               4      2            2   \n",
            "\n",
            "   음주 여부  2022년 개인 근로소득 발생 여부  가구원 수  우울증_지수  \n",
            "0      2                    2      1      27  \n",
            "1      2                    2      1      16  \n",
            "2      1                    1      2      11  \n",
            "3      2                    2      2      17  \n",
            "4      2                    2      4      15  \n",
            "\n",
            "[5 rows x 36 columns]\n"
          ]
        }
      ],
      "source": [
        "column_mapping = {\n",
        "    \"age016\": \"연령대(6범주)\",\n",
        "    \"edu01\": \"최종학력\",\n",
        "    \"area017\": \"현재 거주지 권역(7범주)\",\n",
        "    \"disa0115\": \"장해등급(15범주)\",\n",
        "    \"con6\": \"요양기간\",\n",
        "    \"emp013\": \"경제활동유형(3 범주)\",\n",
        "    \"A01001001\": \"최종학교\",\n",
        "    \"A01002002\": \"혼인상태\",\n",
        "    \"A01005002\": \"자격증 보유 개수\",\n",
        "    \"B01002001\": \"최초 의료기관 방문시점\",\n",
        "    \"B01010001\": \"치료기간 적정 여부\",\n",
        "    \"B01011001\": \"비급여 금액 발생 여부 및 부담 방법\",\n",
        "    \"B01018017\": \"지원여부 (5) 위로금\",\n",
        "    \"B01024001\": \"산업재해 발생 이후 교육훈련 경험 유무\",\n",
        "    \"B01026001\": \"현재 업무수행능력\",\n",
        "    \"C01005001\": \"종사상 지위\",\n",
        "    \"C01015001\": \"제공여부-법정퇴직금\",\n",
        "    \"C01026001\": \"한 달 평균 임금/소득\",\n",
        "    \"C01028001\": \"한 달 평균 근무일수\",\n",
        "    \"C01028002\": \"하루 평균 근무시간\",\n",
        "    \"C01036001\": \"직장 동료들과의 관계\",\n",
        "    \"C01037001\": \"직장동료 도움지지여부\",\n",
        "    \"C01037002\": \"직장상사 도움지지여부\",\n",
        "    \"C01038001\": \"일자리 만족도\",\n",
        "    \"G01001001\": \"산재 이후 건강회복 정도\",\n",
        "    \"G01002001\": \"산재 이후 통증 느끼는 횟수\",\n",
        "    \"G01003001\": \"산재로 인한 통증이 일상 및 삶을 방해하는 정도\",\n",
        "    \"G01005001\": \"현재 전반적인 건강상태\",\n",
        "    \"G01013001\": \"일상생활 도움 주는 사람 유무\",\n",
        "    \"G01012001\": \"산재 이후 일상생활에서 가족이나 타인의 도움 필요 정도\",\n",
        "    \"G01018001\": \"흡연 여부\",\n",
        "    \"G01016001\": \"1주 평균 운동일 수\",\n",
        "    \"G01019001\": \"음주 여부\",\n",
        "    \"H01001001\": \"2022년 개인 근로소득 발생 여부\",\n",
        "    \"I01001001\": \"가구원 수\"\n",
        "}\n",
        "\n",
        "selected_columns = list(column_mapping.keys()) + ['우울증_지수']\n",
        "# 선택한 컬럼만 추출 및 이름 변경 (우울증_지수는 이름 변경하지 않음)\n",
        "df_selected = df[selected_columns].rename(columns={key: column_mapping[key] for key in column_mapping if key in df.columns})\n",
        "\n",
        "# 결과 확인\n",
        "print(df_selected.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZ_-vvnYavDJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c816026a-4232-4849-e00d-4f8b9ff45732"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "연령대(6범주)                             0\n",
              "최종학력                                 0\n",
              "현재 거주지 권역(7범주)                       0\n",
              "장해등급(15범주)                           0\n",
              "요양기간                                 0\n",
              "경제활동유형(3 범주)                         0\n",
              "최종학교                                 0\n",
              "혼인상태                                 0\n",
              "자격증 보유 개수                         2399\n",
              "최초 의료기관 방문시점                         0\n",
              "치료기간 적정 여부                           0\n",
              "비급여 금액 발생 여부 및 부담 방법                 0\n",
              "지원여부 (5) 위로금                         0\n",
              "산업재해 발생 이후 교육훈련 경험 유무                0\n",
              "현재 업무수행능력                            0\n",
              "종사상 지위                               0\n",
              "제공여부-법정퇴직금                          65\n",
              "한 달 평균 임금/소득                         0\n",
              "한 달 평균 근무일수                          0\n",
              "하루 평균 근무시간                           0\n",
              "직장 동료들과의 관계                         54\n",
              "직장동료 도움지지여부                         54\n",
              "직장상사 도움지지여부                         65\n",
              "일자리 만족도                              0\n",
              "산재 이후 건강회복 정도                        0\n",
              "산재 이후 통증 느끼는 횟수                      0\n",
              "산재로 인한 통증이 일상 및 삶을 방해하는 정도           0\n",
              "현재 전반적인 건강상태                         0\n",
              "일상생활 도움 주는 사람 유무                     0\n",
              "산재 이후 일상생활에서 가족이나 타인의 도움 필요 정도       0\n",
              "흡연 여부                                0\n",
              "1주 평균 운동일 수                          0\n",
              "음주 여부                                0\n",
              "2022년 개인 근로소득 발생 여부                  0\n",
              "가구원 수                                0\n",
              "우울증_지수                               0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>연령대(6범주)</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>최종학력</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>현재 거주지 권역(7범주)</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>장해등급(15범주)</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>요양기간</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>경제활동유형(3 범주)</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>최종학교</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>혼인상태</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>자격증 보유 개수</th>\n",
              "      <td>2399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>최초 의료기관 방문시점</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>치료기간 적정 여부</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>비급여 금액 발생 여부 및 부담 방법</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>지원여부 (5) 위로금</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>산업재해 발생 이후 교육훈련 경험 유무</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>현재 업무수행능력</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>종사상 지위</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>제공여부-법정퇴직금</th>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>한 달 평균 임금/소득</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>한 달 평균 근무일수</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>하루 평균 근무시간</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>직장 동료들과의 관계</th>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>직장동료 도움지지여부</th>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>직장상사 도움지지여부</th>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>일자리 만족도</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>산재 이후 건강회복 정도</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>산재 이후 통증 느끼는 횟수</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>산재로 인한 통증이 일상 및 삶을 방해하는 정도</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>현재 전반적인 건강상태</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>일상생활 도움 주는 사람 유무</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>산재 이후 일상생활에서 가족이나 타인의 도움 필요 정도</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>흡연 여부</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1주 평균 운동일 수</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>음주 여부</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022년 개인 근로소득 발생 여부</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>가구원 수</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>우울증_지수</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "df_selected.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jE-JbEibyYd"
      },
      "outputs": [],
      "source": [
        "df_combined  = df_selected.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cb1skC8IbtR1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d19c748-a682-43b9-9a49-bf53770517f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "연령대(6범주)                          0\n",
            "최종학력                              0\n",
            "현재 거주지 권역(7범주)                    0\n",
            "장해등급(15범주)                        0\n",
            "요양기간                              0\n",
            "경제활동유형(3 범주)                      0\n",
            "최종학교                              0\n",
            "혼인상태                              0\n",
            "자격증 보유 개수                         0\n",
            "최초 의료기관 방문시점                      0\n",
            "치료기간 적정 여부                        0\n",
            "비급여 금액 발생 여부 및 부담 방법              0\n",
            "지원여부 (5) 위로금                      0\n",
            "산업재해 발생 이후 교육훈련 경험 유무             0\n",
            "현재 업무수행능력                         0\n",
            "종사상 지위                            0\n",
            "제공여부-법정퇴직금                        0\n",
            "한 달 평균 임금/소득                      0\n",
            "한 달 평균 근무일수                       0\n",
            "하루 평균 근무시간                        0\n",
            "직장 동료들과의 관계                       0\n",
            "직장동료 도움지지여부                       0\n",
            "직장상사 도움지지여부                       0\n",
            "일자리 만족도                           0\n",
            "산재 이후 건강회복 정도                     0\n",
            "산재 이후 통증 느끼는 횟수                   0\n",
            "산재로 인한 통증이 일상 및 삶을 방해하는 정도        0\n",
            "현재 전반적인 건강상태                      0\n",
            "일상생활 도움 주는 사람 유무                  0\n",
            "산재 이후 일상생활에서 가족이나 타인의 도움 필요 정도    0\n",
            "흡연 여부                             0\n",
            "1주 평균 운동일 수                       0\n",
            "음주 여부                             0\n",
            "2022년 개인 근로소득 발생 여부               0\n",
            "가구원 수                             0\n",
            "우울증_지수                            0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# 1. '자격증 보유 개수' 널값은 0으로 채우기\n",
        "df_combined['자격증 보유 개수'] = df_combined['자격증 보유 개수'].fillna(0)\n",
        "\n",
        "# 2. '제공여부-법정퇴직금' 널값은 2로 채우기\n",
        "df_combined['제공여부-법정퇴직금'] = df_combined['제공여부-법정퇴직금'].fillna(2)\n",
        "\n",
        "# 3. '직장 동료들과의 관계' 널값은 최빈값으로 채우기\n",
        "if df_combined['직장 동료들과의 관계'].isnull().any():\n",
        "    most_frequent_value = df_combined['직장 동료들과의 관계'].mode()[0]\n",
        "    df_combined['직장 동료들과의 관계'] = df_combined['직장 동료들과의 관계'].fillna(most_frequent_value)\n",
        "\n",
        "# 4. '직장동료 도움지지여부' 널값은 최빈값으로 채우기\n",
        "if df_combined['직장동료 도움지지여부'].isnull().any():\n",
        "    most_frequent_value = df_combined['직장동료 도움지지여부'].mode()[0]\n",
        "    df_combined['직장동료 도움지지여부'] = df_combined['직장동료 도움지지여부'].fillna(most_frequent_value)\n",
        "\n",
        "# 5. '직장상사 도움지지여부' 널값은 최빈값으로 채우기\n",
        "if df_combined['직장상사 도움지지여부'].isnull().any():\n",
        "    most_frequent_value = df_combined['직장상사 도움지지여부'].mode()[0]\n",
        "    df_combined['직장상사 도움지지여부'] = df_combined['직장상사 도움지지여부'].fillna(most_frequent_value)\n",
        "\n",
        "# 결과 확인\n",
        "print(df_combined.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcpIkBzaeVbu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "outputId": "83782f62-bed0-4268-bd47-6c89b16fafe1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df_combined['우울증_지수'], bins=20, edgecolor='black', alpha=0.7)\n",
        "plt.title('melancholia', fontsize=16)\n",
        "plt.xlabel('melancholia', fontsize=14)\n",
        "plt.ylabel('y', fontsize=14)\n",
        "plt.grid(axis='y', alpha=0.75)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lx3IoUR_gFK7"
      },
      "outputs": [],
      "source": [
        "df= df_combined.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFzTZU9Bgci-"
      },
      "outputs": [],
      "source": [
        "# 1, 2는 1로, 3, 4, 5, 6, 7은 2로 변환\n",
        "df['현재 거주지 권역(7범주)'] = df['현재 거주지 권역(7범주)'].apply(lambda x: 1 if x in [1, 2] else 2)\n",
        "\n",
        "# 원핫인코딩 적용\n",
        "df = pd.get_dummies(df, columns=['현재 거주지 권역(7범주)'], prefix='거주지')\n",
        "# 경제활동유형(3범주)을 원핫인코딩\n",
        "df = pd.get_dummies(df, columns=['경제활동유형(3 범주)'], prefix='경제활동')\n",
        "# 혼인 상태 컬럼을 원핫인코딩하는 코드\n",
        "df = pd.get_dummies(df, columns=['혼인상태'], prefix='혼인상태')\n",
        "# '비급여 금액 발생 여부 및 부담 방법' 컬럼에서 1을 제외한 모든 값을 2로 변환\n",
        "df['비급여 금액 발생 여부 및 부담 방법'] = df['비급여 금액 발생 여부 및 부담 방법'].apply(lambda x: 1 if x == 1 else 2)\n",
        "\n",
        "# 원핫인코딩 적용\n",
        "df = pd.get_dummies(df, columns=['비급여 금액 발생 여부 및 부담 방법'], prefix='비급여')\n",
        "# '지원여부 (5) 위로금' 컬럼을 원핫인코딩\n",
        "df = pd.get_dummies(df, columns=['지원여부 (5) 위로금'], prefix='위로금')\n",
        "# 교육훈련\n",
        "df = pd.get_dummies(df, columns=['산업재해 발생 이후 교육훈련 경험 유무'], prefix='이후_교육훈련')\n",
        "# '종사상 지위' 컬럼에서 4와 5를 4로 통일\n",
        "df['종사상 지위'] = df['종사상 지위'].replace({5: 4})\n",
        "\n",
        "# 원핫인코딩 적용\n",
        "df = pd.get_dummies(df, columns=['종사상 지위'], prefix='종사상지위')\n",
        "# 퇴직금\n",
        "df = pd.get_dummies(df, columns=['제공여부-법정퇴직금'], prefix='법정퇴직금_지급')\n",
        "#도움\n",
        "df = pd.get_dummies(df, columns=['일상생활 도움 주는 사람 유무'], prefix='도움주는사람_여부')\n",
        "# '흡연 여부', '음주 여부', '2022년 개인 근로소득 발생 여부' 컬럼을 원핫인코딩\n",
        "df = pd.get_dummies(df, columns=['흡연 여부', '음주 여부', '2022년 개인 근로소득 발생 여부'],\n",
        "                           prefix=['흡연', '음주', '근로소득발생'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0HiFyiyn7Bq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "424cc936-a40b-49eb-8a11-cf5c3ba66940"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['연령대(6범주)', '최종학력', '장해등급(15범주)', '요양기간', '최종학교', '자격증 보유 개수',\n",
              "       '최초 의료기관 방문시점', '치료기간 적정 여부', '현재 업무수행능력', '한 달 평균 임금/소득',\n",
              "       '한 달 평균 근무일수', '하루 평균 근무시간', '직장 동료들과의 관계', '직장동료 도움지지여부',\n",
              "       '직장상사 도움지지여부', '일자리 만족도', '산재 이후 건강회복 정도', '산재 이후 통증 느끼는 횟수',\n",
              "       '산재로 인한 통증이 일상 및 삶을 방해하는 정도', '현재 전반적인 건강상태',\n",
              "       '산재 이후 일상생활에서 가족이나 타인의 도움 필요 정도', '1주 평균 운동일 수', '가구원 수', '우울증_지수',\n",
              "       '거주지_1', '거주지_2', '경제활동_1', '경제활동_2', '경제활동_3', '혼인상태_1', '혼인상태_2',\n",
              "       '혼인상태_3', '혼인상태_4', '혼인상태_5', '비급여_1', '비급여_2', '위로금_1', '위로금_2',\n",
              "       '이후_교육훈련_1', '이후_교육훈련_2', '종사상지위_1', '종사상지위_2', '종사상지위_3', '종사상지위_4',\n",
              "       '법정퇴직금_지급_1.0', '법정퇴직금_지급_2.0', '법정퇴직금_지급_3.0', '도움주는사람_여부_1',\n",
              "       '도움주는사람_여부_2', '흡연_1', '흡연_2', '음주_1', '음주_2', '근로소득발생_1', '근로소득발생_2'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrMM4uFZpgoK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85ad29cc-f45b-41ae-fdb0-33a741d80c6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      연령대(6범주)  최종학력  장해등급(15범주)  요양기간  최종학교  자격증 보유 개수  최초 의료기관 방문시점  \\\n",
            "0            3     4           1     5     4          0             1   \n",
            "1            3     4           3     6     6          0             1   \n",
            "2            3     5           1     6     5          0             1   \n",
            "3            3     4           1     6     4          0             1   \n",
            "4            3     5           3     6     6          1             1   \n",
            "...        ...   ...         ...   ...   ...        ...           ...   \n",
            "3686         6     4          15     3     4          1             1   \n",
            "3687         5     2          15     2     2          0             1   \n",
            "3688         5     4          15     4     4          2             1   \n",
            "3689         5     4          15     3     4          0             3   \n",
            "3690         6     2          15     1     2          0             1   \n",
            "\n",
            "      치료기간 적정 여부  현재 업무수행능력  한 달 평균 임금/소득  ...  법정퇴직금_지급_3.0  도움주는사람_여부_2  \\\n",
            "0              5          0           450  ...             1            0   \n",
            "1              3          0           360  ...             0            1   \n",
            "2              2          1           200  ...             1            0   \n",
            "3              1          0           270  ...             0            0   \n",
            "4              3          2           100  ...             0            0   \n",
            "...          ...        ...           ...  ...           ...          ...   \n",
            "3686           3          3           280  ...             0            1   \n",
            "3687           2          4           200  ...             0            1   \n",
            "3688           1          1           320  ...             0            1   \n",
            "3689           1          6           180  ...             0            1   \n",
            "3690           3          8            27  ...             0            1   \n",
            "\n",
            "      흡연_1  흡연_2  음주_1  음주_2  근로소득발생_1  근로소득발생_2  도움주는사람_여부_1_False  \\\n",
            "0        1     0     0     1         0         1                  0   \n",
            "1        0     1     0     1         0         1                  1   \n",
            "2        1     0     1     0         1         0                  0   \n",
            "3        0     1     0     1         0         1                  0   \n",
            "4        0     1     0     1         0         1                  0   \n",
            "...    ...   ...   ...   ...       ...       ...                ...   \n",
            "3686     0     1     0     1         1         0                  1   \n",
            "3687     1     0     0     1         0         1                  1   \n",
            "3688     1     0     1     0         0         1                  1   \n",
            "3689     0     1     0     1         0         1                  1   \n",
            "3690     0     1     0     1         1         0                  1   \n",
            "\n",
            "      도움주는사람_여부_1_True  \n",
            "0                    1  \n",
            "1                    0  \n",
            "2                    1  \n",
            "3                    1  \n",
            "4                    1  \n",
            "...                ...  \n",
            "3686                 0  \n",
            "3687                 0  \n",
            "3688                 0  \n",
            "3689                 0  \n",
            "3690                 0  \n",
            "\n",
            "[3691 rows x 56 columns]\n"
          ]
        }
      ],
      "source": [
        "df_encoded = pd.get_dummies(df, columns=['도움주는사람_여부_1'])\n",
        "\n",
        "# True/False를 0/1로 변환\n",
        "df_encoded = df_encoded.astype(int)\n",
        "\n",
        "print(df_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrWgtlSAoVA2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "c4742df2-fa50-488d-8c25-2aa03225fb18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   연령대(6범주)  최종학력  장해등급(15범주)  요양기간  최종학교  자격증 보유 개수  최초 의료기관 방문시점  \\\n",
              "0         3     4           1     5     4          0             1   \n",
              "1         3     4           3     6     6          0             1   \n",
              "2         3     5           1     6     5          0             1   \n",
              "3         3     4           1     6     4          0             1   \n",
              "4         3     5           3     6     6          1             1   \n",
              "\n",
              "   치료기간 적정 여부  현재 업무수행능력  한 달 평균 임금/소득  ...  법정퇴직금_지급_3.0  도움주는사람_여부_2  흡연_1  \\\n",
              "0           5          0           450  ...             1            0     1   \n",
              "1           3          0           360  ...             0            1     0   \n",
              "2           2          1           200  ...             1            0     1   \n",
              "3           1          0           270  ...             0            0     0   \n",
              "4           3          2           100  ...             0            0     0   \n",
              "\n",
              "   흡연_2  음주_1  음주_2  근로소득발생_1  근로소득발생_2  도움주는사람_여부_1_False  도움주는사람_여부_1_True  \n",
              "0     0     0     1         0         1                  0                 1  \n",
              "1     1     0     1         0         1                  1                 0  \n",
              "2     0     1     0         1         0                  0                 1  \n",
              "3     1     0     1         0         1                  0                 1  \n",
              "4     1     0     1         0         1                  0                 1  \n",
              "\n",
              "[5 rows x 56 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af1dbb25-ee6d-46f5-ab8c-dc19d2d5878d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>연령대(6범주)</th>\n",
              "      <th>최종학력</th>\n",
              "      <th>장해등급(15범주)</th>\n",
              "      <th>요양기간</th>\n",
              "      <th>최종학교</th>\n",
              "      <th>자격증 보유 개수</th>\n",
              "      <th>최초 의료기관 방문시점</th>\n",
              "      <th>치료기간 적정 여부</th>\n",
              "      <th>현재 업무수행능력</th>\n",
              "      <th>한 달 평균 임금/소득</th>\n",
              "      <th>...</th>\n",
              "      <th>법정퇴직금_지급_3.0</th>\n",
              "      <th>도움주는사람_여부_2</th>\n",
              "      <th>흡연_1</th>\n",
              "      <th>흡연_2</th>\n",
              "      <th>음주_1</th>\n",
              "      <th>음주_2</th>\n",
              "      <th>근로소득발생_1</th>\n",
              "      <th>근로소득발생_2</th>\n",
              "      <th>도움주는사람_여부_1_False</th>\n",
              "      <th>도움주는사람_여부_1_True</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>450</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>360</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>200</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>270</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 56 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af1dbb25-ee6d-46f5-ab8c-dc19d2d5878d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-af1dbb25-ee6d-46f5-ab8c-dc19d2d5878d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-af1dbb25-ee6d-46f5-ab8c-dc19d2d5878d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cc17bd45-1cb0-454c-9770-8bcb49f2e2d3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cc17bd45-1cb0-454c-9770-8bcb49f2e2d3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cc17bd45-1cb0-454c-9770-8bcb49f2e2d3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_encoded"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "df_encoded.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcMrDnjip_6X"
      },
      "outputs": [],
      "source": [
        "df_encoded = df_encoded.drop(columns= '도움주는사람_여부_1_False')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gVnb5gbqIoH"
      },
      "outputs": [],
      "source": [
        "df = df_encoded.rename(columns={\n",
        "    '도움주는사람_여부_1_True': '도움주는사람_여부_1',\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##기본"
      ],
      "metadata": {
        "id": "01RF6u_KvTVY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgzChP54tqv9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad78dd0a-88f9-41d3-c365-7b9cffacefa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1:\n",
            "Final Loss for Fold 1: 16.9961\n",
            "Fold 1 Test MAE: 3.3805\n",
            "\n",
            "Fold 2:\n",
            "Final Loss for Fold 2: 16.2782\n",
            "Fold 2 Test MAE: 3.3915\n",
            "\n",
            "Fold 3:\n",
            "Final Loss for Fold 3: 17.3400\n",
            "Fold 3 Test MAE: 3.3534\n",
            "\n",
            "Average MAE across folds: 3.3752\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# 데이터 준비\n",
        "target = '우울증_지수'\n",
        "\n",
        "# 타겟 변수 제외한 나머지를 입력 변수로 설정\n",
        "features = [col for col in df.columns if col != target]\n",
        "\n",
        "X = df[features].values  # 입력 변수\n",
        "y = df[target].values.reshape(-1, 1)  # 타겟 변수 (2D 배열로 변환)\n",
        "\n",
        "# K-Fold 설정\n",
        "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# MLP 모델 정의\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# 교차검증 루프\n",
        "fold = 1\n",
        "fold_mae_scores = []\n",
        "\n",
        "for train_idx, test_idx in kf.split(X, y):\n",
        "    print(f\"\\nFold {fold}:\")\n",
        "\n",
        "    # 데이터 분할\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    # NumPy 데이터를 PyTorch 텐서로 변환\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "    y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "    # 모델 초기화\n",
        "    input_dim = X_train.shape[1]\n",
        "    model = MLP(input_dim)\n",
        "\n",
        "    # 2️⃣ **손실 함수 및 옵티마이저**\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # 학습 루프\n",
        "    num_epochs = 200\n",
        "    batch_size = 16\n",
        "\n",
        "    # DataLoader를 사용한 배치 학습\n",
        "    train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # 학습 모드\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    print(f\"Final Loss for Fold {fold}: {epoch_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    # 평가\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        y_pred = model(X_test).numpy()\n",
        "        y_pred_original = y_pred\n",
        "        y_test_original = y_test.numpy()\n",
        "\n",
        "        # MAE 계산\n",
        "        mae = mean_absolute_error(y_test_original, y_pred_original)\n",
        "        print(f\"Fold {fold} Test MAE: {mae:.4f}\")\n",
        "        fold_mae_scores.append(mae)\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# 전체 Fold 결과\n",
        "print(f\"\\nAverage MAE across folds: {np.mean(fold_mae_scores):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_tabnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eh9QJK4nQO0F",
        "outputId": "662c0b1f-d24f-4cc9-ca40-c6274dd3d471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch_tabnet in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from pytorch_tabnet) (1.26.4)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.11/dist-packages (from pytorch_tabnet) (1.6.1)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.11/dist-packages (from pytorch_tabnet) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.11/dist-packages (from pytorch_tabnet) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.11/dist-packages (from pytorch_tabnet) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.3->pytorch_tabnet) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.3->pytorch_tabnet) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyqE3Sb6waw3",
        "outputId": "cf2d624d-0071-4d58-fee5-bdcb22a9bf35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.2.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.38)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.9)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import optuna\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 랜덤 시드 설정\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "\n",
        "# 데이터 준비\n",
        "target = '우울증_지수'\n",
        "features = [col for col in df.columns if col != target]\n",
        "\n",
        "X = df[features].values\n",
        "y = df[target].values.reshape(-1, 1)\n",
        "\n",
        "# 데이터 정규화\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "kf = KFold(n_splits=3, shuffle=True, random_state=seed)\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=50),\n",
        "        'objective': 'reg:squarederror',\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
        "        'lambda': trial.suggest_float('lambda', 1e-3, 10, log=True),\n",
        "        'alpha': trial.suggest_float('alpha', 1e-3, 10, log=True),\n",
        "        'eval_metric': 'mae'\n",
        "    }\n",
        "\n",
        "    fold_mae_scores = []\n",
        "    fold = 1  # Fold 카운트\n",
        "\n",
        "    for train_idx, test_idx in kf.split(X, y):\n",
        "        print(f\"\\nFold {fold}:\")  # ✅ PyTorch 코드처럼 Fold별 로그 출력\n",
        "\n",
        "        X_train, X_test = X[train_idx], X[test_idx]\n",
        "        y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "        D_train = xgb.DMatrix(X_train, label=y_train)\n",
        "        D_valid = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "        # ✅ `xgb.train()`을 사용하여 Optuna의 하이퍼파라미터 튜닝 적용\n",
        "        model = xgb.train(\n",
        "            params=params,\n",
        "            dtrain=D_train,\n",
        "            num_boost_round=500,\n",
        "            evals=[(D_valid, \"Valid\")],\n",
        "            early_stopping_rounds=20,\n",
        "            verbose_eval=False\n",
        "        )\n",
        "\n",
        "        # 예측 및 MAE 계산\n",
        "        y_pred = model.predict(D_valid)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "        print(f\"Fold {fold} Test MAE: {mae:.4f}\")  # ✅ PyTorch 코드처럼 Fold별 MAE 출력\n",
        "        fold_mae_scores.append(mae)\n",
        "\n",
        "        fold += 1  # Fold 증가\n",
        "\n",
        "    return np.mean(fold_mae_scores)\n",
        "\n",
        "# Optuna 실행\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# 최적 하이퍼파라미터 출력\n",
        "print(\"Best Hyperparameters:\", study.best_params)\n",
        "\n",
        "# ✅ 최적 하이퍼파라미터로 최종 학습 및 평가\n",
        "best_params = study.best_params\n",
        "fold_mae_scores = []\n",
        "fold = 1\n",
        "\n",
        "for train_idx, test_idx in kf.split(X, y):\n",
        "    print(f\"\\nFold {fold}:\")\n",
        "\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    D_train = xgb.DMatrix(X_train, label=y_train)\n",
        "    D_valid = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "    model = xgb.train(\n",
        "        params=best_params,\n",
        "        dtrain=D_train,\n",
        "        num_boost_round=500,\n",
        "        evals=[(D_valid, \"Valid\")],\n",
        "        early_stopping_rounds=20,\n",
        "        verbose_eval=False\n",
        "    )\n",
        "\n",
        "    # 예측 및 MAE 계산\n",
        "    y_pred = model.predict(D_valid)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "    print(f\"Fold {fold} Test MAE: {mae:.4f}\")  # ✅ Fold별 MAE 출력\n",
        "    fold_mae_scores.append(mae)\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# ✅ 최종 MAE 출력 (PyTorch 코드와 동일하게)\n",
        "print(f\"\\nAverage MAE across folds: {np.mean(fold_mae_scores):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkTYrPfSK8Kv",
        "outputId": "29f33d6a-8b28-419f-e352-d594b153ce33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:00:02,754] A new study created in memory with name: no-name-85eb19df-b023-4391-a5ca-d160553ecb01\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.3685\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:03,056] Trial 0 finished with value: 3.353869835535685 and parameters: {'n_estimators': 1000, 'learning_rate': 0.08397242505149571, 'max_depth': 7, 'subsample': 0.9745890013287872, 'colsample_bytree': 0.7338373732559353, 'gamma': 0.20865232432121184, 'lambda': 0.010834686202323937, 'alpha': 0.20871373958011635}. Best is trial 0 with value: 3.353869835535685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3773\n",
            "\n",
            "Fold 3:\n",
            "Fold 3 Test MAE: 3.3158\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.3560\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3462\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:04,330] Trial 1 finished with value: 3.35711677869161 and parameters: {'n_estimators': 200, 'learning_rate': 0.020007786388833375, 'max_depth': 9, 'subsample': 0.8467669021473165, 'colsample_bytree': 0.9782905320921577, 'gamma': 0.6161916562113923, 'lambda': 0.005447772276474931, 'alpha': 0.07193425456857974}. Best is trial 0 with value: 3.353869835535685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3691\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:04] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.6470\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:04] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.6402\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:04] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:05,243] Trial 2 finished with value: 3.631665070851644 and parameters: {'n_estimators': 250, 'learning_rate': 0.0022513438351515827, 'max_depth': 3, 'subsample': 0.7159256181739151, 'colsample_bytree': 0.6204309622562526, 'gamma': 4.430482157170747, 'lambda': 0.03299736844343092, 'alpha': 0.006102315389207127}. Best is trial 0 with value: 3.353869835535685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.6078\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.3120\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:05] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:05] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:05] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:05,796] Trial 3 finished with value: 3.3210906982421875 and parameters: {'n_estimators': 500, 'learning_rate': 0.027262748609461956, 'max_depth': 3, 'subsample': 0.8797398810607688, 'colsample_bytree': 0.7106204713448113, 'gamma': 3.9984062832596217, 'lambda': 1.1841245561581244, 'alpha': 0.2782132839516796}. Best is trial 3 with value: 3.3210906982421875.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3220\n",
            "\n",
            "Fold 3:\n",
            "Fold 3 Test MAE: 3.3293\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:05] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:05] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.3948\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.3989\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:06,192] Trial 4 finished with value: 3.385537624359131 and parameters: {'n_estimators': 300, 'learning_rate': 0.07910462485297585, 'max_depth': 10, 'subsample': 0.9355834577977876, 'colsample_bytree': 0.9909424960246622, 'gamma': 4.032656128755892, 'lambda': 1.1953741460021758, 'alpha': 0.05138653445072268}. Best is trial 3 with value: 3.3210906982421875.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3629\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.2952\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3044\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:07,116] Trial 5 finished with value: 3.299158732096354 and parameters: {'n_estimators': 850, 'learning_rate': 0.013168934103630028, 'max_depth': 4, 'subsample': 0.6077495579111851, 'colsample_bytree': 0.735015731944456, 'gamma': 4.617354456543461, 'lambda': 0.002731144458631616, 'alpha': 2.883348200112655}. Best is trial 5 with value: 3.299158732096354.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.2979\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:07] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.3343\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3655\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:09,886] Trial 6 finished with value: 3.3341403802235923 and parameters: {'n_estimators': 750, 'learning_rate': 0.00496709628524993, 'max_depth': 9, 'subsample': 0.909416814050209, 'colsample_bytree': 0.6423314308796024, 'gamma': 0.8982463636922783, 'lambda': 6.756910075391064, 'alpha': 0.0028059373763119214}. Best is trial 5 with value: 3.299158732096354.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3026\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.3665\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3770\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:10,542] Trial 7 finished with value: 3.363058169682821 and parameters: {'n_estimators': 100, 'learning_rate': 0.04532754357474614, 'max_depth': 10, 'subsample': 0.940786056182898, 'colsample_bytree': 0.9668780611112, 'gamma': 3.4915923965637385, 'lambda': 0.4986374313799726, 'alpha': 1.9676106913551048}. Best is trial 5 with value: 3.299158732096354.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3457\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.2868\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.3417\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:10,794] Trial 8 finished with value: 3.3241360187530518 and parameters: {'n_estimators': 700, 'learning_rate': 0.08439824977427922, 'max_depth': 4, 'subsample': 0.8361348121110135, 'colsample_bytree': 0.7281120886163763, 'gamma': 0.020628187494947103, 'lambda': 0.0016033758089662269, 'alpha': 0.010100296147762502}. Best is trial 5 with value: 3.299158732096354.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3439\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.4566\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.4681\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:12,361] Trial 9 finished with value: 3.4492650032043457 and parameters: {'n_estimators': 1000, 'learning_rate': 0.0036007081774904253, 'max_depth': 5, 'subsample': 0.961660046170876, 'colsample_bytree': 0.6131102782793041, 'gamma': 3.8415400622566227, 'lambda': 3.2010484005495217, 'alpha': 9.602678507252213}. Best is trial 5 with value: 3.299158732096354.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.4230\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.2728\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3217\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:13,905] Trial 10 finished with value: 3.302236715952555 and parameters: {'n_estimators': 800, 'learning_rate': 0.009805280906914796, 'max_depth': 6, 'subsample': 0.5410635618045969, 'colsample_bytree': 0.8545657301526788, 'gamma': 2.2789576147771844, 'lambda': 0.12629273656738907, 'alpha': 1.6575259200893182}. Best is trial 5 with value: 3.299158732096354.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3123\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.2753\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:14] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3181\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:14] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:15,379] Trial 11 finished with value: 3.300902525583903 and parameters: {'n_estimators': 800, 'learning_rate': 0.009575193668327734, 'max_depth': 6, 'subsample': 0.5424116046709359, 'colsample_bytree': 0.8546253435905372, 'gamma': 2.2743348574395927, 'lambda': 0.13413614124978054, 'alpha': 1.9151203428176873}. Best is trial 5 with value: 3.299158732096354.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3093\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:15] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.2861\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:15] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3205\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:16] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:16,715] Trial 12 finished with value: 3.297151724497477 and parameters: {'n_estimators': 550, 'learning_rate': 0.010463736945484857, 'max_depth': 7, 'subsample': 0.5284297798536771, 'colsample_bytree': 0.851802427370398, 'gamma': 2.39820097657554, 'lambda': 0.11473966569660214, 'alpha': 8.804308082584228}. Best is trial 12 with value: 3.297151724497477.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.2849\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:16] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.2981\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:16] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3309\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:17] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:17,525] Trial 13 finished with value: 3.304401159286499 and parameters: {'n_estimators': 500, 'learning_rate': 0.018379102275741202, 'max_depth': 7, 'subsample': 0.616320036411609, 'colsample_bytree': 0.8407956636923937, 'gamma': 3.13106373978854, 'lambda': 0.001115216430474797, 'alpha': 9.57784627859857}. Best is trial 12 with value: 3.297151724497477.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.2842\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:17] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.8241\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:18] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.8065\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:18] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:19,357] Trial 14 finished with value: 3.7965572675069175 and parameters: {'n_estimators': 600, 'learning_rate': 0.001024586678569403, 'max_depth': 8, 'subsample': 0.645046483164159, 'colsample_bytree': 0.8048283683296695, 'gamma': 1.5010485479939093, 'lambda': 0.02469535844428962, 'alpha': 0.7646483283694641}. Best is trial 12 with value: 3.297151724497477.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.7591\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:19] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.3355\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:19] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3488\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:20] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:20,423] Trial 15 finished with value: 3.3394468625386557 and parameters: {'n_estimators': 400, 'learning_rate': 0.006066177207076865, 'max_depth': 5, 'subsample': 0.5016142800900413, 'colsample_bytree': 0.537679272003718, 'gamma': 2.8294962610669545, 'lambda': 0.0739683076618397, 'alpha': 4.972922073668163}. Best is trial 12 with value: 3.297151724497477.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3340\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:20] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.2983\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:20] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3058\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:20] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:21,198] Trial 16 finished with value: 3.303548494974772 and parameters: {'n_estimators': 900, 'learning_rate': 0.015267081496387147, 'max_depth': 5, 'subsample': 0.6329114249475806, 'colsample_bytree': 0.9111637440187506, 'gamma': 4.67603329851058, 'lambda': 0.004657564030980601, 'alpha': 0.5176425256311367}. Best is trial 12 with value: 3.297151724497477.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3066\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.3013\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:21] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:21] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:21] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:21,627] Trial 17 finished with value: 3.301306883494059 and parameters: {'n_estimators': 600, 'learning_rate': 0.03370682636438383, 'max_depth': 4, 'subsample': 0.7256325292803425, 'colsample_bytree': 0.781256173685493, 'gamma': 1.616622955879788, 'lambda': 0.42331962984375215, 'alpha': 3.5573613552459418}. Best is trial 12 with value: 3.297151724497477.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.2966\n",
            "\n",
            "Fold 3:\n",
            "Fold 3 Test MAE: 3.3060\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:21] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.5058\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:22] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.5254\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:22] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:23,499] Trial 18 finished with value: 3.5099085172017417 and parameters: {'n_estimators': 400, 'learning_rate': 0.00253055037845439, 'max_depth': 8, 'subsample': 0.5777691472485081, 'colsample_bytree': 0.682904379022846, 'gamma': 1.6396861085307521, 'lambda': 0.02618782076754805, 'alpha': 0.03036459786705991}. Best is trial 12 with value: 3.297151724497477.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.4985\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:23] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.3353\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:23] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3443\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:24] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:24,414] Trial 19 finished with value: 3.341242710749308 and parameters: {'n_estimators': 650, 'learning_rate': 0.0074889849531647795, 'max_depth': 4, 'subsample': 0.6647008308810141, 'colsample_bytree': 0.5011105979019228, 'gamma': 4.87018898988663, 'lambda': 0.0033226658678002885, 'alpha': 0.7117784439320355}. Best is trial 12 with value: 3.297151724497477.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3441\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.3053\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:24] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:24] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:24] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:24,812] Trial 20 finished with value: 3.319600820541382 and parameters: {'n_estimators': 850, 'learning_rate': 0.0410552928466495, 'max_depth': 6, 'subsample': 0.7772352882826566, 'colsample_bytree': 0.9110769506406994, 'gamma': 2.683852323980081, 'lambda': 0.2586796505735279, 'alpha': 4.062829662801354}. Best is trial 12 with value: 3.297151724497477.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3316\n",
            "\n",
            "Fold 3:\n",
            "Fold 3 Test MAE: 3.3219\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:24] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.2782\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3236\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:25,955] Trial 21 finished with value: 3.297328551610311 and parameters: {'n_estimators': 900, 'learning_rate': 0.012169976497929532, 'max_depth': 6, 'subsample': 0.5569634977820416, 'colsample_bytree': 0.8754059607014277, 'gamma': 2.221893138115988, 'lambda': 0.08477696454141063, 'alpha': 1.4076598422125857}. Best is trial 12 with value: 3.297151724497477.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.2901\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.3075\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:26] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3261\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:26] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:27,023] Trial 22 finished with value: 3.3227345943450928 and parameters: {'n_estimators': 900, 'learning_rate': 0.013631027485152984, 'max_depth': 7, 'subsample': 0.5921130159870914, 'colsample_bytree': 0.9061912343151186, 'gamma': 2.070942433307247, 'lambda': 0.05483635079632681, 'alpha': 1.263219012155755}. Best is trial 12 with value: 3.297151724497477.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3346\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:27] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.3472\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:27] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3415\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:27] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:28,413] Trial 23 finished with value: 3.338686386744181 and parameters: {'n_estimators': 950, 'learning_rate': 0.011252089901316032, 'max_depth': 8, 'subsample': 0.5044987980103096, 'colsample_bytree': 0.7911562528646807, 'gamma': 3.169041048816002, 'lambda': 0.01218252130266289, 'alpha': 0.20353018353159005}. Best is trial 12 with value: 3.297151724497477.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3274\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:28] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.2699\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.3035\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:28] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:28] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:29,001] Trial 24 finished with value: 3.294232447942098 and parameters: {'n_estimators': 450, 'learning_rate': 0.021381755853828385, 'max_depth': 5, 'subsample': 0.6802876691046746, 'colsample_bytree': 0.819511613101773, 'gamma': 1.8925892499734425, 'lambda': 0.013104063250784658, 'alpha': 4.507948124311501}. Best is trial 24 with value: 3.294232447942098.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3092\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.3009\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.3194\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:29,561] Trial 25 finished with value: 3.3017923831939697 and parameters: {'n_estimators': 400, 'learning_rate': 0.02287549371847967, 'max_depth': 6, 'subsample': 0.6881138392802171, 'colsample_bytree': 0.8896900962005239, 'gamma': 1.1229417656148115, 'lambda': 0.22608837966278195, 'alpha': 6.056536263092468}. Best is trial 24 with value: 3.294232447942098.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.2851\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.3179\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3487\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:30] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:30,678] Trial 26 finished with value: 3.3283448219299316 and parameters: {'n_estimators': 500, 'learning_rate': 0.007494151842714293, 'max_depth': 5, 'subsample': 0.777829203950613, 'colsample_bytree': 0.8239502851830613, 'gamma': 1.86374264526164, 'lambda': 0.011939254481068518, 'alpha': 0.40290063458238107}. Best is trial 24 with value: 3.294232447942098.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3185\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.3270\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:30] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:30] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:30] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:31,088] Trial 27 finished with value: 3.3375118573506675 and parameters: {'n_estimators': 550, 'learning_rate': 0.049841716942434396, 'max_depth': 7, 'subsample': 0.5603089802004576, 'colsample_bytree': 0.9474085760905192, 'gamma': 2.5412363408423757, 'lambda': 0.04114444299482195, 'alpha': 0.001095746357632422}. Best is trial 24 with value: 3.294232447942098.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3321\n",
            "\n",
            "Fold 3:\n",
            "Fold 3 Test MAE: 3.3534\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:31] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.3579\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:31] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3974\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:31] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:32,382] Trial 28 finished with value: 3.3761932055155435 and parameters: {'n_estimators': 700, 'learning_rate': 0.004514021756264693, 'max_depth': 6, 'subsample': 0.6774116532652782, 'colsample_bytree': 0.7726337031541489, 'gamma': 1.364391430997068, 'lambda': 0.09160792377318899, 'alpha': 1.0231426223980173}. Best is trial 24 with value: 3.294232447942098.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3733\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.3229\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:32] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:32] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:32] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:32,854] Trial 29 finished with value: 3.3478711446126304 and parameters: {'n_estimators': 350, 'learning_rate': 0.028630728429664395, 'max_depth': 7, 'subsample': 0.5312652492771428, 'colsample_bytree': 0.8794831528957463, 'gamma': 2.0271913883683617, 'lambda': 0.01762193274615939, 'alpha': 0.11961334458440452}. Best is trial 24 with value: 3.294232447942098.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3546\n",
            "\n",
            "Fold 3:\n",
            "Fold 3 Test MAE: 3.3660\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:32] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:32] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:33] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:33,156] Trial 30 finished with value: 3.324587106704712 and parameters: {'n_estimators': 450, 'learning_rate': 0.06078940019600249, 'max_depth': 5, 'subsample': 0.5856449817717789, 'colsample_bytree': 0.9464680998086794, 'gamma': 0.5227946619411341, 'lambda': 0.006092899091287007, 'alpha': 5.933341070500184}. Best is trial 24 with value: 3.294232447942098.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.3142\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.3281\n",
            "\n",
            "Fold 3:\n",
            "Fold 3 Test MAE: 3.3314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:33] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.2847\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:33] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.2967\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:33] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:33,997] Trial 31 finished with value: 3.296721617380778 and parameters: {'n_estimators': 1000, 'learning_rate': 0.014536834135315214, 'max_depth': 4, 'subsample': 0.6047545689468266, 'colsample_bytree': 0.763353570438245, 'gamma': 2.999746427073602, 'lambda': 0.0023899161336021504, 'alpha': 2.632976897958516}. Best is trial 24 with value: 3.294232447942098.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3088\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:34] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.2933\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:34] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:34] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:34,662] Trial 32 finished with value: 3.3054937521616616 and parameters: {'n_estimators': 1000, 'learning_rate': 0.018506821513488318, 'max_depth': 3, 'subsample': 0.6506404075547589, 'colsample_bytree': 0.7579926802067103, 'gamma': 3.020097049657731, 'lambda': 0.007506215509246476, 'alpha': 2.7291346174349083}. Best is trial 24 with value: 3.294232447942098.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3014\n",
            "\n",
            "Fold 3:\n",
            "Fold 3 Test MAE: 3.3217\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:34] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.3159\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.3247\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:34] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:35] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:35,258] Trial 33 finished with value: 3.3195718924204507 and parameters: {'n_estimators': 950, 'learning_rate': 0.02256107730122271, 'max_depth': 4, 'subsample': 0.9996238672955062, 'colsample_bytree': 0.8159348923949225, 'gamma': 2.37601408568383, 'lambda': 0.0018595819138941029, 'alpha': 9.97427034977809}. Best is trial 24 with value: 3.294232447942098.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3181\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:35] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.2958\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:35] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3234\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:36] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:36,383] Trial 34 finished with value: 3.306077798207601 and parameters: {'n_estimators': 200, 'learning_rate': 0.007963183570266482, 'max_depth': 5, 'subsample': 0.7127945252730441, 'colsample_bytree': 0.8603461126435206, 'gamma': 3.5767347381634416, 'lambda': 0.057207414556144746, 'alpha': 2.7321088171543826}. Best is trial 24 with value: 3.294232447942098.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.2990\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:36] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.2881\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:36] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3113\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:37] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:37,350] Trial 35 finished with value: 3.292530377705892 and parameters: {'n_estimators': 600, 'learning_rate': 0.015176642506574897, 'max_depth': 6, 'subsample': 0.5639883110436343, 'colsample_bytree': 0.693992122400459, 'gamma': 1.8676427047386925, 'lambda': 0.016295918342431246, 'alpha': 6.136363903291891}. Best is trial 35 with value: 3.292530377705892.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.2782\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:37] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.2988\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:37] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3016\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:37] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:38,041] Trial 36 finished with value: 3.301911989847819 and parameters: {'n_estimators': 300, 'learning_rate': 0.016787872297688126, 'max_depth': 3, 'subsample': 0.6158600980139596, 'colsample_bytree': 0.6863732344652341, 'gamma': 1.8417589692787761, 'lambda': 0.01583818376885624, 'alpha': 6.294285445017498}. Best is trial 35 with value: 3.292530377705892.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3053\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:38] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.2722\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:38] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3372\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:38] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:38,751] Trial 37 finished with value: 3.2989509105682373 and parameters: {'n_estimators': 600, 'learning_rate': 0.03130424753764824, 'max_depth': 8, 'subsample': 0.6958549621555384, 'colsample_bytree': 0.6571007298434904, 'gamma': 1.286477456562026, 'lambda': 0.006830661344933762, 'alpha': 4.224275737038026}. Best is trial 35 with value: 3.292530377705892.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.2874\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:38] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.2864\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.2946\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:38] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:39] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:39,359] Trial 38 finished with value: 3.296215613683065 and parameters: {'n_estimators': 550, 'learning_rate': 0.023126427139139646, 'max_depth': 4, 'subsample': 0.5218816854681008, 'colsample_bytree': 0.7400540461892067, 'gamma': 2.8099123905328054, 'lambda': 0.0033668738051281745, 'alpha': 2.2364975839854706}. Best is trial 35 with value: 3.292530377705892.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3076\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.3211\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:39] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:39] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:39] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:39,996] Trial 39 finished with value: 3.3106272220611572 and parameters: {'n_estimators': 450, 'learning_rate': 0.023841962097907766, 'max_depth': 4, 'subsample': 0.5700034286764385, 'colsample_bytree': 0.7064082922255068, 'gamma': 3.441867513804757, 'lambda': 0.0030835661579944463, 'alpha': 0.20465269521538645}. Best is trial 35 with value: 3.292530377705892.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.2925\n",
            "\n",
            "Fold 3:\n",
            "Fold 3 Test MAE: 3.3183\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.3048\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:40] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:40] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:40] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:40,406] Trial 40 finished with value: 3.3164219856262207 and parameters: {'n_estimators': 700, 'learning_rate': 0.0368431767753637, 'max_depth': 4, 'subsample': 0.7563943749885975, 'colsample_bytree': 0.7448664685848918, 'gamma': 4.215087634585448, 'lambda': 0.002319478129089579, 'alpha': 0.01935834113640999}. Best is trial 35 with value: 3.292530377705892.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3189\n",
            "\n",
            "Fold 3:\n",
            "Fold 3 Test MAE: 3.3255\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:40] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.2867\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:40] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3177\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:40] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:41,222] Trial 41 finished with value: 3.304749011993408 and parameters: {'n_estimators': 550, 'learning_rate': 0.015535500570232657, 'max_depth': 3, 'subsample': 0.5255662153963229, 'colsample_bytree': 0.717109086366972, 'gamma': 2.7489441974485853, 'lambda': 0.001000621461163818, 'alpha': 2.947032268890891}. Best is trial 35 with value: 3.292530377705892.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3098\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:41] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.2977\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:41] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3196\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:41] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:42,252] Trial 42 finished with value: 3.3070696194966636 and parameters: {'n_estimators': 100, 'learning_rate': 0.009862817268583396, 'max_depth': 5, 'subsample': 0.6083838279980054, 'colsample_bytree': 0.6077752077264277, 'gamma': 2.5240647853841174, 'lambda': 0.004231507259647489, 'alpha': 2.0883480579156837}. Best is trial 35 with value: 3.292530377705892.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3039\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:42] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.2892\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:42] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3095\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:42] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:43,078] Trial 43 finished with value: 3.2917051315307617 and parameters: {'n_estimators': 650, 'learning_rate': 0.026257337187746796, 'max_depth': 9, 'subsample': 0.5078771260229435, 'colsample_bytree': 0.7643080281525076, 'gamma': 2.9929098591476055, 'lambda': 0.008507664395265785, 'alpha': 6.963965356016991}. Best is trial 43 with value: 3.2917051315307617.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.2763\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:43] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.3174\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:43] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3310\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:43] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:44,160] Trial 44 finished with value: 3.3222197691599527 and parameters: {'n_estimators': 650, 'learning_rate': 0.01931757714090521, 'max_depth': 9, 'subsample': 0.5086881278215493, 'colsample_bytree': 0.7604604988470159, 'gamma': 2.909294766162971, 'lambda': 0.008172279436887211, 'alpha': 1.1075367700053447}. Best is trial 43 with value: 3.2917051315307617.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3183\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.3024\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:44] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:44] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:44] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:44,569] Trial 45 finished with value: 3.3565760453542075 and parameters: {'n_estimators': 750, 'learning_rate': 0.06374316860023847, 'max_depth': 9, 'subsample': 0.5566697485960137, 'colsample_bytree': 0.6857489736090963, 'gamma': 3.314818845843633, 'lambda': 0.0016761549619391735, 'alpha': 6.27791957277203}. Best is trial 43 with value: 3.2917051315307617.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.4203\n",
            "\n",
            "Fold 3:\n",
            "Fold 3 Test MAE: 3.3471\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:44] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.2895\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:44] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3578\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:45] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:45,385] Trial 46 finished with value: 3.329275210698446 and parameters: {'n_estimators': 450, 'learning_rate': 0.027641985523916193, 'max_depth': 10, 'subsample': 0.589046393321801, 'colsample_bytree': 0.7351988321443, 'gamma': 3.6818509387481138, 'lambda': 0.01948724413356695, 'alpha': 1.968178405160438}. Best is trial 43 with value: 3.2917051315307617.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3405\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:45] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:45] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.2766\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.3068\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:45] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:45,935] Trial 47 finished with value: 3.294006109237671 and parameters: {'n_estimators': 500, 'learning_rate': 0.023918095488091644, 'max_depth': 4, 'subsample': 0.6296547126550436, 'colsample_bytree': 0.6457869485188296, 'gamma': 0.903752023822472, 'lambda': 0.00883625312428476, 'alpha': 4.48426270650178}. Best is trial 43 with value: 3.2917051315307617.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:45] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.2987\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.3041\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.3047\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:46,255] Trial 48 finished with value: 3.3052639961242676 and parameters: {'n_estimators': 500, 'learning_rate': 0.049864663435749065, 'max_depth': 3, 'subsample': 0.5181758582100258, 'colsample_bytree': 0.5836228265851698, 'gamma': 0.6191688209345774, 'lambda': 0.010549392668727047, 'alpha': 6.953542926496535}. Best is trial 43 with value: 3.2917051315307617.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3070\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.3110\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-03-11 13:00:46,820] Trial 49 finished with value: 3.302531639734904 and parameters: {'n_estimators': 650, 'learning_rate': 0.024161863338413157, 'max_depth': 5, 'subsample': 0.6408318871575175, 'colsample_bytree': 0.5905038029897569, 'gamma': 0.939044511172334, 'lambda': 0.036371973568729545, 'alpha': 4.841912277473866}. Best is trial 43 with value: 3.2917051315307617.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.2992\n",
            "\n",
            "Fold 3:\n",
            "Fold 3 Test MAE: 3.2974\n",
            "Best Hyperparameters: {'n_estimators': 650, 'learning_rate': 0.026257337187746796, 'max_depth': 9, 'subsample': 0.5078771260229435, 'colsample_bytree': 0.7643080281525076, 'gamma': 2.9929098591476055, 'lambda': 0.008507664395265785, 'alpha': 6.963965356016991}\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.3115\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.3114\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:47] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:47] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3011\n",
            "\n",
            "Average MAE across folds: 3.3080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, GridSearchCV\n",
        "from sklearn.metrics import make_scorer, mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 랜덤 시드 설정\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "\n",
        "# 데이터 준비\n",
        "target = '우울증_지수'\n",
        "features = [col for col in df.columns if col != target]\n",
        "\n",
        "X = df[features].values\n",
        "y = df[target].values.reshape(-1, 1)\n",
        "\n",
        "# 데이터 정규화\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "kf = KFold(n_splits=3, shuffle=True, random_state=seed)\n",
        "\n",
        "# ✅ 하이퍼파라미터 그리드 정의\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 300, 500, 1000],  # 트리 개수\n",
        "    'learning_rate': [0.001, 0.05, 0.1],  # 학습률\n",
        "    'max_depth': [3, 5, 7],  # 트리 깊이\n",
        "    'subsample': [0.5, 0.7, 1.0],  # 샘플링 비율\n",
        "    'colsample_bytree': [0.5, 0.7, 1.0],  # 컬럼 샘플링 비율\n",
        "    'lambda': [0.001, 1, 10],  # L2 정규화\n",
        "    'alpha': [0.001, 1, 10]  # L1 정규화\n",
        "}\n",
        "\n",
        "# XGBoost 모델 초기화\n",
        "model = xgb.XGBRegressor(objective='reg:squarederror', eval_metric='mae', random_state=seed)\n",
        "\n",
        "# ✅ GridSearchCV 설정 (3-Fold 교차 검증, MAE 최소화)\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=param_grid,\n",
        "    scoring=make_scorer(mean_absolute_error, greater_is_better=False),  # MAE를 최소화\n",
        "    cv=kf,\n",
        "    verbose=3,\n",
        "    n_jobs=-1  # 모든 코어 사용\n",
        ")\n",
        "\n",
        "# GridSearch 실행\n",
        "grid_search.fit(X, y.ravel())\n",
        "\n",
        "# 최적 하이퍼파라미터 출력\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# ✅ 최적 하이퍼파라미터로 최종 학습 및 평가\n",
        "best_params = grid_search.best_params_\n",
        "fold_mae_scores = []\n",
        "fold = 1\n",
        "\n",
        "for train_idx, test_idx in kf.split(X, y):\n",
        "    print(f\"\\nFold {fold}:\")\n",
        "\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    # 최적 하이퍼파라미터 기반 XGBoost 모델 생성\n",
        "    model = xgb.XGBRegressor(**best_params, objective='reg:squarederror', eval_metric='mae', random_state=seed)\n",
        "\n",
        "    # 모델 학습\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # 예측 및 MAE 계산\n",
        "    y_pred = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "    print(f\"Fold {fold} Test MAE: {mae:.4f}\")\n",
        "    fold_mae_scores.append(mae)\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# ✅ 최종 평균 MAE 출력\n",
        "print(f\"\\nAverage MAE across folds: {np.mean(fold_mae_scores):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNxwUckH-kYC",
        "outputId": "61b34d42-4bce-4231-c738-65c9a98a0c91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 2916 candidates, totalling 8748 fits\n",
            "Best Hyperparameters: {'alpha': 1, 'colsample_bytree': 1.0, 'lambda': 10, 'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 100, 'subsample': 0.5}\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.2598\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.3009\n",
            "\n",
            "Fold 3:\n",
            "Fold 3 Test MAE: 3.2246\n",
            "\n",
            "Average MAE across folds: 3.2618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 10% 데이터만 사용하여 실행 시간 예측\n",
        "X_sample, _, y_sample, _ = train_test_split(X, y, test_size=0.99, random_state=seed)\n",
        "\n",
        "start_time = time.time()\n",
        "grid_search.fit(X_sample, y_sample.ravel())\n",
        "end_time = time.time()\n",
        "\n",
        "elapsed_time = end_time - start_time\n",
        "estimated_full_time = elapsed_time * 100  # 전체 데이터 크기에 비례하여 예측\n",
        "\n",
        "print(f\"샘플 실행 시간: {elapsed_time:.2f} 초\")\n",
        "print(f\"예상 전체 실행 시간: {estimated_full_time:.2f} 초\")\n",
        "print(f\"예상 전체 실행 시간: {estimated_full_time / 60:.2f} 분\")\n",
        "print(f\"예상 전체 실행 시간: {estimated_full_time / 3600:.2f} 시간\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu8RWXso_QBz",
        "outputId": "c2469354-7ca7-4a86-e2c0-ed986b01d28d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 2916 candidates, totalling 8748 fits\n",
            "샘플 실행 시간: 85.58 초\n",
            "예상 전체 실행 시간: 8557.52 초\n",
            "예상 전체 실행 시간: 142.63 분\n",
            "예상 전체 실행 시간: 2.38 시간\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n",
        "import numpy as np\n",
        "import optuna\n",
        "import catboost\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 랜덤 시드 설정\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "\n",
        "# 데이터 준비\n",
        "target = '우울증_지수'\n",
        "features = [col for col in df.columns if col != target]\n",
        "\n",
        "X = df[features].values\n",
        "y = df[target].values.reshape(-1, 1)\n",
        "\n",
        "# 데이터 정규화\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "kf = KFold(n_splits=3, shuffle=True, random_state=seed)\n",
        "\n",
        "# ✅ Optuna를 사용한 CatBoost 하이퍼파라미터 튜닝\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        \"iterations\": trial.suggest_int(\"iterations\", 100, 1000, step=100),  # 트리 개수\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),  # 학습률\n",
        "        \"depth\": trial.suggest_int(\"depth\", 4, 10),  # 트리 깊이\n",
        "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1, 10),  # L2 정규화\n",
        "        \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 1.0),  # 샘플링 강도\n",
        "        \"border_count\": trial.suggest_int(\"border_count\", 32, 255),  # 분할 수\n",
        "        \"random_strength\": trial.suggest_float(\"random_strength\", 1e-9, 10.0, log=True),  # 랜덤 노이즈\n",
        "        \"loss_function\": \"MAE\",\n",
        "        \"random_seed\": seed,\n",
        "        \"verbose\": 0\n",
        "    }\n",
        "\n",
        "    fold_mae_scores = []\n",
        "    fold = 1\n",
        "\n",
        "    for train_idx, test_idx in kf.split(X, y):\n",
        "        print(f\"\\nFold {fold}:\")\n",
        "\n",
        "        X_train, X_test = X[train_idx], X[test_idx]\n",
        "        y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "        # ✅ CatBoost 모델 학습\n",
        "        model = CatBoostRegressor(**params)\n",
        "        model.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=20, verbose=False)\n",
        "\n",
        "        # 예측 및 MAE 계산\n",
        "        y_pred = model.predict(X_test)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "        print(f\"Fold {fold} Test MAE: {mae:.4f}\")\n",
        "        fold_mae_scores.append(mae)\n",
        "\n",
        "        fold += 1\n",
        "\n",
        "    return np.mean(fold_mae_scores)\n",
        "\n",
        "# Optuna 실행\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# 최적 하이퍼파라미터 출력\n",
        "print(\"Best Hyperparameters:\", study.best_params)\n",
        "\n",
        "# ✅ 최적 하이퍼파라미터로 최종 학습 및 평가\n",
        "best_params = study.best_params\n",
        "fold_mae_scores = []\n",
        "fold = 1\n",
        "\n",
        "for train_idx, test_idx in kf.split(X, y):\n",
        "    print(f\"\\nFold {fold}:\")\n",
        "\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    # ✅ 최적 하이퍼파라미터 기반 CatBoost 모델 생성\n",
        "    model = CatBoostRegressor(**best_params, loss_function=\"MAE\", random_seed=seed, verbose=0)\n",
        "\n",
        "    # 모델 학습\n",
        "    model.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=20, verbose=False)\n",
        "\n",
        "    # 예측 및 MAE 계산\n",
        "    y_pred = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "    print(f\"Fold {fold} Test MAE: {mae:.4f}\")\n",
        "    fold_mae_scores.append(mae)\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# ✅ 최종 평균 MAE 출력\n",
        "print(f\"\\nAverage MAE across folds: {np.mean(fold_mae_scores):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYf0JUYAb_xI",
        "outputId": "20010317-d025-4a50-d377-bfc4243dc896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:43:22,756] A new study created in memory with name: no-name-fbb4a536-4949-4d96-a0fc-62e1f5a5f776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0277\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.1160\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:43:24,384] Trial 0 finished with value: 3.0559562476922775 and parameters: {'iterations': 200, 'learning_rate': 0.029550403303084057, 'depth': 7, 'l2_leaf_reg': 1.0238733875092396, 'bagging_temperature': 0.6246889020833766, 'border_count': 224, 'random_strength': 5.0971955297867914e-08}. Best is trial 0 with value: 3.0559562476922775.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0241\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 2.9983\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.0751\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:43:25,681] Trial 1 finished with value: 3.0210738848947685 and parameters: {'iterations': 600, 'learning_rate': 0.042855489611658415, 'depth': 6, 'l2_leaf_reg': 9.228806605999832, 'bagging_temperature': 0.44508157297941464, 'border_count': 218, 'random_strength': 0.8497266891308358}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 2.9899\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0328\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.1332\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:43:27,822] Trial 2 finished with value: 3.064902666943903 and parameters: {'iterations': 800, 'learning_rate': 0.01046035290928671, 'depth': 4, 'l2_leaf_reg': 5.5468957376675, 'bagging_temperature': 0.9805658914180255, 'border_count': 132, 'random_strength': 6.937339200832775e-08}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0287\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.1146\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.1758\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:43:32,265] Trial 3 finished with value: 3.1266088264135625 and parameters: {'iterations': 500, 'learning_rate': 0.034559191543477204, 'depth': 10, 'l2_leaf_reg': 7.026139436086617, 'bagging_temperature': 0.7677724652943746, 'border_count': 75, 'random_strength': 0.00010724193771550873}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0894\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.2356\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.1820\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:43:33,551] Trial 4 finished with value: 3.194739340121604 and parameters: {'iterations': 200, 'learning_rate': 0.18990583552774462, 'depth': 10, 'l2_leaf_reg': 4.568466895108251, 'bagging_temperature': 0.3854309742624188, 'border_count': 85, 'random_strength': 8.551135422904422e-06}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.1666\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0155\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.1133\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:43:34,377] Trial 5 finished with value: 3.052467898530958 and parameters: {'iterations': 300, 'learning_rate': 0.06252694499671427, 'depth': 4, 'l2_leaf_reg': 6.154574201387186, 'bagging_temperature': 0.8841861939034202, 'border_count': 108, 'random_strength': 0.00038371848518557587}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0286\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0970\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.1614\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:43:35,712] Trial 6 finished with value: 3.09885360530185 and parameters: {'iterations': 100, 'learning_rate': 0.024570816847665152, 'depth': 8, 'l2_leaf_reg': 4.767497090471521, 'bagging_temperature': 0.20112642465915576, 'border_count': 51, 'random_strength': 2.0624770583757893e-09}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0381\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.1480\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.1792\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:43:38,898] Trial 7 finished with value: 3.1451018208345354 and parameters: {'iterations': 100, 'learning_rate': 0.02357674701678935, 'depth': 10, 'l2_leaf_reg': 6.453275862911047, 'bagging_temperature': 0.13014840512880343, 'border_count': 101, 'random_strength': 0.0016279402225934478}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.1081\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0195\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.1031\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:43:40,988] Trial 8 finished with value: 3.051529197741577 and parameters: {'iterations': 800, 'learning_rate': 0.01485438570086312, 'depth': 4, 'l2_leaf_reg': 9.950573054765878, 'bagging_temperature': 0.03208967093154225, 'border_count': 117, 'random_strength': 0.03937240250980392}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0320\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0340\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.1186\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:43:42,385] Trial 9 finished with value: 3.0596359929924977 and parameters: {'iterations': 600, 'learning_rate': 0.04517704658378395, 'depth': 7, 'l2_leaf_reg': 3.5904854402791404, 'bagging_temperature': 0.2056557350734819, 'border_count': 156, 'random_strength': 9.858556770932766e-08}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0263\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0820\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.0709\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:43:43,249] Trial 10 finished with value: 3.0580519553146144 and parameters: {'iterations': 1000, 'learning_rate': 0.1064668723199278, 'depth': 6, 'l2_leaf_reg': 9.91684161949103, 'bagging_temperature': 0.4480275445393044, 'border_count': 255, 'random_strength': 8.592252297843492}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0212\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0033\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.0835\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:43:45,895] Trial 11 finished with value: 3.0366788055849843 and parameters: {'iterations': 700, 'learning_rate': 0.011151019668326056, 'depth': 5, 'l2_leaf_reg': 9.495824835942162, 'bagging_temperature': 0.027008382375011575, 'border_count': 182, 'random_strength': 0.3970868970113849}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0232\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0298\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.0875\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:43:46,880] Trial 12 finished with value: 3.05274201186946 and parameters: {'iterations': 600, 'learning_rate': 0.0859880044126475, 'depth': 6, 'l2_leaf_reg': 8.31471905643816, 'bagging_temperature': 0.35459351086691765, 'border_count': 186, 'random_strength': 8.206024108927837}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0410\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0730\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:43:47,371] Trial 13 finished with value: 3.085407353232236 and parameters: {'iterations': 800, 'learning_rate': 0.27572198323296204, 'depth': 5, 'l2_leaf_reg': 8.589997647393417, 'bagging_temperature': 0.6086729386099442, 'border_count': 190, 'random_strength': 0.08127315560765383}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.1379\n",
            "\n",
            "Fold 3:\n",
            "Fold 3 Test MAE: 3.0453\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0077\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.1044\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:43:49,534] Trial 14 finished with value: 3.0467134823847375 and parameters: {'iterations': 500, 'learning_rate': 0.01554827218423355, 'depth': 6, 'l2_leaf_reg': 8.525879138259876, 'bagging_temperature': 0.03907828604695873, 'border_count': 199, 'random_strength': 0.1952188391797261}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0280\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0156\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.1105\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:43:54,566] Trial 15 finished with value: 3.0510537523035346 and parameters: {'iterations': 700, 'learning_rate': 0.010172512915439413, 'depth': 8, 'l2_leaf_reg': 7.424634627740203, 'bagging_temperature': 0.30639326598472255, 'border_count': 165, 'random_strength': 0.558918458820174}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0270\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0108\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.1130\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:43:55,166] Trial 16 finished with value: 3.0478008656369044 and parameters: {'iterations': 1000, 'learning_rate': 0.102789494830898, 'depth': 5, 'l2_leaf_reg': 8.986216481158236, 'bagging_temperature': 0.5603135521550743, 'border_count': 246, 'random_strength': 0.004065186177250259}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0196\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0167\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.1299\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:43:56,679] Trial 17 finished with value: 3.0597584366330643 and parameters: {'iterations': 400, 'learning_rate': 0.017295590096681978, 'depth': 5, 'l2_leaf_reg': 2.704346981147049, 'bagging_temperature': 0.7089770523308763, 'border_count': 220, 'random_strength': 4.6851516146536245e-06}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0326\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0148\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.1668\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:43:58,009] Trial 18 finished with value: 3.078509597134236 and parameters: {'iterations': 700, 'learning_rate': 0.051055253730383734, 'depth': 8, 'l2_leaf_reg': 7.575146394457855, 'bagging_temperature': 0.4797915247535083, 'border_count': 217, 'random_strength': 0.010891448823045841}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0539\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 2.9958\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.0930\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:43:58,867] Trial 19 finished with value: 3.0373298292623314 and parameters: {'iterations': 900, 'learning_rate': 0.07525349221166854, 'depth': 6, 'l2_leaf_reg': 9.279022413886079, 'bagging_temperature': 0.2937752443036425, 'border_count': 173, 'random_strength': 0.9648366339947726}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0232\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0139\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:43:59,527] Trial 20 finished with value: 3.043321342993293 and parameters: {'iterations': 400, 'learning_rate': 0.15101330521162698, 'depth': 5, 'l2_leaf_reg': 7.691397257679876, 'bagging_temperature': 0.16484511150353853, 'border_count': 142, 'random_strength': 1.1789549368916798}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.1048\n",
            "\n",
            "Fold 3:\n",
            "Fold 3 Test MAE: 3.0113\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0264\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.0910\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:00,458] Trial 21 finished with value: 3.0473015779299257 and parameters: {'iterations': 900, 'learning_rate': 0.08050912705675635, 'depth': 6, 'l2_leaf_reg': 9.689429611674308, 'bagging_temperature': 0.28660059200609594, 'border_count': 171, 'random_strength': 0.7675094391404923}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0246\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0750\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.1004\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:01,759] Trial 22 finished with value: 3.0638454267768984 and parameters: {'iterations': 700, 'learning_rate': 0.04252158029662665, 'depth': 7, 'l2_leaf_reg': 9.18301556927889, 'bagging_temperature': 0.001209649750478825, 'border_count': 204, 'random_strength': 0.024992603170852588}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0161\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0026\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.0824\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:02,786] Trial 23 finished with value: 3.0296561594039644 and parameters: {'iterations': 900, 'learning_rate': 0.06413626124188943, 'depth': 6, 'l2_leaf_reg': 7.94703051788321, 'bagging_temperature': 0.4119662801263139, 'border_count': 175, 'random_strength': 2.164487239624801}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0039\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0385\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.1166\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:03,464] Trial 24 finished with value: 3.055836561230658 and parameters: {'iterations': 900, 'learning_rate': 0.14055735610244996, 'depth': 5, 'l2_leaf_reg': 7.993532054675876, 'bagging_temperature': 0.42474270748493675, 'border_count': 242, 'random_strength': 2.9247990375585986}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0124\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0157\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.1148\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:04,438] Trial 25 finished with value: 3.0554412099960118 and parameters: {'iterations': 600, 'learning_rate': 0.05993142679254507, 'depth': 7, 'l2_leaf_reg': 6.971791469098854, 'bagging_temperature': 0.719674691236558, 'border_count': 146, 'random_strength': 0.16225381274167494}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0358\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0566\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.1550\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:08,288] Trial 26 finished with value: 3.0817481698267755 and parameters: {'iterations': 700, 'learning_rate': 0.020612345397590357, 'depth': 9, 'l2_leaf_reg': 8.931215762442289, 'bagging_temperature': 0.5211179277990011, 'border_count': 184, 'random_strength': 0.0012241433353134788}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0336\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0060\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.1309\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:09,788] Trial 27 finished with value: 3.052570707426739 and parameters: {'iterations': 800, 'learning_rate': 0.031128156102973047, 'depth': 6, 'l2_leaf_reg': 8.040347217255515, 'bagging_temperature': 0.09355544170578281, 'border_count': 231, 'random_strength': 0.012569585693946266}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0209\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0052\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.1174\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:10,855] Trial 28 finished with value: 3.045524923192284 and parameters: {'iterations': 500, 'learning_rate': 0.040684207965725125, 'depth': 5, 'l2_leaf_reg': 9.389423164206049, 'bagging_temperature': 0.24634431353721442, 'border_count': 205, 'random_strength': 0.1874364626857425}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0140\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0228\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.0802\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:14,469] Trial 29 finished with value: 3.042564215761953 and parameters: {'iterations': 900, 'learning_rate': 0.012663567738557655, 'depth': 7, 'l2_leaf_reg': 6.412158009158318, 'bagging_temperature': 0.6252817279396957, 'border_count': 216, 'random_strength': 9.534056082695107}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0247\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0119\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.0965\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:15,715] Trial 30 finished with value: 3.045843852397374 and parameters: {'iterations': 400, 'learning_rate': 0.03371817223987393, 'depth': 4, 'l2_leaf_reg': 1.0415535845099395, 'bagging_temperature': 0.3600902758520821, 'border_count': 161, 'random_strength': 1.0922038375604326e-05}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0291\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0289\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.0764\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:16,615] Trial 31 finished with value: 3.0422589506975535 and parameters: {'iterations': 1000, 'learning_rate': 0.06851967842204341, 'depth': 6, 'l2_leaf_reg': 9.217837256579928, 'bagging_temperature': 0.30832336060333765, 'border_count': 177, 'random_strength': 2.059349227530223}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0215\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0229\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.0921\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:17,444] Trial 32 finished with value: 3.044297277505209 and parameters: {'iterations': 900, 'learning_rate': 0.0783457277438251, 'depth': 6, 'l2_leaf_reg': 8.725052524171478, 'bagging_temperature': 0.5431753168961724, 'border_count': 126, 'random_strength': 0.5106120203626674}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0179\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0130\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.0801\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:18,464] Trial 33 finished with value: 3.036228381166758 and parameters: {'iterations': 800, 'learning_rate': 0.09497475542782956, 'depth': 7, 'l2_leaf_reg': 9.497037801976411, 'bagging_temperature': 0.45239135929955576, 'border_count': 148, 'random_strength': 2.26671318527625}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0156\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0302\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.0661\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:19,366] Trial 34 finished with value: 3.047228197437264 and parameters: {'iterations': 800, 'learning_rate': 0.1120279555934242, 'depth': 7, 'l2_leaf_reg': 9.98195532035494, 'bagging_temperature': 0.40528797474178907, 'border_count': 148, 'random_strength': 2.8492787657433407}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0454\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.1306\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:19,997] Trial 35 finished with value: 3.1393452743056827 and parameters: {'iterations': 700, 'learning_rate': 0.2585591039430988, 'depth': 8, 'l2_leaf_reg': 5.424726429573715, 'bagging_temperature': 0.8564319756613059, 'border_count': 197, 'random_strength': 0.07650271526590383}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.1834\n",
            "\n",
            "Fold 3:\n",
            "Fold 3 Test MAE: 3.1041\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0694\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:20,674] Trial 36 finished with value: 3.1012390805875563 and parameters: {'iterations': 600, 'learning_rate': 0.1526794551761151, 'depth': 7, 'l2_leaf_reg': 8.207410906031033, 'bagging_temperature': 0.6041690276751913, 'border_count': 135, 'random_strength': 4.130258691238646e-05}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.1592\n",
            "\n",
            "Fold 3:\n",
            "Fold 3 Test MAE: 3.0751\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0082\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:21,538] Trial 37 finished with value: 3.0572418840636844 and parameters: {'iterations': 800, 'learning_rate': 0.05554238914274687, 'depth': 4, 'l2_leaf_reg': 9.500842686159613, 'bagging_temperature': 0.9621832672650383, 'border_count': 92, 'random_strength': 8.253000087274833e-07}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.1121\n",
            "\n",
            "Fold 3:\n",
            "Fold 3 Test MAE: 3.0514\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0372\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.1314\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:24,778] Trial 38 finished with value: 3.07193687819073 and parameters: {'iterations': 700, 'learning_rate': 0.02456711159947301, 'depth': 9, 'l2_leaf_reg': 5.833998239912653, 'bagging_temperature': 0.48008985506679874, 'border_count': 44, 'random_strength': 0.31062524553359266}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0472\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0315\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:25,404] Trial 39 finished with value: 3.065865585639866 and parameters: {'iterations': 500, 'learning_rate': 0.12365575025006616, 'depth': 5, 'l2_leaf_reg': 7.153143993177472, 'bagging_temperature': 0.6734138182070027, 'border_count': 232, 'random_strength': 0.0003708548313760791}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.1385\n",
            "\n",
            "Fold 3:\n",
            "Fold 3 Test MAE: 3.0275\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0491\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.1266\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:26,017] Trial 40 finished with value: 3.07620651350652 and parameters: {'iterations': 800, 'learning_rate': 0.19846834372723846, 'depth': 7, 'l2_leaf_reg': 6.938137280270221, 'bagging_temperature': 0.8040680384107709, 'border_count': 64, 'random_strength': 3.244690479972025}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0529\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0254\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.0936\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:27,023] Trial 41 finished with value: 3.0425375826743397 and parameters: {'iterations': 900, 'learning_rate': 0.06807144513243463, 'depth': 6, 'l2_leaf_reg': 9.425163098590685, 'bagging_temperature': 0.3562781871611963, 'border_count': 176, 'random_strength': 1.1371390453563812}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0087\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0254\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:27,883] Trial 42 finished with value: 3.0674525960994465 and parameters: {'iterations': 900, 'learning_rate': 0.09263111789972171, 'depth': 6, 'l2_leaf_reg': 8.848583911641997, 'bagging_temperature': 0.45856024503777393, 'border_count': 155, 'random_strength': 1.5074324935373926e-09}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.1299\n",
            "\n",
            "Fold 3:\n",
            "Fold 3 Test MAE: 3.0470\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0004\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.1203\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:28,963] Trial 43 finished with value: 3.0487392492521312 and parameters: {'iterations': 1000, 'learning_rate': 0.038634867142182665, 'depth': 6, 'l2_leaf_reg': 9.64448075746741, 'bagging_temperature': 0.12054206686417739, 'border_count': 166, 'random_strength': 0.043313200991796794}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0256\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 2.9984\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.0819\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:30,041] Trial 44 finished with value: 3.0389211215151977 and parameters: {'iterations': 600, 'learning_rate': 0.052994408632322715, 'depth': 7, 'l2_leaf_reg': 8.400370481759033, 'bagging_temperature': 0.2276453944339721, 'border_count': 209, 'random_strength': 4.763078299386145}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0365\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0096\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.0877\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:30,932] Trial 45 finished with value: 3.0454381436995948 and parameters: {'iterations': 800, 'learning_rate': 0.07138598273583963, 'depth': 5, 'l2_leaf_reg': 9.110717018165257, 'bagging_temperature': 0.39458348679360583, 'border_count': 190, 'random_strength': 1.0858071744801207e-08}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0390\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0106\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.0783\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:32,098] Trial 46 finished with value: 3.03506180744909 and parameters: {'iterations': 900, 'learning_rate': 0.04776563607633891, 'depth': 6, 'l2_leaf_reg': 9.981533602058919, 'bagging_temperature': 0.33025602318589226, 'border_count': 126, 'random_strength': 1.10384269052259}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0163\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0019\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:33,003] Trial 47 finished with value: 3.049744166794408 and parameters: {'iterations': 700, 'learning_rate': 0.047727078372140276, 'depth': 4, 'l2_leaf_reg': 9.816738198782627, 'bagging_temperature': 0.5235363001110463, 'border_count': 115, 'random_strength': 0.1116471199875415}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.1015\n",
            "\n",
            "Fold 3:\n",
            "Fold 3 Test MAE: 3.0459\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0070\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.1002\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:34,645] Trial 48 finished with value: 3.039109571569272 and parameters: {'iterations': 1000, 'learning_rate': 0.029522038843078052, 'depth': 6, 'l2_leaf_reg': 9.986250011432794, 'bagging_temperature': 0.17636694153840124, 'border_count': 130, 'random_strength': 0.3034544491983926}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0102\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 3.0123\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.1282\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:44:36,698] Trial 49 finished with value: 3.0574621586901785 and parameters: {'iterations': 800, 'learning_rate': 0.012197870494413317, 'depth': 5, 'l2_leaf_reg': 4.279294068371814, 'bagging_temperature': 0.5669634840656618, 'border_count': 101, 'random_strength': 0.004472328405986764}. Best is trial 1 with value: 3.0210738848947685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.0319\n",
            "Best Hyperparameters: {'iterations': 600, 'learning_rate': 0.042855489611658415, 'depth': 6, 'l2_leaf_reg': 9.228806605999832, 'bagging_temperature': 0.44508157297941464, 'border_count': 218, 'random_strength': 0.8497266891308358}\n",
            "\n",
            "Fold 1:\n",
            "Fold 1 Test MAE: 2.9983\n",
            "\n",
            "Fold 2:\n",
            "Fold 2 Test MAE: 3.0751\n",
            "\n",
            "Fold 3:\n",
            "Fold 3 Test MAE: 2.9899\n",
            "\n",
            "Average MAE across folds: 3.0211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8O8IgSnhXxQi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adc8058d-02b9-4f34-d5a0-026945f1c492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-11 13:51:59,411] A new study created in memory with name: no-name-87c5f1fc-e1e1-4390-8b85-ded252cad813\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1:\n",
            "epoch 0  | loss: 35.16501| val_0_mse: 29.7077 |  0:00:01s\n",
            "epoch 1  | loss: 28.65549| val_0_mse: 28.35834|  0:00:02s\n",
            "epoch 2  | loss: 27.1401 | val_0_mse: 26.84063|  0:00:03s\n",
            "epoch 3  | loss: 26.52346| val_0_mse: 27.03741|  0:00:04s\n",
            "epoch 4  | loss: 26.44148| val_0_mse: 26.9233 |  0:00:06s\n",
            "epoch 5  | loss: 25.37952| val_0_mse: 25.3637 |  0:00:07s\n",
            "epoch 6  | loss: 24.75033| val_0_mse: 26.14008|  0:00:08s\n",
            "epoch 7  | loss: 25.2394 | val_0_mse: 24.85993|  0:00:09s\n",
            "epoch 8  | loss: 24.4813 | val_0_mse: 28.73252|  0:00:11s\n",
            "epoch 9  | loss: 23.97364| val_0_mse: 23.43693|  0:00:12s\n",
            "epoch 10 | loss: 23.93193| val_0_mse: 23.72613|  0:00:13s\n",
            "epoch 11 | loss: 22.89537| val_0_mse: 23.88817|  0:00:14s\n",
            "epoch 12 | loss: 22.55644| val_0_mse: 22.85433|  0:00:15s\n",
            "epoch 13 | loss: 22.90081| val_0_mse: 23.62722|  0:00:17s\n",
            "epoch 14 | loss: 23.11772| val_0_mse: 22.23941|  0:00:18s\n",
            "epoch 15 | loss: 22.67197| val_0_mse: 22.59759|  0:00:19s\n",
            "epoch 16 | loss: 23.08868| val_0_mse: 23.06386|  0:00:20s\n",
            "epoch 17 | loss: 22.50987| val_0_mse: 22.92365|  0:00:22s\n",
            "epoch 18 | loss: 22.29078| val_0_mse: 22.07887|  0:00:23s\n",
            "epoch 19 | loss: 21.11216| val_0_mse: 22.4173 |  0:00:24s\n",
            "epoch 20 | loss: 22.34566| val_0_mse: 22.37569|  0:00:25s\n",
            "epoch 21 | loss: 21.66984| val_0_mse: 21.91436|  0:00:26s\n",
            "epoch 22 | loss: 21.91038| val_0_mse: 22.16932|  0:00:28s\n",
            "epoch 23 | loss: 21.70905| val_0_mse: 22.52841|  0:00:29s\n",
            "epoch 24 | loss: 21.44713| val_0_mse: 21.84298|  0:00:30s\n",
            "epoch 25 | loss: 21.76326| val_0_mse: 23.15496|  0:00:31s\n",
            "epoch 26 | loss: 21.80883| val_0_mse: 22.01709|  0:00:33s\n",
            "epoch 27 | loss: 21.60125| val_0_mse: 21.99907|  0:00:34s\n",
            "epoch 28 | loss: 21.21213| val_0_mse: 21.83551|  0:00:35s\n",
            "epoch 29 | loss: 21.47747| val_0_mse: 21.99097|  0:00:36s\n",
            "epoch 30 | loss: 21.98856| val_0_mse: 22.06533|  0:00:37s\n",
            "epoch 31 | loss: 21.56382| val_0_mse: 21.92231|  0:00:39s\n",
            "epoch 32 | loss: 21.37566| val_0_mse: 21.92351|  0:00:40s\n",
            "epoch 33 | loss: 21.71046| val_0_mse: 21.79209|  0:00:41s\n",
            "epoch 34 | loss: 21.37929| val_0_mse: 21.51459|  0:00:42s\n",
            "epoch 35 | loss: 21.01226| val_0_mse: 21.94403|  0:00:43s\n",
            "epoch 36 | loss: 20.88989| val_0_mse: 22.60524|  0:00:45s\n",
            "epoch 37 | loss: 21.10257| val_0_mse: 22.64181|  0:00:46s\n",
            "epoch 38 | loss: 21.02466| val_0_mse: 21.96799|  0:00:47s\n",
            "epoch 39 | loss: 21.39527| val_0_mse: 21.94825|  0:00:48s\n",
            "epoch 40 | loss: 20.71782| val_0_mse: 21.72469|  0:00:50s\n",
            "epoch 41 | loss: 20.90192| val_0_mse: 22.10867|  0:00:51s\n",
            "epoch 42 | loss: 21.58534| val_0_mse: 21.23963|  0:00:52s\n",
            "epoch 43 | loss: 20.9767 | val_0_mse: 21.37822|  0:00:53s\n",
            "epoch 44 | loss: 20.51412| val_0_mse: 22.25305|  0:00:54s\n",
            "epoch 45 | loss: 20.93484| val_0_mse: 21.57644|  0:00:56s\n",
            "epoch 46 | loss: 21.11873| val_0_mse: 21.51599|  0:00:57s\n",
            "epoch 47 | loss: 20.22166| val_0_mse: 22.02081|  0:00:58s\n",
            "epoch 48 | loss: 20.75137| val_0_mse: 21.96863|  0:00:59s\n",
            "epoch 49 | loss: 20.79228| val_0_mse: 21.6979 |  0:01:00s\n",
            "epoch 50 | loss: 20.686  | val_0_mse: 21.95703|  0:01:02s\n",
            "epoch 51 | loss: 20.74455| val_0_mse: 21.87918|  0:01:03s\n",
            "epoch 52 | loss: 21.15805| val_0_mse: 22.19113|  0:01:04s\n",
            "epoch 53 | loss: 20.41123| val_0_mse: 22.35205|  0:01:05s\n",
            "epoch 54 | loss: 20.34181| val_0_mse: 23.04556|  0:01:06s\n",
            "epoch 55 | loss: 21.22138| val_0_mse: 22.52012|  0:01:08s\n",
            "epoch 56 | loss: 20.33245| val_0_mse: 22.41805|  0:01:09s\n",
            "epoch 57 | loss: 20.03673| val_0_mse: 22.56214|  0:01:10s\n",
            "epoch 58 | loss: 20.48308| val_0_mse: 22.7262 |  0:01:11s\n",
            "epoch 59 | loss: 19.79178| val_0_mse: 22.12109|  0:01:12s\n",
            "epoch 60 | loss: 19.86928| val_0_mse: 22.17202|  0:01:14s\n",
            "epoch 61 | loss: 20.19338| val_0_mse: 22.77975|  0:01:15s\n",
            "epoch 62 | loss: 19.9757 | val_0_mse: 22.56302|  0:01:16s\n",
            "\n",
            "Early stopping occurred at epoch 62 with best_epoch = 42 and best_val_0_mse = 21.23963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.4443\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 35.31525| val_0_mse: 31.37686|  0:00:01s\n",
            "epoch 1  | loss: 26.60137| val_0_mse: 27.6117 |  0:00:02s\n",
            "epoch 2  | loss: 26.79697| val_0_mse: 28.45   |  0:00:03s\n",
            "epoch 3  | loss: 25.58154| val_0_mse: 25.55458|  0:00:04s\n",
            "epoch 4  | loss: 25.9025 | val_0_mse: 26.11126|  0:00:06s\n",
            "epoch 5  | loss: 25.69677| val_0_mse: 26.58148|  0:00:07s\n",
            "epoch 6  | loss: 25.14326| val_0_mse: 28.03429|  0:00:08s\n",
            "epoch 7  | loss: 25.15658| val_0_mse: 23.60075|  0:00:09s\n",
            "epoch 8  | loss: 24.62175| val_0_mse: 25.10625|  0:00:10s\n",
            "epoch 9  | loss: 24.02632| val_0_mse: 22.62385|  0:00:12s\n",
            "epoch 10 | loss: 23.65185| val_0_mse: 24.78468|  0:00:13s\n",
            "epoch 11 | loss: 24.02599| val_0_mse: 24.38939|  0:00:14s\n",
            "epoch 12 | loss: 23.95844| val_0_mse: 23.79312|  0:00:15s\n",
            "epoch 13 | loss: 23.65569| val_0_mse: 24.27699|  0:00:17s\n",
            "epoch 14 | loss: 23.50315| val_0_mse: 23.91512|  0:00:18s\n",
            "epoch 15 | loss: 24.52263| val_0_mse: 25.53941|  0:00:19s\n",
            "epoch 16 | loss: 23.90975| val_0_mse: 23.18699|  0:00:20s\n",
            "epoch 17 | loss: 22.75346| val_0_mse: 23.0587 |  0:00:22s\n",
            "epoch 18 | loss: 23.0785 | val_0_mse: 23.75904|  0:00:23s\n",
            "epoch 19 | loss: 22.63863| val_0_mse: 23.62003|  0:00:24s\n",
            "epoch 20 | loss: 21.80345| val_0_mse: 23.72114|  0:00:25s\n",
            "epoch 21 | loss: 21.88771| val_0_mse: 23.89139|  0:00:27s\n",
            "epoch 22 | loss: 22.43292| val_0_mse: 23.75309|  0:00:28s\n",
            "epoch 23 | loss: 22.44902| val_0_mse: 25.12445|  0:00:29s\n",
            "epoch 24 | loss: 22.30134| val_0_mse: 23.41368|  0:00:30s\n",
            "epoch 25 | loss: 21.87984| val_0_mse: 22.62062|  0:00:32s\n",
            "epoch 26 | loss: 22.4692 | val_0_mse: 23.09425|  0:00:33s\n",
            "epoch 27 | loss: 23.02968| val_0_mse: 22.8181 |  0:00:34s\n",
            "epoch 28 | loss: 21.3895 | val_0_mse: 23.70107|  0:00:35s\n",
            "epoch 29 | loss: 21.81694| val_0_mse: 22.84273|  0:00:37s\n",
            "epoch 30 | loss: 22.11599| val_0_mse: 23.45318|  0:00:38s\n",
            "epoch 31 | loss: 21.85163| val_0_mse: 23.98799|  0:00:39s\n",
            "epoch 32 | loss: 22.28642| val_0_mse: 24.09133|  0:00:40s\n",
            "epoch 33 | loss: 21.80844| val_0_mse: 24.34476|  0:00:41s\n",
            "epoch 34 | loss: 21.77379| val_0_mse: 22.97497|  0:00:43s\n",
            "epoch 35 | loss: 21.70132| val_0_mse: 23.75334|  0:00:44s\n",
            "epoch 36 | loss: 21.29007| val_0_mse: 23.0862 |  0:00:45s\n",
            "epoch 37 | loss: 21.45916| val_0_mse: 24.09668|  0:00:46s\n",
            "epoch 38 | loss: 22.09821| val_0_mse: 23.3045 |  0:00:48s\n",
            "epoch 39 | loss: 22.21179| val_0_mse: 23.44823|  0:00:49s\n",
            "epoch 40 | loss: 22.26476| val_0_mse: 24.21251|  0:00:50s\n",
            "epoch 41 | loss: 21.63994| val_0_mse: 24.27113|  0:00:51s\n",
            "epoch 42 | loss: 22.58393| val_0_mse: 24.40375|  0:00:53s\n",
            "epoch 43 | loss: 22.12407| val_0_mse: 23.12014|  0:00:54s\n",
            "epoch 44 | loss: 22.13119| val_0_mse: 24.20562|  0:00:55s\n",
            "epoch 45 | loss: 21.87683| val_0_mse: 23.80113|  0:00:56s\n",
            "\n",
            "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_mse = 22.62062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.4639\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 34.88445| val_0_mse: 27.2237 |  0:00:01s\n",
            "epoch 1  | loss: 27.86866| val_0_mse: 26.47856|  0:00:02s\n",
            "epoch 2  | loss: 27.1189 | val_0_mse: 25.74489|  0:00:03s\n",
            "epoch 3  | loss: 26.85215| val_0_mse: 26.20611|  0:00:04s\n",
            "epoch 4  | loss: 26.94997| val_0_mse: 25.60205|  0:00:06s\n",
            "epoch 5  | loss: 26.78073| val_0_mse: 24.95717|  0:00:07s\n",
            "epoch 6  | loss: 25.75469| val_0_mse: 26.06879|  0:00:08s\n",
            "epoch 7  | loss: 26.91394| val_0_mse: 27.75058|  0:00:09s\n",
            "epoch 8  | loss: 25.90447| val_0_mse: 25.0975 |  0:00:11s\n",
            "epoch 9  | loss: 26.08384| val_0_mse: 22.97331|  0:00:12s\n",
            "epoch 10 | loss: 24.64817| val_0_mse: 24.29346|  0:00:13s\n",
            "epoch 11 | loss: 24.8349 | val_0_mse: 23.00622|  0:00:14s\n",
            "epoch 12 | loss: 24.09317| val_0_mse: 25.72033|  0:00:16s\n",
            "epoch 13 | loss: 24.10377| val_0_mse: 25.24313|  0:00:17s\n",
            "epoch 14 | loss: 25.18012| val_0_mse: 24.62649|  0:00:18s\n",
            "epoch 15 | loss: 25.11612| val_0_mse: 23.90056|  0:00:19s\n",
            "epoch 16 | loss: 25.45332| val_0_mse: 26.43441|  0:00:20s\n",
            "epoch 17 | loss: 25.11836| val_0_mse: 24.29515|  0:00:22s\n",
            "epoch 18 | loss: 24.48245| val_0_mse: 25.4252 |  0:00:23s\n",
            "epoch 19 | loss: 25.51952| val_0_mse: 25.37914|  0:00:24s\n",
            "epoch 20 | loss: 24.61763| val_0_mse: 24.18805|  0:00:25s\n",
            "epoch 21 | loss: 24.60832| val_0_mse: 22.26661|  0:00:26s\n",
            "epoch 22 | loss: 23.32536| val_0_mse: 22.16252|  0:00:28s\n",
            "epoch 23 | loss: 23.17617| val_0_mse: 23.00652|  0:00:29s\n",
            "epoch 24 | loss: 23.51161| val_0_mse: 22.47484|  0:00:30s\n",
            "epoch 25 | loss: 23.22882| val_0_mse: 23.0428 |  0:00:31s\n",
            "epoch 26 | loss: 22.62641| val_0_mse: 21.74425|  0:00:33s\n",
            "epoch 27 | loss: 23.3595 | val_0_mse: 22.68824|  0:00:34s\n",
            "epoch 28 | loss: 23.08777| val_0_mse: 22.13671|  0:00:35s\n",
            "epoch 29 | loss: 23.10596| val_0_mse: 21.98902|  0:00:36s\n",
            "epoch 30 | loss: 22.79045| val_0_mse: 22.03856|  0:00:37s\n",
            "epoch 31 | loss: 22.88337| val_0_mse: 22.33182|  0:00:39s\n",
            "epoch 32 | loss: 22.54689| val_0_mse: 22.632  |  0:00:40s\n",
            "epoch 33 | loss: 23.30094| val_0_mse: 23.04162|  0:00:41s\n",
            "epoch 34 | loss: 23.01717| val_0_mse: 22.28865|  0:00:42s\n",
            "epoch 35 | loss: 22.44446| val_0_mse: 22.86303|  0:00:44s\n",
            "epoch 36 | loss: 22.69817| val_0_mse: 22.8964 |  0:00:45s\n",
            "epoch 37 | loss: 22.41687| val_0_mse: 22.19183|  0:00:46s\n",
            "epoch 38 | loss: 22.90842| val_0_mse: 22.22295|  0:00:47s\n",
            "epoch 39 | loss: 22.16952| val_0_mse: 22.40337|  0:00:48s\n",
            "epoch 40 | loss: 22.42717| val_0_mse: 22.31126|  0:00:50s\n",
            "epoch 41 | loss: 22.609  | val_0_mse: 22.61866|  0:00:51s\n",
            "epoch 42 | loss: 23.04796| val_0_mse: 22.60713|  0:00:52s\n",
            "epoch 43 | loss: 22.72963| val_0_mse: 21.45535|  0:00:53s\n",
            "epoch 44 | loss: 22.65324| val_0_mse: 21.90565|  0:00:55s\n",
            "epoch 45 | loss: 22.14184| val_0_mse: 21.67392|  0:00:56s\n",
            "epoch 46 | loss: 22.36235| val_0_mse: 21.7993 |  0:00:57s\n",
            "epoch 47 | loss: 21.87575| val_0_mse: 22.0514 |  0:00:58s\n",
            "epoch 48 | loss: 22.18046| val_0_mse: 22.45342|  0:01:00s\n",
            "epoch 49 | loss: 22.22663| val_0_mse: 22.54445|  0:01:01s\n",
            "epoch 50 | loss: 22.6037 | val_0_mse: 22.2298 |  0:01:02s\n",
            "epoch 51 | loss: 22.75853| val_0_mse: 22.10528|  0:01:03s\n",
            "epoch 52 | loss: 22.84015| val_0_mse: 22.49962|  0:01:04s\n",
            "epoch 53 | loss: 22.23945| val_0_mse: 22.32575|  0:01:06s\n",
            "epoch 54 | loss: 22.63693| val_0_mse: 22.14374|  0:01:07s\n",
            "epoch 55 | loss: 21.99475| val_0_mse: 21.93174|  0:01:08s\n",
            "epoch 56 | loss: 22.32105| val_0_mse: 22.10282|  0:01:09s\n",
            "epoch 57 | loss: 21.59706| val_0_mse: 21.66936|  0:01:11s\n",
            "epoch 58 | loss: 21.98841| val_0_mse: 21.90345|  0:01:12s\n",
            "epoch 59 | loss: 21.99845| val_0_mse: 22.57913|  0:01:13s\n",
            "epoch 60 | loss: 21.81933| val_0_mse: 21.86726|  0:01:14s\n",
            "epoch 61 | loss: 21.98596| val_0_mse: 21.29069|  0:01:15s\n",
            "epoch 62 | loss: 22.23382| val_0_mse: 21.72275|  0:01:17s\n",
            "epoch 63 | loss: 21.6758 | val_0_mse: 21.26262|  0:01:18s\n",
            "epoch 64 | loss: 21.72993| val_0_mse: 21.16261|  0:01:19s\n",
            "epoch 65 | loss: 21.30064| val_0_mse: 21.13075|  0:01:20s\n",
            "epoch 66 | loss: 22.06534| val_0_mse: 21.73361|  0:01:22s\n",
            "epoch 67 | loss: 21.78355| val_0_mse: 21.37883|  0:01:23s\n",
            "epoch 68 | loss: 21.56935| val_0_mse: 21.10019|  0:01:24s\n",
            "epoch 69 | loss: 20.9011 | val_0_mse: 20.98937|  0:01:25s\n",
            "epoch 70 | loss: 21.22018| val_0_mse: 20.72186|  0:01:27s\n",
            "epoch 71 | loss: 21.43363| val_0_mse: 21.01781|  0:01:28s\n",
            "epoch 72 | loss: 21.59131| val_0_mse: 20.84969|  0:01:29s\n",
            "epoch 73 | loss: 21.51894| val_0_mse: 21.01713|  0:01:30s\n",
            "epoch 74 | loss: 21.94223| val_0_mse: 20.98457|  0:01:32s\n",
            "epoch 75 | loss: 21.13549| val_0_mse: 21.0291 |  0:01:33s\n",
            "epoch 76 | loss: 21.14976| val_0_mse: 21.56149|  0:01:34s\n",
            "epoch 77 | loss: 20.73909| val_0_mse: 21.40017|  0:01:35s\n",
            "epoch 78 | loss: 20.55333| val_0_mse: 20.77383|  0:01:37s\n",
            "epoch 79 | loss: 20.82613| val_0_mse: 21.12866|  0:01:38s\n",
            "epoch 80 | loss: 21.501  | val_0_mse: 21.52489|  0:01:39s\n",
            "epoch 81 | loss: 21.10826| val_0_mse: 21.53987|  0:01:40s\n",
            "epoch 82 | loss: 21.07793| val_0_mse: 21.25692|  0:01:41s\n",
            "epoch 83 | loss: 20.44981| val_0_mse: 21.15799|  0:01:43s\n",
            "epoch 84 | loss: 20.52158| val_0_mse: 21.00019|  0:01:44s\n",
            "epoch 85 | loss: 20.24755| val_0_mse: 21.36387|  0:01:45s\n",
            "epoch 86 | loss: 20.64511| val_0_mse: 21.33879|  0:01:46s\n",
            "epoch 87 | loss: 20.70695| val_0_mse: 21.30317|  0:01:48s\n",
            "epoch 88 | loss: 20.94349| val_0_mse: 21.54854|  0:01:49s\n",
            "epoch 89 | loss: 20.99471| val_0_mse: 21.46569|  0:01:50s\n",
            "epoch 90 | loss: 20.07221| val_0_mse: 21.30397|  0:01:51s\n",
            "\n",
            "Early stopping occurred at epoch 90 with best_epoch = 70 and best_val_0_mse = 20.72186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-03-11 13:56:06,705] Trial 0 finished with value: 3.4190167586008706 and parameters: {'n_d': 40, 'n_a': 24, 'n_steps': 6, 'gamma': 1.2811295600659984, 'lambda_sparse': 0.00041863525891465647, 'momentum': 0.2605252766145581}. Best is trial 0 with value: 3.4190167586008706.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3489\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 35.90581| val_0_mse: 29.74692|  0:00:01s\n",
            "epoch 1  | loss: 27.98595| val_0_mse: 32.77154|  0:00:02s\n",
            "epoch 2  | loss: 26.85563| val_0_mse: 28.96668|  0:00:04s\n",
            "epoch 3  | loss: 27.65898| val_0_mse: 27.95531|  0:00:05s\n",
            "epoch 4  | loss: 26.38409| val_0_mse: 25.49607|  0:00:07s\n",
            "epoch 5  | loss: 25.0815 | val_0_mse: 28.56147|  0:00:08s\n",
            "epoch 6  | loss: 26.06309| val_0_mse: 25.82608|  0:00:09s\n",
            "epoch 7  | loss: 24.22289| val_0_mse: 24.23989|  0:00:11s\n",
            "epoch 8  | loss: 25.05475| val_0_mse: 24.95739|  0:00:12s\n",
            "epoch 9  | loss: 25.01749| val_0_mse: 26.02736|  0:00:14s\n",
            "epoch 10 | loss: 25.38421| val_0_mse: 24.85132|  0:00:15s\n",
            "epoch 11 | loss: 25.11833| val_0_mse: 23.73342|  0:00:16s\n",
            "epoch 12 | loss: 23.87805| val_0_mse: 23.27791|  0:00:18s\n",
            "epoch 13 | loss: 23.77394| val_0_mse: 23.15246|  0:00:19s\n",
            "epoch 14 | loss: 23.78859| val_0_mse: 24.46262|  0:00:21s\n",
            "epoch 15 | loss: 23.35817| val_0_mse: 25.40512|  0:00:22s\n",
            "epoch 16 | loss: 23.1652 | val_0_mse: 24.85635|  0:00:24s\n",
            "epoch 17 | loss: 24.60657| val_0_mse: 24.57707|  0:00:25s\n",
            "epoch 18 | loss: 23.51491| val_0_mse: 24.27145|  0:00:26s\n",
            "epoch 19 | loss: 22.91115| val_0_mse: 24.06974|  0:00:28s\n",
            "epoch 20 | loss: 22.71041| val_0_mse: 23.45118|  0:00:29s\n",
            "epoch 21 | loss: 23.53113| val_0_mse: 23.82448|  0:00:31s\n",
            "epoch 22 | loss: 22.98267| val_0_mse: 23.10316|  0:00:32s\n",
            "epoch 23 | loss: 22.40432| val_0_mse: 24.3455 |  0:00:33s\n",
            "epoch 24 | loss: 23.02066| val_0_mse: 24.94455|  0:00:35s\n",
            "epoch 25 | loss: 22.65668| val_0_mse: 23.20284|  0:00:36s\n",
            "epoch 26 | loss: 22.82498| val_0_mse: 24.16015|  0:00:38s\n",
            "epoch 27 | loss: 22.74645| val_0_mse: 22.218  |  0:00:39s\n",
            "epoch 28 | loss: 22.27884| val_0_mse: 23.21334|  0:00:41s\n",
            "epoch 29 | loss: 22.69731| val_0_mse: 22.80059|  0:00:42s\n",
            "epoch 30 | loss: 22.16583| val_0_mse: 22.44487|  0:00:43s\n",
            "epoch 31 | loss: 22.53161| val_0_mse: 22.49817|  0:00:45s\n",
            "epoch 32 | loss: 22.46362| val_0_mse: 22.02207|  0:00:46s\n",
            "epoch 33 | loss: 22.31004| val_0_mse: 23.12718|  0:00:48s\n",
            "epoch 34 | loss: 21.95096| val_0_mse: 22.54909|  0:00:49s\n",
            "epoch 35 | loss: 22.29417| val_0_mse: 26.13171|  0:00:51s\n",
            "epoch 36 | loss: 23.11103| val_0_mse: 22.85843|  0:00:52s\n",
            "epoch 37 | loss: 22.38877| val_0_mse: 22.58077|  0:00:53s\n",
            "epoch 38 | loss: 22.31968| val_0_mse: 22.19078|  0:00:55s\n",
            "epoch 39 | loss: 23.42319| val_0_mse: 22.88498|  0:00:56s\n",
            "epoch 40 | loss: 22.08114| val_0_mse: 22.73441|  0:00:58s\n",
            "epoch 41 | loss: 22.90407| val_0_mse: 22.42623|  0:00:59s\n",
            "epoch 42 | loss: 21.65845| val_0_mse: 21.60971|  0:01:00s\n",
            "epoch 43 | loss: 22.21933| val_0_mse: 21.60511|  0:01:02s\n",
            "epoch 44 | loss: 21.99973| val_0_mse: 21.72816|  0:01:03s\n",
            "epoch 45 | loss: 21.90845| val_0_mse: 21.96103|  0:01:05s\n",
            "epoch 46 | loss: 21.83058| val_0_mse: 21.81874|  0:01:06s\n",
            "epoch 47 | loss: 21.33047| val_0_mse: 22.28907|  0:01:07s\n",
            "epoch 48 | loss: 21.30718| val_0_mse: 21.92212|  0:01:09s\n",
            "epoch 49 | loss: 21.46144| val_0_mse: 22.35842|  0:01:10s\n",
            "epoch 50 | loss: 21.94903| val_0_mse: 22.51847|  0:01:12s\n",
            "epoch 51 | loss: 21.66891| val_0_mse: 22.11035|  0:01:13s\n",
            "epoch 52 | loss: 21.97803| val_0_mse: 24.00437|  0:01:15s\n",
            "epoch 53 | loss: 21.61762| val_0_mse: 22.45714|  0:01:16s\n",
            "epoch 54 | loss: 21.23569| val_0_mse: 22.21942|  0:01:17s\n",
            "epoch 55 | loss: 21.1508 | val_0_mse: 22.42563|  0:01:19s\n",
            "epoch 56 | loss: 20.94335| val_0_mse: 21.98452|  0:01:20s\n",
            "epoch 57 | loss: 21.40073| val_0_mse: 23.53936|  0:01:21s\n",
            "epoch 58 | loss: 21.65318| val_0_mse: 24.58439|  0:01:23s\n",
            "epoch 59 | loss: 22.58887| val_0_mse: 23.90871|  0:01:24s\n",
            "epoch 60 | loss: 22.82217| val_0_mse: 23.22635|  0:01:26s\n",
            "epoch 61 | loss: 22.28763| val_0_mse: 23.20705|  0:01:27s\n",
            "epoch 62 | loss: 22.4756 | val_0_mse: 23.5909 |  0:01:28s\n",
            "epoch 63 | loss: 22.24567| val_0_mse: 22.8888 |  0:01:30s\n",
            "\n",
            "Early stopping occurred at epoch 63 with best_epoch = 43 and best_val_0_mse = 21.60511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.2862\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 33.97466| val_0_mse: 30.57967|  0:00:01s\n",
            "epoch 1  | loss: 28.90901| val_0_mse: 27.85566|  0:00:02s\n",
            "epoch 2  | loss: 28.26496| val_0_mse: 26.98026|  0:00:04s\n",
            "epoch 3  | loss: 26.55556| val_0_mse: 26.00631|  0:00:05s\n",
            "epoch 4  | loss: 27.11915| val_0_mse: 25.41257|  0:00:07s\n",
            "epoch 5  | loss: 26.59086| val_0_mse: 26.64897|  0:00:08s\n",
            "epoch 6  | loss: 25.69728| val_0_mse: 25.69575|  0:00:09s\n",
            "epoch 7  | loss: 26.35204| val_0_mse: 25.90159|  0:00:11s\n",
            "epoch 8  | loss: 26.5109 | val_0_mse: 26.48006|  0:00:12s\n",
            "epoch 9  | loss: 26.14747| val_0_mse: 26.78135|  0:00:14s\n",
            "epoch 10 | loss: 26.30059| val_0_mse: 25.00199|  0:00:15s\n",
            "epoch 11 | loss: 26.5148 | val_0_mse: 25.61065|  0:00:16s\n",
            "epoch 12 | loss: 26.0899 | val_0_mse: 25.28761|  0:00:18s\n",
            "epoch 13 | loss: 24.71838| val_0_mse: 25.11996|  0:00:19s\n",
            "epoch 14 | loss: 24.66426| val_0_mse: 25.69763|  0:00:21s\n",
            "epoch 15 | loss: 24.64421| val_0_mse: 24.94661|  0:00:22s\n",
            "epoch 16 | loss: 24.36414| val_0_mse: 25.57818|  0:00:23s\n",
            "epoch 17 | loss: 24.08543| val_0_mse: 23.88575|  0:00:25s\n",
            "epoch 18 | loss: 23.95103| val_0_mse: 24.95438|  0:00:26s\n",
            "epoch 19 | loss: 23.81823| val_0_mse: 24.95064|  0:00:28s\n",
            "epoch 20 | loss: 23.81323| val_0_mse: 24.16636|  0:00:29s\n",
            "epoch 21 | loss: 23.53264| val_0_mse: 23.44473|  0:00:30s\n",
            "epoch 22 | loss: 23.82862| val_0_mse: 23.70674|  0:00:32s\n",
            "epoch 23 | loss: 23.68485| val_0_mse: 23.28041|  0:00:33s\n",
            "epoch 24 | loss: 23.87121| val_0_mse: 24.27616|  0:00:35s\n",
            "epoch 25 | loss: 23.94791| val_0_mse: 23.54039|  0:00:36s\n",
            "epoch 26 | loss: 23.28233| val_0_mse: 23.57151|  0:00:37s\n",
            "epoch 27 | loss: 22.64858| val_0_mse: 23.79212|  0:00:39s\n",
            "epoch 28 | loss: 23.11007| val_0_mse: 25.13217|  0:00:40s\n",
            "epoch 29 | loss: 22.53915| val_0_mse: 24.06417|  0:00:42s\n",
            "epoch 30 | loss: 22.88781| val_0_mse: 24.13643|  0:00:43s\n",
            "epoch 31 | loss: 22.30037| val_0_mse: 24.47935|  0:00:44s\n",
            "epoch 32 | loss: 21.95287| val_0_mse: 24.4345 |  0:00:46s\n",
            "epoch 33 | loss: 21.74927| val_0_mse: 24.19432|  0:00:47s\n",
            "epoch 34 | loss: 21.67417| val_0_mse: 24.34161|  0:00:49s\n",
            "epoch 35 | loss: 21.97472| val_0_mse: 23.20125|  0:00:50s\n",
            "epoch 36 | loss: 22.44987| val_0_mse: 23.65922|  0:00:51s\n",
            "epoch 37 | loss: 22.36757| val_0_mse: 23.81458|  0:00:53s\n",
            "epoch 38 | loss: 22.3942 | val_0_mse: 23.83704|  0:00:54s\n",
            "epoch 39 | loss: 21.60992| val_0_mse: 23.95891|  0:00:56s\n",
            "epoch 40 | loss: 21.59599| val_0_mse: 23.84455|  0:00:57s\n",
            "epoch 41 | loss: 21.30098| val_0_mse: 23.07899|  0:00:58s\n",
            "epoch 42 | loss: 20.92452| val_0_mse: 23.57078|  0:01:00s\n",
            "epoch 43 | loss: 20.59038| val_0_mse: 24.13572|  0:01:01s\n",
            "epoch 44 | loss: 21.20836| val_0_mse: 22.94328|  0:01:03s\n",
            "epoch 45 | loss: 22.00645| val_0_mse: 23.14993|  0:01:04s\n",
            "epoch 46 | loss: 21.62176| val_0_mse: 23.25323|  0:01:05s\n",
            "epoch 47 | loss: 21.65263| val_0_mse: 22.86278|  0:01:07s\n",
            "epoch 48 | loss: 21.45319| val_0_mse: 22.94913|  0:01:08s\n",
            "epoch 49 | loss: 20.96787| val_0_mse: 22.8869 |  0:01:10s\n",
            "epoch 50 | loss: 20.85439| val_0_mse: 23.18127|  0:01:11s\n",
            "epoch 51 | loss: 21.91959| val_0_mse: 23.91048|  0:01:12s\n",
            "epoch 52 | loss: 20.84897| val_0_mse: 22.74688|  0:01:14s\n",
            "epoch 53 | loss: 21.1171 | val_0_mse: 23.8722 |  0:01:15s\n",
            "epoch 54 | loss: 20.88776| val_0_mse: 23.11323|  0:01:16s\n",
            "epoch 55 | loss: 21.17997| val_0_mse: 23.02773|  0:01:18s\n",
            "epoch 56 | loss: 20.78592| val_0_mse: 23.08854|  0:01:19s\n",
            "epoch 57 | loss: 20.52434| val_0_mse: 22.75743|  0:01:21s\n",
            "epoch 58 | loss: 21.05716| val_0_mse: 23.54561|  0:01:22s\n",
            "epoch 59 | loss: 20.53159| val_0_mse: 23.58609|  0:01:23s\n",
            "epoch 60 | loss: 20.4957 | val_0_mse: 22.88098|  0:01:25s\n",
            "epoch 61 | loss: 20.49927| val_0_mse: 23.20411|  0:01:26s\n",
            "epoch 62 | loss: 20.68924| val_0_mse: 22.73301|  0:01:28s\n",
            "epoch 63 | loss: 20.75075| val_0_mse: 22.82154|  0:01:29s\n",
            "epoch 64 | loss: 20.7786 | val_0_mse: 23.36258|  0:01:30s\n",
            "epoch 65 | loss: 21.02284| val_0_mse: 23.57508|  0:01:32s\n",
            "epoch 66 | loss: 20.24522| val_0_mse: 23.74902|  0:01:33s\n",
            "epoch 67 | loss: 20.57508| val_0_mse: 23.31744|  0:01:35s\n",
            "epoch 68 | loss: 20.64884| val_0_mse: 23.49646|  0:01:36s\n",
            "epoch 69 | loss: 20.32295| val_0_mse: 23.59731|  0:01:38s\n",
            "epoch 70 | loss: 19.68488| val_0_mse: 23.89427|  0:01:39s\n",
            "epoch 71 | loss: 19.54894| val_0_mse: 23.18139|  0:01:40s\n",
            "epoch 72 | loss: 19.91665| val_0_mse: 23.65873|  0:01:42s\n",
            "epoch 73 | loss: 19.51731| val_0_mse: 23.35296|  0:01:43s\n",
            "epoch 74 | loss: 19.25288| val_0_mse: 23.31911|  0:01:45s\n",
            "epoch 75 | loss: 19.22423| val_0_mse: 22.75828|  0:01:46s\n",
            "epoch 76 | loss: 19.07045| val_0_mse: 23.1001 |  0:01:47s\n",
            "epoch 77 | loss: 19.2025 | val_0_mse: 23.89941|  0:01:49s\n",
            "epoch 78 | loss: 18.76897| val_0_mse: 22.99027|  0:01:50s\n",
            "epoch 79 | loss: 18.76906| val_0_mse: 23.61864|  0:01:51s\n",
            "epoch 80 | loss: 18.69291| val_0_mse: 22.95326|  0:01:53s\n",
            "epoch 81 | loss: 18.27462| val_0_mse: 24.41663|  0:01:54s\n",
            "epoch 82 | loss: 18.47687| val_0_mse: 23.10974|  0:01:56s\n",
            "\n",
            "Early stopping occurred at epoch 82 with best_epoch = 62 and best_val_0_mse = 22.73301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.4267\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 37.36225| val_0_mse: 32.53722|  0:00:01s\n",
            "epoch 1  | loss: 29.21261| val_0_mse: 28.30908|  0:00:02s\n",
            "epoch 2  | loss: 27.04521| val_0_mse: 26.56868|  0:00:04s\n",
            "epoch 3  | loss: 27.35443| val_0_mse: 26.30419|  0:00:05s\n",
            "epoch 4  | loss: 27.78962| val_0_mse: 25.13286|  0:00:06s\n",
            "epoch 5  | loss: 34.66503| val_0_mse: 29.53809|  0:00:08s\n",
            "epoch 6  | loss: 28.54756| val_0_mse: 26.04079|  0:00:09s\n",
            "epoch 7  | loss: 25.83798| val_0_mse: 24.22595|  0:00:11s\n",
            "epoch 8  | loss: 26.02062| val_0_mse: 24.36502|  0:00:12s\n",
            "epoch 9  | loss: 25.42452| val_0_mse: 25.13346|  0:00:14s\n",
            "epoch 10 | loss: 26.23024| val_0_mse: 23.76187|  0:00:15s\n",
            "epoch 11 | loss: 25.00357| val_0_mse: 23.62053|  0:00:16s\n",
            "epoch 12 | loss: 24.74592| val_0_mse: 24.08061|  0:00:18s\n",
            "epoch 13 | loss: 24.35127| val_0_mse: 22.64741|  0:00:19s\n",
            "epoch 14 | loss: 23.35395| val_0_mse: 25.10043|  0:00:20s\n",
            "epoch 15 | loss: 23.60279| val_0_mse: 22.94308|  0:00:22s\n",
            "epoch 16 | loss: 24.03942| val_0_mse: 23.73272|  0:00:23s\n",
            "epoch 17 | loss: 23.99549| val_0_mse: 23.62692|  0:00:25s\n",
            "epoch 18 | loss: 23.61855| val_0_mse: 23.20419|  0:00:26s\n",
            "epoch 19 | loss: 23.02009| val_0_mse: 23.24562|  0:00:28s\n",
            "epoch 20 | loss: 23.22808| val_0_mse: 23.6501 |  0:00:29s\n",
            "epoch 21 | loss: 23.00818| val_0_mse: 22.1085 |  0:00:30s\n",
            "epoch 22 | loss: 23.72632| val_0_mse: 22.48793|  0:00:32s\n",
            "epoch 23 | loss: 23.59758| val_0_mse: 22.72521|  0:00:33s\n",
            "epoch 24 | loss: 23.23358| val_0_mse: 21.72117|  0:00:35s\n",
            "epoch 25 | loss: 23.09071| val_0_mse: 22.61279|  0:00:36s\n",
            "epoch 26 | loss: 22.58166| val_0_mse: 22.61343|  0:00:37s\n",
            "epoch 27 | loss: 23.33858| val_0_mse: 23.312  |  0:00:39s\n",
            "epoch 28 | loss: 23.43857| val_0_mse: 23.27826|  0:00:40s\n",
            "epoch 29 | loss: 23.33329| val_0_mse: 23.24805|  0:00:42s\n",
            "epoch 30 | loss: 22.87188| val_0_mse: 24.77114|  0:00:43s\n",
            "epoch 31 | loss: 23.02976| val_0_mse: 22.54093|  0:00:44s\n",
            "epoch 32 | loss: 22.89938| val_0_mse: 21.25555|  0:00:46s\n",
            "epoch 33 | loss: 22.86385| val_0_mse: 21.75522|  0:00:47s\n",
            "epoch 34 | loss: 22.93251| val_0_mse: 23.47768|  0:00:49s\n",
            "epoch 35 | loss: 22.75695| val_0_mse: 22.45837|  0:00:50s\n",
            "epoch 36 | loss: 23.3671 | val_0_mse: 22.79109|  0:00:52s\n",
            "epoch 37 | loss: 23.54494| val_0_mse: 22.73741|  0:00:53s\n",
            "epoch 38 | loss: 22.9472 | val_0_mse: 22.66668|  0:00:54s\n",
            "epoch 39 | loss: 23.03008| val_0_mse: 22.70006|  0:00:56s\n",
            "epoch 40 | loss: 23.02416| val_0_mse: 21.84154|  0:00:57s\n",
            "epoch 41 | loss: 23.40074| val_0_mse: 22.38955|  0:00:58s\n",
            "epoch 42 | loss: 23.17594| val_0_mse: 22.45506|  0:01:00s\n",
            "epoch 43 | loss: 22.88676| val_0_mse: 21.93517|  0:01:01s\n",
            "epoch 44 | loss: 22.50669| val_0_mse: 21.7921 |  0:01:03s\n",
            "epoch 45 | loss: 23.16048| val_0_mse: 21.2535 |  0:01:04s\n",
            "epoch 46 | loss: 22.78042| val_0_mse: 21.53155|  0:01:06s\n",
            "epoch 47 | loss: 22.61692| val_0_mse: 22.15696|  0:01:07s\n",
            "epoch 48 | loss: 22.98553| val_0_mse: 21.7464 |  0:01:08s\n",
            "epoch 49 | loss: 23.18818| val_0_mse: 23.79847|  0:01:10s\n",
            "epoch 50 | loss: 23.93198| val_0_mse: 22.15749|  0:01:11s\n",
            "epoch 51 | loss: 23.0867 | val_0_mse: 22.48043|  0:01:13s\n",
            "epoch 52 | loss: 22.32606| val_0_mse: 21.89255|  0:01:14s\n",
            "epoch 53 | loss: 22.97198| val_0_mse: 21.93242|  0:01:15s\n",
            "epoch 54 | loss: 22.0218 | val_0_mse: 21.75573|  0:01:17s\n",
            "epoch 55 | loss: 22.82326| val_0_mse: 22.17082|  0:01:18s\n",
            "epoch 56 | loss: 22.09245| val_0_mse: 22.11462|  0:01:20s\n",
            "epoch 57 | loss: 22.23106| val_0_mse: 22.47298|  0:01:21s\n",
            "epoch 58 | loss: 22.30578| val_0_mse: 22.10629|  0:01:22s\n",
            "epoch 59 | loss: 21.50043| val_0_mse: 21.72721|  0:01:24s\n",
            "epoch 60 | loss: 21.63203| val_0_mse: 22.31577|  0:01:25s\n",
            "epoch 61 | loss: 22.25721| val_0_mse: 21.94609|  0:01:27s\n",
            "epoch 62 | loss: 21.86518| val_0_mse: 21.98945|  0:01:28s\n",
            "epoch 63 | loss: 21.53715| val_0_mse: 22.76243|  0:01:29s\n",
            "epoch 64 | loss: 21.98285| val_0_mse: 22.23411|  0:01:31s\n",
            "epoch 65 | loss: 21.74766| val_0_mse: 21.89831|  0:01:32s\n",
            "\n",
            "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_mse = 21.2535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-03-11 14:01:08,238] Trial 1 finished with value: 3.350657304128011 and parameters: {'n_d': 48, 'n_a': 32, 'n_steps': 7, 'gamma': 1.2749114062446103, 'lambda_sparse': 0.0006455290121945874, 'momentum': 0.10524942688819135}. Best is trial 1 with value: 3.350657304128011.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3391\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 36.60548| val_0_mse: 35.68745|  0:00:02s\n",
            "epoch 1  | loss: 29.89969| val_0_mse: 36.23439|  0:00:04s\n",
            "epoch 2  | loss: 37.82999| val_0_mse: 40.47165|  0:00:05s\n",
            "epoch 3  | loss: 29.20442| val_0_mse: 32.75875|  0:00:07s\n",
            "epoch 4  | loss: 31.4581 | val_0_mse: 31.25049|  0:00:09s\n",
            "epoch 5  | loss: 27.15234| val_0_mse: 30.11667|  0:00:11s\n",
            "epoch 6  | loss: 28.88459| val_0_mse: 42.42859|  0:00:13s\n",
            "epoch 7  | loss: 28.73522| val_0_mse: 27.65895|  0:00:15s\n",
            "epoch 8  | loss: 26.16911| val_0_mse: 29.19566|  0:00:17s\n",
            "epoch 9  | loss: 26.85438| val_0_mse: 25.40349|  0:00:19s\n",
            "epoch 10 | loss: 29.04124| val_0_mse: 26.47675|  0:00:21s\n",
            "epoch 11 | loss: 25.36112| val_0_mse: 24.92662|  0:00:23s\n",
            "epoch 12 | loss: 26.1084 | val_0_mse: 26.0067 |  0:00:25s\n",
            "epoch 13 | loss: 25.35905| val_0_mse: 25.52191|  0:00:26s\n",
            "epoch 14 | loss: 24.92797| val_0_mse: 26.42073|  0:00:28s\n",
            "epoch 15 | loss: 24.43686| val_0_mse: 24.20909|  0:00:30s\n",
            "epoch 16 | loss: 23.65287| val_0_mse: 25.41474|  0:00:32s\n",
            "epoch 17 | loss: 24.70115| val_0_mse: 23.42259|  0:00:34s\n",
            "epoch 18 | loss: 23.9549 | val_0_mse: 22.75046|  0:00:36s\n",
            "epoch 19 | loss: 22.75113| val_0_mse: 22.70664|  0:00:38s\n",
            "epoch 20 | loss: 22.9242 | val_0_mse: 22.58461|  0:00:40s\n",
            "epoch 21 | loss: 22.98025| val_0_mse: 22.65547|  0:00:42s\n",
            "epoch 22 | loss: 22.24057| val_0_mse: 23.29465|  0:00:44s\n",
            "epoch 23 | loss: 22.9647 | val_0_mse: 22.78474|  0:00:46s\n",
            "epoch 24 | loss: 22.55096| val_0_mse: 23.12792|  0:00:48s\n",
            "epoch 25 | loss: 22.38213| val_0_mse: 22.13964|  0:00:49s\n",
            "epoch 26 | loss: 21.75842| val_0_mse: 21.51027|  0:00:51s\n",
            "epoch 27 | loss: 22.04532| val_0_mse: 22.71044|  0:00:53s\n",
            "epoch 28 | loss: 21.76745| val_0_mse: 21.85523|  0:00:55s\n",
            "epoch 29 | loss: 21.97757| val_0_mse: 22.98104|  0:00:57s\n",
            "epoch 30 | loss: 21.79025| val_0_mse: 22.16563|  0:00:59s\n",
            "epoch 31 | loss: 21.80962| val_0_mse: 22.23125|  0:01:01s\n",
            "epoch 32 | loss: 22.07349| val_0_mse: 21.91514|  0:01:03s\n",
            "epoch 33 | loss: 21.63558| val_0_mse: 22.54222|  0:01:05s\n",
            "epoch 34 | loss: 21.70534| val_0_mse: 22.04568|  0:01:07s\n",
            "epoch 35 | loss: 21.54848| val_0_mse: 21.88593|  0:01:09s\n",
            "epoch 36 | loss: 21.51841| val_0_mse: 21.98133|  0:01:10s\n",
            "epoch 37 | loss: 21.02009| val_0_mse: 22.46544|  0:01:12s\n",
            "epoch 38 | loss: 21.113  | val_0_mse: 23.16704|  0:01:14s\n",
            "epoch 39 | loss: 21.55583| val_0_mse: 21.89825|  0:01:16s\n",
            "epoch 40 | loss: 21.53715| val_0_mse: 21.8354 |  0:01:18s\n",
            "epoch 41 | loss: 21.3083 | val_0_mse: 22.98753|  0:01:20s\n",
            "epoch 42 | loss: 21.54577| val_0_mse: 21.88538|  0:01:22s\n",
            "epoch 43 | loss: 20.83629| val_0_mse: 22.33746|  0:01:24s\n",
            "epoch 44 | loss: 21.01645| val_0_mse: 22.51034|  0:01:26s\n",
            "epoch 45 | loss: 21.54246| val_0_mse: 21.77617|  0:01:28s\n",
            "epoch 46 | loss: 20.5732 | val_0_mse: 21.95603|  0:01:29s\n",
            "\n",
            "Early stopping occurred at epoch 46 with best_epoch = 26 and best_val_0_mse = 21.51027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.3231\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 35.41124| val_0_mse: 32.58401|  0:00:01s\n",
            "epoch 1  | loss: 31.74314| val_0_mse: 38.64708|  0:00:03s\n",
            "epoch 2  | loss: 32.65805| val_0_mse: 28.95559|  0:00:05s\n",
            "epoch 3  | loss: 34.67401| val_0_mse: 26.34567|  0:00:07s\n",
            "epoch 4  | loss: 31.60183| val_0_mse: 27.78735|  0:00:09s\n",
            "epoch 5  | loss: 28.1649 | val_0_mse: 26.85759|  0:00:11s\n",
            "epoch 6  | loss: 26.73329| val_0_mse: 26.28663|  0:00:13s\n",
            "epoch 7  | loss: 26.52451| val_0_mse: 26.55018|  0:00:15s\n",
            "epoch 8  | loss: 25.3559 | val_0_mse: 25.75718|  0:00:17s\n",
            "epoch 9  | loss: 25.82135| val_0_mse: 25.39411|  0:00:19s\n",
            "epoch 10 | loss: 27.83946| val_0_mse: 28.09564|  0:00:21s\n",
            "epoch 11 | loss: 29.55183| val_0_mse: 29.85159|  0:00:23s\n",
            "epoch 12 | loss: 28.16927| val_0_mse: 25.74401|  0:00:24s\n",
            "epoch 13 | loss: 25.7912 | val_0_mse: 24.47679|  0:00:26s\n",
            "epoch 14 | loss: 24.3892 | val_0_mse: 24.31414|  0:00:28s\n",
            "epoch 15 | loss: 24.28084| val_0_mse: 24.9769 |  0:00:30s\n",
            "epoch 16 | loss: 24.39719| val_0_mse: 25.31659|  0:00:32s\n",
            "epoch 17 | loss: 24.96674| val_0_mse: 23.3579 |  0:00:34s\n",
            "epoch 18 | loss: 23.55884| val_0_mse: 23.07346|  0:00:36s\n",
            "epoch 19 | loss: 23.1271 | val_0_mse: 23.58821|  0:00:38s\n",
            "epoch 20 | loss: 22.72724| val_0_mse: 22.46582|  0:00:40s\n",
            "epoch 21 | loss: 22.55378| val_0_mse: 22.69397|  0:00:42s\n",
            "epoch 22 | loss: 21.84778| val_0_mse: 22.76409|  0:00:44s\n",
            "epoch 23 | loss: 22.68797| val_0_mse: 23.45664|  0:00:45s\n",
            "epoch 24 | loss: 22.41456| val_0_mse: 24.11648|  0:00:47s\n",
            "epoch 25 | loss: 22.20254| val_0_mse: 23.81027|  0:00:49s\n",
            "epoch 26 | loss: 22.00181| val_0_mse: 22.66915|  0:00:51s\n",
            "epoch 27 | loss: 21.95542| val_0_mse: 23.05698|  0:00:53s\n",
            "epoch 28 | loss: 22.10488| val_0_mse: 22.09993|  0:00:55s\n",
            "epoch 29 | loss: 22.84134| val_0_mse: 23.17642|  0:00:57s\n",
            "epoch 30 | loss: 21.80721| val_0_mse: 22.50387|  0:00:59s\n",
            "epoch 31 | loss: 21.72615| val_0_mse: 22.20718|  0:01:01s\n",
            "epoch 32 | loss: 21.9305 | val_0_mse: 22.92287|  0:01:03s\n",
            "epoch 33 | loss: 21.98308| val_0_mse: 22.847  |  0:01:04s\n",
            "epoch 34 | loss: 21.8323 | val_0_mse: 23.82005|  0:01:06s\n",
            "epoch 35 | loss: 21.88411| val_0_mse: 24.14372|  0:01:08s\n",
            "epoch 36 | loss: 22.26238| val_0_mse: 22.81012|  0:01:10s\n",
            "epoch 37 | loss: 21.46891| val_0_mse: 23.04444|  0:01:12s\n",
            "epoch 38 | loss: 21.40967| val_0_mse: 22.58901|  0:01:14s\n",
            "epoch 39 | loss: 21.31974| val_0_mse: 22.33898|  0:01:16s\n",
            "epoch 40 | loss: 21.05875| val_0_mse: 23.13733|  0:01:18s\n",
            "epoch 41 | loss: 21.46767| val_0_mse: 22.60217|  0:01:20s\n",
            "epoch 42 | loss: 21.0557 | val_0_mse: 24.12324|  0:01:22s\n",
            "epoch 43 | loss: 21.07807| val_0_mse: 22.60183|  0:01:24s\n",
            "epoch 44 | loss: 21.21982| val_0_mse: 22.93779|  0:01:25s\n",
            "epoch 45 | loss: 21.46689| val_0_mse: 22.07567|  0:01:27s\n",
            "epoch 46 | loss: 21.29103| val_0_mse: 22.34406|  0:01:29s\n",
            "epoch 47 | loss: 21.46614| val_0_mse: 22.64795|  0:01:31s\n",
            "epoch 48 | loss: 20.26703| val_0_mse: 23.00426|  0:01:33s\n",
            "epoch 49 | loss: 20.49773| val_0_mse: 23.50509|  0:01:35s\n",
            "epoch 50 | loss: 20.50072| val_0_mse: 23.08707|  0:01:37s\n",
            "epoch 51 | loss: 20.96845| val_0_mse: 22.76663|  0:01:39s\n",
            "epoch 52 | loss: 20.45561| val_0_mse: 22.75854|  0:01:41s\n",
            "epoch 53 | loss: 20.84631| val_0_mse: 22.87424|  0:01:42s\n",
            "epoch 54 | loss: 20.81501| val_0_mse: 23.01277|  0:01:44s\n",
            "epoch 55 | loss: 20.27333| val_0_mse: 24.24007|  0:01:46s\n",
            "epoch 56 | loss: 20.32059| val_0_mse: 22.96729|  0:01:48s\n",
            "epoch 57 | loss: 19.91811| val_0_mse: 23.73407|  0:01:50s\n",
            "epoch 58 | loss: 20.58672| val_0_mse: 23.51566|  0:01:52s\n",
            "epoch 59 | loss: 20.44416| val_0_mse: 22.85645|  0:01:54s\n",
            "epoch 60 | loss: 20.43289| val_0_mse: 23.64181|  0:01:56s\n",
            "epoch 61 | loss: 20.23248| val_0_mse: 23.7102 |  0:01:58s\n",
            "epoch 62 | loss: 19.14664| val_0_mse: 23.69209|  0:02:00s\n",
            "epoch 63 | loss: 20.00032| val_0_mse: 23.89596|  0:02:02s\n",
            "epoch 64 | loss: 20.00855| val_0_mse: 22.95477|  0:02:03s\n",
            "epoch 65 | loss: 19.88061| val_0_mse: 24.71039|  0:02:05s\n",
            "\n",
            "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_mse = 22.07567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.4197\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 34.9316 | val_0_mse: 29.4535 |  0:00:01s\n",
            "epoch 1  | loss: 31.94224| val_0_mse: 30.27988|  0:00:03s\n",
            "epoch 2  | loss: 30.90433| val_0_mse: 44.50578|  0:00:05s\n",
            "epoch 3  | loss: 30.40971| val_0_mse: 28.70472|  0:00:07s\n",
            "epoch 4  | loss: 28.83012| val_0_mse: 34.37365|  0:00:09s\n",
            "epoch 5  | loss: 27.77532| val_0_mse: 25.7708 |  0:00:11s\n",
            "epoch 6  | loss: 27.89802| val_0_mse: 26.20138|  0:00:13s\n",
            "epoch 7  | loss: 36.01401| val_0_mse: 55.56945|  0:00:15s\n",
            "epoch 8  | loss: 47.51725| val_0_mse: 32.50219|  0:00:17s\n",
            "epoch 9  | loss: 29.25994| val_0_mse: 36.77407|  0:00:19s\n",
            "epoch 10 | loss: 28.2742 | val_0_mse: 26.20499|  0:00:21s\n",
            "epoch 11 | loss: 26.85314| val_0_mse: 26.00732|  0:00:22s\n",
            "epoch 12 | loss: 25.73801| val_0_mse: 25.49043|  0:00:24s\n",
            "epoch 13 | loss: 25.6366 | val_0_mse: 27.74427|  0:00:26s\n",
            "epoch 14 | loss: 26.12271| val_0_mse: 23.93917|  0:00:28s\n",
            "epoch 15 | loss: 24.67974| val_0_mse: 24.84959|  0:00:30s\n",
            "epoch 16 | loss: 25.12973| val_0_mse: 24.44361|  0:00:32s\n",
            "epoch 17 | loss: 25.05692| val_0_mse: 24.21126|  0:00:34s\n",
            "epoch 18 | loss: 25.73498| val_0_mse: 23.38791|  0:00:36s\n",
            "epoch 19 | loss: 25.36496| val_0_mse: 24.17243|  0:00:38s\n",
            "epoch 20 | loss: 25.27734| val_0_mse: 23.85013|  0:00:40s\n",
            "epoch 21 | loss: 25.46552| val_0_mse: 25.71353|  0:00:42s\n",
            "epoch 22 | loss: 25.46604| val_0_mse: 25.05357|  0:00:44s\n",
            "epoch 23 | loss: 25.33191| val_0_mse: 23.03425|  0:00:45s\n",
            "epoch 24 | loss: 23.69845| val_0_mse: 22.73135|  0:00:47s\n",
            "epoch 25 | loss: 23.58773| val_0_mse: 22.66492|  0:00:49s\n",
            "epoch 26 | loss: 23.49081| val_0_mse: 22.66327|  0:00:51s\n",
            "epoch 27 | loss: 24.47658| val_0_mse: 22.93236|  0:00:53s\n",
            "epoch 28 | loss: 23.3688 | val_0_mse: 24.1471 |  0:00:55s\n",
            "epoch 29 | loss: 23.76807| val_0_mse: 21.8561 |  0:00:57s\n",
            "epoch 30 | loss: 23.4125 | val_0_mse: 21.701  |  0:00:59s\n",
            "epoch 31 | loss: 23.33123| val_0_mse: 22.75521|  0:01:01s\n",
            "epoch 32 | loss: 24.32856| val_0_mse: 22.51955|  0:01:03s\n",
            "epoch 33 | loss: 24.26629| val_0_mse: 22.97367|  0:01:05s\n",
            "epoch 34 | loss: 24.32689| val_0_mse: 24.12673|  0:01:06s\n",
            "epoch 35 | loss: 24.19044| val_0_mse: 23.24119|  0:01:08s\n",
            "epoch 36 | loss: 23.88855| val_0_mse: 23.73684|  0:01:10s\n",
            "epoch 37 | loss: 24.58964| val_0_mse: 23.2914 |  0:01:12s\n",
            "epoch 38 | loss: 24.13756| val_0_mse: 22.13226|  0:01:14s\n",
            "epoch 39 | loss: 23.67455| val_0_mse: 22.76564|  0:01:16s\n",
            "epoch 40 | loss: 24.52804| val_0_mse: 23.04724|  0:01:18s\n",
            "epoch 41 | loss: 23.93632| val_0_mse: 23.08138|  0:01:20s\n",
            "epoch 42 | loss: 23.62158| val_0_mse: 21.72716|  0:01:22s\n",
            "epoch 43 | loss: 23.46314| val_0_mse: 22.50868|  0:01:24s\n",
            "epoch 44 | loss: 23.05365| val_0_mse: 22.1729 |  0:01:26s\n",
            "epoch 45 | loss: 23.43506| val_0_mse: 22.01894|  0:01:27s\n",
            "epoch 46 | loss: 23.3324 | val_0_mse: 22.07246|  0:01:29s\n",
            "epoch 47 | loss: 23.69567| val_0_mse: 22.20811|  0:01:31s\n",
            "epoch 48 | loss: 22.9827 | val_0_mse: 22.73891|  0:01:33s\n",
            "epoch 49 | loss: 23.14852| val_0_mse: 22.48895|  0:01:35s\n",
            "epoch 50 | loss: 23.70327| val_0_mse: 22.09275|  0:01:37s\n",
            "\n",
            "Early stopping occurred at epoch 50 with best_epoch = 30 and best_val_0_mse = 21.701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-03-11 14:06:24,973] Trial 2 finished with value: 3.3887641429901123 and parameters: {'n_d': 32, 'n_a': 32, 'n_steps': 10, 'gamma': 1.500471979073426, 'lambda_sparse': 0.002180383343896343, 'momentum': 0.048256890282373066}. Best is trial 1 with value: 3.350657304128011.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.4235\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 30.47618| val_0_mse: 31.05327|  0:00:00s\n",
            "epoch 1  | loss: 25.7597 | val_0_mse: 32.56459|  0:00:01s\n",
            "epoch 2  | loss: 26.12943| val_0_mse: 27.36755|  0:00:02s\n",
            "epoch 3  | loss: 25.16727| val_0_mse: 26.70706|  0:00:02s\n",
            "epoch 4  | loss: 24.78434| val_0_mse: 24.65741|  0:00:03s\n",
            "epoch 5  | loss: 24.86897| val_0_mse: 26.63276|  0:00:04s\n",
            "epoch 6  | loss: 24.13838| val_0_mse: 25.63021|  0:00:04s\n",
            "epoch 7  | loss: 22.4731 | val_0_mse: 24.90355|  0:00:05s\n",
            "epoch 8  | loss: 21.80242| val_0_mse: 23.15833|  0:00:06s\n",
            "epoch 9  | loss: 21.90772| val_0_mse: 23.70879|  0:00:07s\n",
            "epoch 10 | loss: 22.06997| val_0_mse: 24.17349|  0:00:07s\n",
            "epoch 11 | loss: 22.40477| val_0_mse: 23.90948|  0:00:08s\n",
            "epoch 12 | loss: 22.37244| val_0_mse: 24.70708|  0:00:09s\n",
            "epoch 13 | loss: 21.22192| val_0_mse: 23.28674|  0:00:09s\n",
            "epoch 14 | loss: 21.23967| val_0_mse: 23.32343|  0:00:10s\n",
            "epoch 15 | loss: 21.48599| val_0_mse: 24.2283 |  0:00:11s\n",
            "epoch 16 | loss: 21.20845| val_0_mse: 23.71676|  0:00:11s\n",
            "epoch 17 | loss: 20.81125| val_0_mse: 24.23611|  0:00:12s\n",
            "epoch 18 | loss: 20.62052| val_0_mse: 23.49927|  0:00:13s\n",
            "epoch 19 | loss: 20.95296| val_0_mse: 23.4786 |  0:00:14s\n",
            "epoch 20 | loss: 20.7346 | val_0_mse: 24.13687|  0:00:14s\n",
            "epoch 21 | loss: 21.05101| val_0_mse: 23.73588|  0:00:15s\n",
            "epoch 22 | loss: 20.20856| val_0_mse: 24.12454|  0:00:16s\n",
            "epoch 23 | loss: 20.3424 | val_0_mse: 23.48444|  0:00:16s\n",
            "epoch 24 | loss: 20.25949| val_0_mse: 25.31754|  0:00:17s\n",
            "epoch 25 | loss: 20.30565| val_0_mse: 24.39779|  0:00:18s\n",
            "epoch 26 | loss: 20.23554| val_0_mse: 23.00118|  0:00:18s\n",
            "epoch 27 | loss: 20.60333| val_0_mse: 24.05238|  0:00:19s\n",
            "epoch 28 | loss: 19.6647 | val_0_mse: 23.71441|  0:00:20s\n",
            "epoch 29 | loss: 19.67995| val_0_mse: 23.41232|  0:00:21s\n",
            "epoch 30 | loss: 19.39462| val_0_mse: 24.08952|  0:00:21s\n",
            "epoch 31 | loss: 19.96316| val_0_mse: 23.80667|  0:00:22s\n",
            "epoch 32 | loss: 19.84394| val_0_mse: 22.78443|  0:00:23s\n",
            "epoch 33 | loss: 19.68351| val_0_mse: 25.93478|  0:00:23s\n",
            "epoch 34 | loss: 19.48376| val_0_mse: 23.54403|  0:00:24s\n",
            "epoch 35 | loss: 18.83245| val_0_mse: 25.55699|  0:00:25s\n",
            "epoch 36 | loss: 18.45433| val_0_mse: 24.21794|  0:00:25s\n",
            "epoch 37 | loss: 19.57972| val_0_mse: 23.80772|  0:00:26s\n",
            "epoch 38 | loss: 18.45541| val_0_mse: 24.00891|  0:00:27s\n",
            "epoch 39 | loss: 18.23443| val_0_mse: 25.42538|  0:00:28s\n",
            "epoch 40 | loss: 17.98316| val_0_mse: 24.0797 |  0:00:28s\n",
            "epoch 41 | loss: 18.62257| val_0_mse: 25.00409|  0:00:29s\n",
            "epoch 42 | loss: 18.4101 | val_0_mse: 24.56564|  0:00:30s\n",
            "epoch 43 | loss: 17.74222| val_0_mse: 25.78528|  0:00:30s\n",
            "epoch 44 | loss: 17.25728| val_0_mse: 23.68739|  0:00:31s\n",
            "epoch 45 | loss: 17.41142| val_0_mse: 24.75959|  0:00:32s\n",
            "epoch 46 | loss: 16.64046| val_0_mse: 24.63468|  0:00:32s\n",
            "epoch 47 | loss: 16.25442| val_0_mse: 26.66087|  0:00:33s\n",
            "epoch 48 | loss: 15.95485| val_0_mse: 24.18895|  0:00:34s\n",
            "epoch 49 | loss: 15.78901| val_0_mse: 25.66722|  0:00:35s\n",
            "epoch 50 | loss: 15.65827| val_0_mse: 24.59005|  0:00:35s\n",
            "epoch 51 | loss: 16.05033| val_0_mse: 24.26151|  0:00:36s\n",
            "epoch 52 | loss: 15.85716| val_0_mse: 23.81573|  0:00:37s\n",
            "\n",
            "Early stopping occurred at epoch 52 with best_epoch = 32 and best_val_0_mse = 22.78443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.4608\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 32.27192| val_0_mse: 28.5783 |  0:00:00s\n",
            "epoch 1  | loss: 28.31798| val_0_mse: 27.6343 |  0:00:01s\n",
            "epoch 2  | loss: 27.33517| val_0_mse: 25.66574|  0:00:02s\n",
            "epoch 3  | loss: 25.7884 | val_0_mse: 25.57473|  0:00:02s\n",
            "epoch 4  | loss: 24.8825 | val_0_mse: 23.75507|  0:00:03s\n",
            "epoch 5  | loss: 25.29301| val_0_mse: 25.46925|  0:00:04s\n",
            "epoch 6  | loss: 24.502  | val_0_mse: 25.06662|  0:00:04s\n",
            "epoch 7  | loss: 23.82682| val_0_mse: 25.37917|  0:00:05s\n",
            "epoch 8  | loss: 24.32635| val_0_mse: 24.39092|  0:00:06s\n",
            "epoch 9  | loss: 23.7849 | val_0_mse: 24.41185|  0:00:07s\n",
            "epoch 10 | loss: 21.53932| val_0_mse: 23.53551|  0:00:07s\n",
            "epoch 11 | loss: 22.65984| val_0_mse: 23.40017|  0:00:08s\n",
            "epoch 12 | loss: 22.12298| val_0_mse: 23.14839|  0:00:09s\n",
            "epoch 13 | loss: 21.48171| val_0_mse: 23.3088 |  0:00:09s\n",
            "epoch 14 | loss: 21.59827| val_0_mse: 23.20883|  0:00:10s\n",
            "epoch 15 | loss: 21.63994| val_0_mse: 22.75112|  0:00:11s\n",
            "epoch 16 | loss: 21.64293| val_0_mse: 22.81526|  0:00:11s\n",
            "epoch 17 | loss: 21.7474 | val_0_mse: 24.15989|  0:00:12s\n",
            "epoch 18 | loss: 21.66154| val_0_mse: 23.24324|  0:00:13s\n",
            "epoch 19 | loss: 21.42709| val_0_mse: 23.18571|  0:00:14s\n",
            "epoch 20 | loss: 21.92066| val_0_mse: 23.93325|  0:00:14s\n",
            "epoch 21 | loss: 22.00348| val_0_mse: 23.85935|  0:00:15s\n",
            "epoch 22 | loss: 21.83178| val_0_mse: 24.23035|  0:00:16s\n",
            "epoch 23 | loss: 21.74485| val_0_mse: 24.17792|  0:00:16s\n",
            "epoch 24 | loss: 21.36432| val_0_mse: 24.28206|  0:00:17s\n",
            "epoch 25 | loss: 21.41092| val_0_mse: 23.11059|  0:00:18s\n",
            "epoch 26 | loss: 21.03484| val_0_mse: 23.65526|  0:00:18s\n",
            "epoch 27 | loss: 21.54588| val_0_mse: 22.41221|  0:00:19s\n",
            "epoch 28 | loss: 21.35466| val_0_mse: 23.28367|  0:00:20s\n",
            "epoch 29 | loss: 20.83155| val_0_mse: 23.47059|  0:00:21s\n",
            "epoch 30 | loss: 20.94046| val_0_mse: 23.07932|  0:00:21s\n",
            "epoch 31 | loss: 20.6167 | val_0_mse: 23.39303|  0:00:22s\n",
            "epoch 32 | loss: 20.5485 | val_0_mse: 22.49124|  0:00:23s\n",
            "epoch 33 | loss: 19.97109| val_0_mse: 21.93069|  0:00:23s\n",
            "epoch 34 | loss: 19.10969| val_0_mse: 22.94781|  0:00:24s\n",
            "epoch 35 | loss: 18.98984| val_0_mse: 24.7131 |  0:00:25s\n",
            "epoch 36 | loss: 19.82348| val_0_mse: 22.99452|  0:00:25s\n",
            "epoch 37 | loss: 19.1485 | val_0_mse: 23.52886|  0:00:26s\n",
            "epoch 38 | loss: 18.22025| val_0_mse: 22.45378|  0:00:27s\n",
            "epoch 39 | loss: 18.41481| val_0_mse: 22.53848|  0:00:28s\n",
            "epoch 40 | loss: 18.53765| val_0_mse: 22.78677|  0:00:28s\n",
            "epoch 41 | loss: 18.50933| val_0_mse: 25.5356 |  0:00:29s\n",
            "epoch 42 | loss: 18.54039| val_0_mse: 24.42172|  0:00:30s\n",
            "epoch 43 | loss: 17.99388| val_0_mse: 23.0753 |  0:00:30s\n",
            "epoch 44 | loss: 17.80314| val_0_mse: 24.50332|  0:00:31s\n",
            "epoch 45 | loss: 17.877  | val_0_mse: 24.26505|  0:00:32s\n",
            "epoch 46 | loss: 16.70207| val_0_mse: 23.96188|  0:00:33s\n",
            "epoch 47 | loss: 17.64034| val_0_mse: 23.97138|  0:00:33s\n",
            "epoch 48 | loss: 19.06965| val_0_mse: 22.52359|  0:00:34s\n",
            "epoch 49 | loss: 18.32525| val_0_mse: 23.14625|  0:00:35s\n",
            "epoch 50 | loss: 17.52376| val_0_mse: 24.55929|  0:00:35s\n",
            "epoch 51 | loss: 16.67949| val_0_mse: 23.49802|  0:00:36s\n",
            "epoch 52 | loss: 16.27412| val_0_mse: 23.55867|  0:00:37s\n",
            "epoch 53 | loss: 16.81744| val_0_mse: 23.46209|  0:00:38s\n",
            "\n",
            "Early stopping occurred at epoch 53 with best_epoch = 33 and best_val_0_mse = 21.93069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.3287\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 33.32509| val_0_mse: 28.94386|  0:00:00s\n",
            "epoch 1  | loss: 28.89542| val_0_mse: 27.66804|  0:00:01s\n",
            "epoch 2  | loss: 27.32571| val_0_mse: 24.93337|  0:00:02s\n",
            "epoch 3  | loss: 26.07303| val_0_mse: 27.71805|  0:00:02s\n",
            "epoch 4  | loss: 25.13882| val_0_mse: 23.43183|  0:00:03s\n",
            "epoch 5  | loss: 24.8854 | val_0_mse: 22.70973|  0:00:04s\n",
            "epoch 6  | loss: 24.62002| val_0_mse: 23.73518|  0:00:04s\n",
            "epoch 7  | loss: 24.23409| val_0_mse: 24.49977|  0:00:05s\n",
            "epoch 8  | loss: 24.86088| val_0_mse: 23.60853|  0:00:06s\n",
            "epoch 9  | loss: 23.14717| val_0_mse: 22.78865|  0:00:07s\n",
            "epoch 10 | loss: 22.88475| val_0_mse: 22.41118|  0:00:07s\n",
            "epoch 11 | loss: 22.68931| val_0_mse: 21.85559|  0:00:08s\n",
            "epoch 12 | loss: 22.3623 | val_0_mse: 22.48333|  0:00:09s\n",
            "epoch 13 | loss: 22.62333| val_0_mse: 21.61758|  0:00:09s\n",
            "epoch 14 | loss: 22.30319| val_0_mse: 22.1337 |  0:00:10s\n",
            "epoch 15 | loss: 22.32312| val_0_mse: 21.19314|  0:00:11s\n",
            "epoch 16 | loss: 22.40086| val_0_mse: 22.25412|  0:00:12s\n",
            "epoch 17 | loss: 22.29333| val_0_mse: 21.90817|  0:00:12s\n",
            "epoch 18 | loss: 21.70018| val_0_mse: 22.676  |  0:00:13s\n",
            "epoch 19 | loss: 21.49137| val_0_mse: 22.53531|  0:00:14s\n",
            "epoch 20 | loss: 21.67172| val_0_mse: 21.94264|  0:00:14s\n",
            "epoch 21 | loss: 21.02211| val_0_mse: 22.21709|  0:00:15s\n",
            "epoch 22 | loss: 20.46121| val_0_mse: 21.53317|  0:00:16s\n",
            "epoch 23 | loss: 20.66145| val_0_mse: 21.68867|  0:00:17s\n",
            "epoch 24 | loss: 20.33141| val_0_mse: 21.43632|  0:00:17s\n",
            "epoch 25 | loss: 20.60096| val_0_mse: 22.47015|  0:00:18s\n",
            "epoch 26 | loss: 20.49186| val_0_mse: 21.68529|  0:00:19s\n",
            "epoch 27 | loss: 20.57073| val_0_mse: 22.84032|  0:00:19s\n",
            "epoch 28 | loss: 20.13313| val_0_mse: 21.86575|  0:00:20s\n",
            "epoch 29 | loss: 19.55214| val_0_mse: 21.93974|  0:00:21s\n",
            "epoch 30 | loss: 19.31076| val_0_mse: 22.64422|  0:00:21s\n",
            "epoch 31 | loss: 19.12155| val_0_mse: 22.61384|  0:00:22s\n",
            "epoch 32 | loss: 19.25232| val_0_mse: 22.36546|  0:00:23s\n",
            "epoch 33 | loss: 18.59877| val_0_mse: 22.72482|  0:00:24s\n",
            "epoch 34 | loss: 18.75465| val_0_mse: 22.88008|  0:00:24s\n",
            "epoch 35 | loss: 18.71124| val_0_mse: 23.32283|  0:00:25s\n",
            "\n",
            "Early stopping occurred at epoch 35 with best_epoch = 15 and best_val_0_mse = 21.19314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-03-11 14:08:06,882] Trial 3 finished with value: 3.3779946168263755 and parameters: {'n_d': 48, 'n_a': 56, 'n_steps': 3, 'gamma': 1.916280480273502, 'lambda_sparse': 0.0008928301694246044, 'momentum': 0.2822865748850537}. Best is trial 1 with value: 3.350657304128011.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3445\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 30.53904| val_0_mse: 29.23293|  0:00:01s\n",
            "epoch 1  | loss: 27.05041| val_0_mse: 28.52694|  0:00:03s\n",
            "epoch 2  | loss: 26.72104| val_0_mse: 30.40484|  0:00:05s\n",
            "epoch 3  | loss: 27.5103 | val_0_mse: 26.83318|  0:00:07s\n",
            "epoch 4  | loss: 27.78853| val_0_mse: 28.25545|  0:00:09s\n",
            "epoch 5  | loss: 27.36085| val_0_mse: 28.43997|  0:00:11s\n",
            "epoch 6  | loss: 28.03616| val_0_mse: 28.17593|  0:00:13s\n",
            "epoch 7  | loss: 26.89769| val_0_mse: 31.07776|  0:00:15s\n",
            "epoch 8  | loss: 27.79316| val_0_mse: 28.83572|  0:00:17s\n",
            "epoch 9  | loss: 26.19675| val_0_mse: 26.6293 |  0:00:19s\n",
            "epoch 10 | loss: 25.25631| val_0_mse: 25.70913|  0:00:21s\n",
            "epoch 11 | loss: 26.26434| val_0_mse: 27.2857 |  0:00:23s\n",
            "epoch 12 | loss: 27.59811| val_0_mse: 27.38177|  0:00:24s\n",
            "epoch 13 | loss: 25.55213| val_0_mse: 25.82318|  0:00:26s\n",
            "epoch 14 | loss: 25.27379| val_0_mse: 25.51863|  0:00:28s\n",
            "epoch 15 | loss: 25.53408| val_0_mse: 25.08932|  0:00:30s\n",
            "epoch 16 | loss: 24.40436| val_0_mse: 24.17569|  0:00:32s\n",
            "epoch 17 | loss: 24.52589| val_0_mse: 25.22829|  0:00:34s\n",
            "epoch 18 | loss: 23.47849| val_0_mse: 25.47481|  0:00:36s\n",
            "epoch 19 | loss: 24.02432| val_0_mse: 26.86356|  0:00:38s\n",
            "epoch 20 | loss: 24.45926| val_0_mse: 25.33853|  0:00:40s\n",
            "epoch 21 | loss: 23.00251| val_0_mse: 23.74927|  0:00:42s\n",
            "epoch 22 | loss: 23.97232| val_0_mse: 24.00129|  0:00:44s\n",
            "epoch 23 | loss: 23.73256| val_0_mse: 24.77591|  0:00:46s\n",
            "epoch 24 | loss: 23.43712| val_0_mse: 24.04732|  0:00:48s\n",
            "epoch 25 | loss: 23.84227| val_0_mse: 24.56948|  0:00:50s\n",
            "epoch 26 | loss: 24.5617 | val_0_mse: 26.11966|  0:00:52s\n",
            "epoch 27 | loss: 23.82045| val_0_mse: 23.49037|  0:00:54s\n",
            "epoch 28 | loss: 24.44268| val_0_mse: 23.76916|  0:00:56s\n",
            "epoch 29 | loss: 23.71679| val_0_mse: 22.59215|  0:00:57s\n",
            "epoch 30 | loss: 23.16112| val_0_mse: 23.12421|  0:00:59s\n",
            "epoch 31 | loss: 22.43609| val_0_mse: 22.65455|  0:01:01s\n",
            "epoch 32 | loss: 22.97136| val_0_mse: 23.40471|  0:01:03s\n",
            "epoch 33 | loss: 22.75482| val_0_mse: 22.54845|  0:01:05s\n",
            "epoch 34 | loss: 23.5865 | val_0_mse: 23.78142|  0:01:07s\n",
            "epoch 35 | loss: 23.61582| val_0_mse: 23.03426|  0:01:09s\n",
            "epoch 36 | loss: 22.2407 | val_0_mse: 22.86797|  0:01:11s\n",
            "epoch 37 | loss: 23.23176| val_0_mse: 23.75929|  0:01:13s\n",
            "epoch 38 | loss: 23.31995| val_0_mse: 23.50247|  0:01:15s\n",
            "epoch 39 | loss: 22.32015| val_0_mse: 22.61528|  0:01:17s\n",
            "epoch 40 | loss: 22.63736| val_0_mse: 23.02335|  0:01:19s\n",
            "epoch 41 | loss: 22.46395| val_0_mse: 23.3157 |  0:01:21s\n",
            "epoch 42 | loss: 22.70908| val_0_mse: 22.65428|  0:01:23s\n",
            "epoch 43 | loss: 21.77541| val_0_mse: 22.72265|  0:01:25s\n",
            "epoch 44 | loss: 21.63349| val_0_mse: 22.38387|  0:01:27s\n",
            "epoch 45 | loss: 21.77738| val_0_mse: 22.64803|  0:01:29s\n",
            "epoch 46 | loss: 22.00959| val_0_mse: 22.43681|  0:01:31s\n",
            "epoch 47 | loss: 21.96336| val_0_mse: 22.16507|  0:01:33s\n",
            "epoch 48 | loss: 21.60166| val_0_mse: 22.71874|  0:01:35s\n",
            "epoch 49 | loss: 21.30819| val_0_mse: 22.60818|  0:01:36s\n",
            "epoch 50 | loss: 21.61329| val_0_mse: 22.96497|  0:01:38s\n",
            "epoch 51 | loss: 21.63105| val_0_mse: 22.59358|  0:01:40s\n",
            "epoch 52 | loss: 21.47336| val_0_mse: 22.60736|  0:01:42s\n",
            "epoch 53 | loss: 21.29165| val_0_mse: 22.99991|  0:01:44s\n",
            "epoch 54 | loss: 22.23664| val_0_mse: 22.00487|  0:01:46s\n",
            "epoch 55 | loss: 21.39622| val_0_mse: 22.57151|  0:01:48s\n",
            "epoch 56 | loss: 20.77353| val_0_mse: 22.31184|  0:01:50s\n",
            "epoch 57 | loss: 21.03779| val_0_mse: 22.25205|  0:01:52s\n",
            "epoch 58 | loss: 21.59652| val_0_mse: 22.4853 |  0:01:54s\n",
            "epoch 59 | loss: 20.96862| val_0_mse: 22.78594|  0:01:56s\n",
            "epoch 60 | loss: 21.04338| val_0_mse: 22.48469|  0:01:57s\n",
            "epoch 61 | loss: 20.84746| val_0_mse: 23.42715|  0:01:59s\n",
            "epoch 62 | loss: 21.21645| val_0_mse: 23.10647|  0:02:01s\n",
            "epoch 63 | loss: 20.88767| val_0_mse: 23.00581|  0:02:03s\n",
            "epoch 64 | loss: 20.51897| val_0_mse: 23.22927|  0:02:05s\n",
            "epoch 65 | loss: 20.64932| val_0_mse: 22.94582|  0:02:07s\n",
            "epoch 66 | loss: 20.95459| val_0_mse: 23.29772|  0:02:09s\n",
            "epoch 67 | loss: 20.62203| val_0_mse: 22.28749|  0:02:11s\n",
            "epoch 68 | loss: 20.52101| val_0_mse: 22.85458|  0:02:13s\n",
            "epoch 69 | loss: 20.34345| val_0_mse: 22.70673|  0:02:15s\n",
            "epoch 70 | loss: 20.16321| val_0_mse: 22.30166|  0:02:17s\n",
            "epoch 71 | loss: 20.57264| val_0_mse: 23.79832|  0:02:18s\n",
            "epoch 72 | loss: 20.49685| val_0_mse: 23.0619 |  0:02:20s\n",
            "epoch 73 | loss: 21.03428| val_0_mse: 22.77814|  0:02:22s\n",
            "epoch 74 | loss: 20.37629| val_0_mse: 23.19308|  0:02:24s\n",
            "\n",
            "Early stopping occurred at epoch 74 with best_epoch = 54 and best_val_0_mse = 22.00487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.4067\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 33.94073| val_0_mse: 30.1083 |  0:00:01s\n",
            "epoch 1  | loss: 28.56638| val_0_mse: 25.89708|  0:00:03s\n",
            "epoch 2  | loss: 28.18725| val_0_mse: 27.10283|  0:00:05s\n",
            "epoch 3  | loss: 27.13214| val_0_mse: 25.72993|  0:00:07s\n",
            "epoch 4  | loss: 25.54692| val_0_mse: 25.78728|  0:00:09s\n",
            "epoch 5  | loss: 25.86809| val_0_mse: 25.67082|  0:00:11s\n",
            "epoch 6  | loss: 26.96192| val_0_mse: 33.19346|  0:00:13s\n",
            "epoch 7  | loss: 27.75246| val_0_mse: 23.91369|  0:00:15s\n",
            "epoch 8  | loss: 24.35694| val_0_mse: 24.58118|  0:00:17s\n",
            "epoch 9  | loss: 24.1669 | val_0_mse: 26.45033|  0:00:19s\n",
            "epoch 10 | loss: 29.52253| val_0_mse: 27.46552|  0:00:21s\n",
            "epoch 11 | loss: 24.31967| val_0_mse: 24.90589|  0:00:23s\n",
            "epoch 12 | loss: 24.56019| val_0_mse: 26.30055|  0:00:25s\n",
            "epoch 13 | loss: 23.8615 | val_0_mse: 26.2597 |  0:00:27s\n",
            "epoch 14 | loss: 24.40774| val_0_mse: 25.13792|  0:00:28s\n",
            "epoch 15 | loss: 24.56278| val_0_mse: 24.4734 |  0:00:30s\n",
            "epoch 16 | loss: 24.12607| val_0_mse: 24.12667|  0:00:32s\n",
            "epoch 17 | loss: 24.47444| val_0_mse: 27.72217|  0:00:34s\n",
            "epoch 18 | loss: 25.0007 | val_0_mse: 26.96701|  0:00:36s\n",
            "epoch 19 | loss: 24.74154| val_0_mse: 24.74927|  0:00:38s\n",
            "epoch 20 | loss: 23.38727| val_0_mse: 24.27463|  0:00:40s\n",
            "epoch 21 | loss: 23.66436| val_0_mse: 23.59488|  0:00:42s\n",
            "epoch 22 | loss: 24.2132 | val_0_mse: 24.12121|  0:00:44s\n",
            "epoch 23 | loss: 23.07899| val_0_mse: 24.16054|  0:00:46s\n",
            "epoch 24 | loss: 23.51061| val_0_mse: 24.00835|  0:00:48s\n",
            "epoch 25 | loss: 23.16467| val_0_mse: 25.01635|  0:00:50s\n",
            "epoch 26 | loss: 24.33542| val_0_mse: 23.48809|  0:00:51s\n",
            "epoch 27 | loss: 22.94526| val_0_mse: 22.81913|  0:00:53s\n",
            "epoch 28 | loss: 22.41811| val_0_mse: 23.49764|  0:00:55s\n",
            "epoch 29 | loss: 22.85076| val_0_mse: 23.98244|  0:00:57s\n",
            "epoch 30 | loss: 23.88817| val_0_mse: 24.16344|  0:00:59s\n",
            "epoch 31 | loss: 22.41842| val_0_mse: 24.72087|  0:01:01s\n",
            "epoch 32 | loss: 22.61878| val_0_mse: 23.33263|  0:01:03s\n",
            "epoch 33 | loss: 21.83042| val_0_mse: 23.68152|  0:01:05s\n",
            "epoch 34 | loss: 22.30598| val_0_mse: 23.09558|  0:01:07s\n",
            "epoch 35 | loss: 22.32274| val_0_mse: 22.93836|  0:01:09s\n",
            "epoch 36 | loss: 22.0795 | val_0_mse: 22.48606|  0:01:11s\n",
            "epoch 37 | loss: 21.94293| val_0_mse: 22.33142|  0:01:13s\n",
            "epoch 38 | loss: 21.56628| val_0_mse: 21.78679|  0:01:14s\n",
            "epoch 39 | loss: 21.91364| val_0_mse: 23.15504|  0:01:16s\n",
            "epoch 40 | loss: 22.0774 | val_0_mse: 22.42498|  0:01:18s\n",
            "epoch 41 | loss: 21.66184| val_0_mse: 22.79683|  0:01:20s\n",
            "epoch 42 | loss: 21.70049| val_0_mse: 22.81141|  0:01:22s\n",
            "epoch 43 | loss: 21.74211| val_0_mse: 23.69938|  0:01:24s\n",
            "epoch 44 | loss: 21.67074| val_0_mse: 22.94431|  0:01:26s\n",
            "epoch 45 | loss: 21.9214 | val_0_mse: 22.554  |  0:01:28s\n",
            "epoch 46 | loss: 21.64097| val_0_mse: 22.92866|  0:01:30s\n",
            "epoch 47 | loss: 21.42342| val_0_mse: 23.11116|  0:01:32s\n",
            "epoch 48 | loss: 21.32023| val_0_mse: 22.57252|  0:01:34s\n",
            "epoch 49 | loss: 21.45965| val_0_mse: 23.07439|  0:01:36s\n",
            "epoch 50 | loss: 21.63467| val_0_mse: 22.64744|  0:01:37s\n",
            "epoch 51 | loss: 21.45603| val_0_mse: 22.47346|  0:01:39s\n",
            "epoch 52 | loss: 21.74719| val_0_mse: 22.89786|  0:01:41s\n",
            "epoch 53 | loss: 21.444  | val_0_mse: 22.51444|  0:01:43s\n",
            "epoch 54 | loss: 22.35936| val_0_mse: 22.61671|  0:01:45s\n",
            "epoch 55 | loss: 21.61895| val_0_mse: 22.28838|  0:01:47s\n",
            "epoch 56 | loss: 21.0948 | val_0_mse: 22.96258|  0:01:49s\n",
            "epoch 57 | loss: 21.44469| val_0_mse: 22.89249|  0:01:51s\n",
            "epoch 58 | loss: 21.14751| val_0_mse: 23.11544|  0:01:53s\n",
            "\n",
            "Early stopping occurred at epoch 58 with best_epoch = 38 and best_val_0_mse = 21.78679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.4618\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 31.37805| val_0_mse: 28.6537 |  0:00:01s\n",
            "epoch 1  | loss: 28.7958 | val_0_mse: 27.75545|  0:00:03s\n",
            "epoch 2  | loss: 29.10722| val_0_mse: 29.22832|  0:00:05s\n",
            "epoch 3  | loss: 35.2092 | val_0_mse: 35.25977|  0:00:07s\n",
            "epoch 4  | loss: 32.73921| val_0_mse: 28.12712|  0:00:09s\n",
            "epoch 5  | loss: 28.94613| val_0_mse: 28.51797|  0:00:11s\n",
            "epoch 6  | loss: 28.57449| val_0_mse: 28.62086|  0:00:13s\n",
            "epoch 7  | loss: 29.29342| val_0_mse: 26.83814|  0:00:15s\n",
            "epoch 8  | loss: 27.82138| val_0_mse: 24.81341|  0:00:17s\n",
            "epoch 9  | loss: 26.84487| val_0_mse: 24.88474|  0:00:19s\n",
            "epoch 10 | loss: 25.24533| val_0_mse: 27.91042|  0:00:21s\n",
            "epoch 11 | loss: 24.84362| val_0_mse: 23.31973|  0:00:23s\n",
            "epoch 12 | loss: 24.17189| val_0_mse: 24.41151|  0:00:25s\n",
            "epoch 13 | loss: 24.17044| val_0_mse: 24.35991|  0:00:27s\n",
            "epoch 14 | loss: 23.48879| val_0_mse: 22.58619|  0:00:29s\n",
            "epoch 15 | loss: 23.80197| val_0_mse: 22.81517|  0:00:31s\n",
            "epoch 16 | loss: 24.33394| val_0_mse: 22.69019|  0:00:33s\n",
            "epoch 17 | loss: 23.12768| val_0_mse: 22.71935|  0:00:35s\n",
            "epoch 18 | loss: 23.65991| val_0_mse: 22.39708|  0:00:37s\n",
            "epoch 19 | loss: 23.04418| val_0_mse: 22.2179 |  0:00:39s\n",
            "epoch 20 | loss: 23.17298| val_0_mse: 23.21475|  0:00:41s\n",
            "epoch 21 | loss: 22.59361| val_0_mse: 24.22931|  0:00:43s\n",
            "epoch 22 | loss: 23.25376| val_0_mse: 22.11172|  0:00:44s\n",
            "epoch 23 | loss: 22.70652| val_0_mse: 22.75228|  0:00:46s\n",
            "epoch 24 | loss: 23.11709| val_0_mse: 23.01433|  0:00:48s\n",
            "epoch 25 | loss: 22.75679| val_0_mse: 22.20162|  0:00:50s\n",
            "epoch 26 | loss: 22.7553 | val_0_mse: 22.8581 |  0:00:52s\n",
            "epoch 27 | loss: 22.54762| val_0_mse: 22.38842|  0:00:54s\n",
            "epoch 28 | loss: 22.24728| val_0_mse: 21.876  |  0:00:56s\n",
            "epoch 29 | loss: 22.41724| val_0_mse: 22.38334|  0:00:58s\n",
            "epoch 30 | loss: 22.65845| val_0_mse: 22.66183|  0:01:00s\n",
            "epoch 31 | loss: 22.75241| val_0_mse: 24.20878|  0:01:02s\n",
            "epoch 32 | loss: 23.01619| val_0_mse: 22.44985|  0:01:04s\n",
            "epoch 33 | loss: 22.95737| val_0_mse: 22.07313|  0:01:05s\n",
            "epoch 34 | loss: 22.89126| val_0_mse: 23.33702|  0:01:07s\n",
            "epoch 35 | loss: 23.35097| val_0_mse: 22.52234|  0:01:09s\n",
            "epoch 36 | loss: 23.26076| val_0_mse: 21.7821 |  0:01:11s\n",
            "epoch 37 | loss: 22.5249 | val_0_mse: 22.70168|  0:01:13s\n",
            "epoch 38 | loss: 23.39444| val_0_mse: 22.3594 |  0:01:15s\n",
            "epoch 39 | loss: 22.57337| val_0_mse: 22.57642|  0:01:17s\n",
            "epoch 40 | loss: 23.37313| val_0_mse: 23.82402|  0:01:19s\n",
            "epoch 41 | loss: 23.69646| val_0_mse: 22.55778|  0:01:21s\n",
            "epoch 42 | loss: 22.60464| val_0_mse: 22.08414|  0:01:23s\n",
            "epoch 43 | loss: 22.68056| val_0_mse: 21.67146|  0:01:25s\n",
            "epoch 44 | loss: 22.9915 | val_0_mse: 22.21721|  0:01:26s\n",
            "epoch 45 | loss: 22.09417| val_0_mse: 21.73475|  0:01:28s\n",
            "epoch 46 | loss: 22.33832| val_0_mse: 21.43466|  0:01:30s\n",
            "epoch 47 | loss: 22.37397| val_0_mse: 21.56321|  0:01:32s\n",
            "epoch 48 | loss: 22.59803| val_0_mse: 22.49168|  0:01:34s\n",
            "epoch 49 | loss: 22.13245| val_0_mse: 21.9725 |  0:01:36s\n",
            "epoch 50 | loss: 22.25076| val_0_mse: 21.87448|  0:01:38s\n",
            "epoch 51 | loss: 22.18263| val_0_mse: 21.55175|  0:01:40s\n",
            "epoch 52 | loss: 21.90664| val_0_mse: 21.73438|  0:01:42s\n",
            "epoch 53 | loss: 22.02957| val_0_mse: 21.77739|  0:01:44s\n",
            "epoch 54 | loss: 22.10184| val_0_mse: 21.28898|  0:01:46s\n",
            "epoch 55 | loss: 21.74622| val_0_mse: 21.60177|  0:01:48s\n",
            "epoch 56 | loss: 21.88397| val_0_mse: 21.68015|  0:01:49s\n",
            "epoch 57 | loss: 21.22617| val_0_mse: 21.80109|  0:01:51s\n",
            "epoch 58 | loss: 21.67982| val_0_mse: 21.86648|  0:01:53s\n",
            "epoch 59 | loss: 21.55985| val_0_mse: 21.93072|  0:01:55s\n",
            "epoch 60 | loss: 21.45409| val_0_mse: 22.30637|  0:01:57s\n",
            "epoch 61 | loss: 20.76089| val_0_mse: 22.41511|  0:01:59s\n",
            "epoch 62 | loss: 20.76886| val_0_mse: 22.74413|  0:02:01s\n",
            "epoch 63 | loss: 21.59892| val_0_mse: 21.81702|  0:02:03s\n",
            "epoch 64 | loss: 21.70076| val_0_mse: 22.30993|  0:02:05s\n",
            "epoch 65 | loss: 21.61487| val_0_mse: 21.81089|  0:02:07s\n",
            "epoch 66 | loss: 21.2448 | val_0_mse: 22.41125|  0:02:08s\n",
            "epoch 67 | loss: 21.97809| val_0_mse: 21.87976|  0:02:10s\n",
            "epoch 68 | loss: 21.61349| val_0_mse: 22.43247|  0:02:12s\n",
            "epoch 69 | loss: 21.484  | val_0_mse: 22.68787|  0:02:14s\n",
            "epoch 70 | loss: 20.76635| val_0_mse: 22.03004|  0:02:16s\n",
            "epoch 71 | loss: 21.4504 | val_0_mse: 23.09244|  0:02:18s\n",
            "epoch 72 | loss: 20.8451 | val_0_mse: 21.70683|  0:02:20s\n",
            "epoch 73 | loss: 21.20572| val_0_mse: 21.76611|  0:02:22s\n",
            "epoch 74 | loss: 21.43922| val_0_mse: 21.95191|  0:02:24s\n",
            "\n",
            "Early stopping occurred at epoch 74 with best_epoch = 54 and best_val_0_mse = 21.28898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-03-11 14:14:52,697] Trial 4 finished with value: 3.4309345881144204 and parameters: {'n_d': 24, 'n_a': 40, 'n_steps': 10, 'gamma': 1.3233723637403376, 'lambda_sparse': 0.006362364872821511, 'momentum': 0.09173836475764915}. Best is trial 1 with value: 3.350657304128011.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.4243\n",
            "Best Hyperparameters: {'n_d': 48, 'n_a': 32, 'n_steps': 7, 'gamma': 1.2749114062446103, 'lambda_sparse': 0.0006455290121945874, 'momentum': 0.10524942688819135}\n",
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 35.90581| val_0_mse: 29.74692|  0:00:01s\n",
            "epoch 1  | loss: 27.98595| val_0_mse: 32.77154|  0:00:02s\n",
            "epoch 2  | loss: 26.85563| val_0_mse: 28.96668|  0:00:04s\n",
            "epoch 3  | loss: 27.65898| val_0_mse: 27.95531|  0:00:05s\n",
            "epoch 4  | loss: 26.38409| val_0_mse: 25.49607|  0:00:07s\n",
            "epoch 5  | loss: 25.0815 | val_0_mse: 28.56147|  0:00:08s\n",
            "epoch 6  | loss: 26.06309| val_0_mse: 25.82608|  0:00:09s\n",
            "epoch 7  | loss: 24.22289| val_0_mse: 24.23989|  0:00:11s\n",
            "epoch 8  | loss: 25.05475| val_0_mse: 24.95739|  0:00:12s\n",
            "epoch 9  | loss: 25.01749| val_0_mse: 26.02736|  0:00:13s\n",
            "epoch 10 | loss: 25.38421| val_0_mse: 24.85132|  0:00:15s\n",
            "epoch 11 | loss: 25.11833| val_0_mse: 23.73342|  0:00:16s\n",
            "epoch 12 | loss: 23.87805| val_0_mse: 23.27791|  0:00:18s\n",
            "epoch 13 | loss: 23.77394| val_0_mse: 23.15246|  0:00:19s\n",
            "epoch 14 | loss: 23.78859| val_0_mse: 24.46262|  0:00:21s\n",
            "epoch 15 | loss: 23.35817| val_0_mse: 25.40512|  0:00:22s\n",
            "epoch 16 | loss: 23.1652 | val_0_mse: 24.85635|  0:00:23s\n",
            "epoch 17 | loss: 24.60657| val_0_mse: 24.57707|  0:00:25s\n",
            "epoch 18 | loss: 23.51491| val_0_mse: 24.27145|  0:00:26s\n",
            "epoch 19 | loss: 22.91115| val_0_mse: 24.06974|  0:00:28s\n",
            "epoch 20 | loss: 22.71041| val_0_mse: 23.45118|  0:00:29s\n",
            "epoch 21 | loss: 23.53113| val_0_mse: 23.82448|  0:00:30s\n",
            "epoch 22 | loss: 22.98267| val_0_mse: 23.10316|  0:00:32s\n",
            "epoch 23 | loss: 22.40432| val_0_mse: 24.3455 |  0:00:33s\n",
            "epoch 24 | loss: 23.02066| val_0_mse: 24.94455|  0:00:35s\n",
            "epoch 25 | loss: 22.65668| val_0_mse: 23.20284|  0:00:36s\n",
            "epoch 26 | loss: 22.82498| val_0_mse: 24.16015|  0:00:37s\n",
            "epoch 27 | loss: 22.74645| val_0_mse: 22.218  |  0:00:39s\n",
            "epoch 28 | loss: 22.27884| val_0_mse: 23.21334|  0:00:40s\n",
            "epoch 29 | loss: 22.69731| val_0_mse: 22.80059|  0:00:42s\n",
            "epoch 30 | loss: 22.16583| val_0_mse: 22.44487|  0:00:43s\n",
            "epoch 31 | loss: 22.53161| val_0_mse: 22.49817|  0:00:44s\n",
            "epoch 32 | loss: 22.46362| val_0_mse: 22.02207|  0:00:46s\n",
            "epoch 33 | loss: 22.31004| val_0_mse: 23.12718|  0:00:47s\n",
            "epoch 34 | loss: 21.95096| val_0_mse: 22.54909|  0:00:49s\n",
            "epoch 35 | loss: 22.29417| val_0_mse: 26.13171|  0:00:50s\n",
            "epoch 36 | loss: 23.11103| val_0_mse: 22.85843|  0:00:51s\n",
            "epoch 37 | loss: 22.38877| val_0_mse: 22.58077|  0:00:53s\n",
            "epoch 38 | loss: 22.31968| val_0_mse: 22.19078|  0:00:54s\n",
            "epoch 39 | loss: 23.42319| val_0_mse: 22.88498|  0:00:56s\n",
            "epoch 40 | loss: 22.08114| val_0_mse: 22.73441|  0:00:57s\n",
            "epoch 41 | loss: 22.90407| val_0_mse: 22.42623|  0:00:58s\n",
            "epoch 42 | loss: 21.65845| val_0_mse: 21.60971|  0:01:00s\n",
            "epoch 43 | loss: 22.21933| val_0_mse: 21.60511|  0:01:01s\n",
            "epoch 44 | loss: 21.99973| val_0_mse: 21.72816|  0:01:03s\n",
            "epoch 45 | loss: 21.90845| val_0_mse: 21.96103|  0:01:04s\n",
            "epoch 46 | loss: 21.83058| val_0_mse: 21.81874|  0:01:05s\n",
            "epoch 47 | loss: 21.33047| val_0_mse: 22.28907|  0:01:07s\n",
            "epoch 48 | loss: 21.30718| val_0_mse: 21.92212|  0:01:08s\n",
            "epoch 49 | loss: 21.46144| val_0_mse: 22.35842|  0:01:09s\n",
            "epoch 50 | loss: 21.94903| val_0_mse: 22.51847|  0:01:11s\n",
            "epoch 51 | loss: 21.66891| val_0_mse: 22.11035|  0:01:12s\n",
            "epoch 52 | loss: 21.97803| val_0_mse: 24.00437|  0:01:14s\n",
            "epoch 53 | loss: 21.61762| val_0_mse: 22.45714|  0:01:15s\n",
            "epoch 54 | loss: 21.23569| val_0_mse: 22.21942|  0:01:16s\n",
            "epoch 55 | loss: 21.1508 | val_0_mse: 22.42563|  0:01:18s\n",
            "epoch 56 | loss: 20.94335| val_0_mse: 21.98452|  0:01:19s\n",
            "epoch 57 | loss: 21.40073| val_0_mse: 23.53936|  0:01:21s\n",
            "epoch 58 | loss: 21.65318| val_0_mse: 24.58439|  0:01:22s\n",
            "epoch 59 | loss: 22.58887| val_0_mse: 23.90871|  0:01:23s\n",
            "epoch 60 | loss: 22.82217| val_0_mse: 23.22635|  0:01:25s\n",
            "epoch 61 | loss: 22.28763| val_0_mse: 23.20705|  0:01:26s\n",
            "epoch 62 | loss: 22.4756 | val_0_mse: 23.5909 |  0:01:28s\n",
            "epoch 63 | loss: 22.24567| val_0_mse: 22.8888 |  0:01:29s\n",
            "\n",
            "Early stopping occurred at epoch 63 with best_epoch = 43 and best_val_0_mse = 21.60511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Test MAE: 3.2862\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 33.97466| val_0_mse: 30.57967|  0:00:01s\n",
            "epoch 1  | loss: 28.90901| val_0_mse: 27.85566|  0:00:02s\n",
            "epoch 2  | loss: 28.26496| val_0_mse: 26.98026|  0:00:04s\n",
            "epoch 3  | loss: 26.55556| val_0_mse: 26.00631|  0:00:05s\n",
            "epoch 4  | loss: 27.11915| val_0_mse: 25.41257|  0:00:06s\n",
            "epoch 5  | loss: 26.59086| val_0_mse: 26.64897|  0:00:08s\n",
            "epoch 6  | loss: 25.69728| val_0_mse: 25.69575|  0:00:09s\n",
            "epoch 7  | loss: 26.35204| val_0_mse: 25.90159|  0:00:11s\n",
            "epoch 8  | loss: 26.5109 | val_0_mse: 26.48006|  0:00:12s\n",
            "epoch 9  | loss: 26.14747| val_0_mse: 26.78135|  0:00:13s\n",
            "epoch 10 | loss: 26.30059| val_0_mse: 25.00199|  0:00:15s\n",
            "epoch 11 | loss: 26.5148 | val_0_mse: 25.61065|  0:00:16s\n",
            "epoch 12 | loss: 26.0899 | val_0_mse: 25.28761|  0:00:18s\n",
            "epoch 13 | loss: 24.71838| val_0_mse: 25.11996|  0:00:19s\n",
            "epoch 14 | loss: 24.66426| val_0_mse: 25.69763|  0:00:20s\n",
            "epoch 15 | loss: 24.64421| val_0_mse: 24.94661|  0:00:22s\n",
            "epoch 16 | loss: 24.36414| val_0_mse: 25.57818|  0:00:23s\n",
            "epoch 17 | loss: 24.08543| val_0_mse: 23.88575|  0:00:25s\n",
            "epoch 18 | loss: 23.95103| val_0_mse: 24.95438|  0:00:26s\n",
            "epoch 19 | loss: 23.81823| val_0_mse: 24.95064|  0:00:27s\n",
            "epoch 20 | loss: 23.81323| val_0_mse: 24.16636|  0:00:29s\n",
            "epoch 21 | loss: 23.53264| val_0_mse: 23.44473|  0:00:30s\n",
            "epoch 22 | loss: 23.82862| val_0_mse: 23.70674|  0:00:32s\n",
            "epoch 23 | loss: 23.68485| val_0_mse: 23.28041|  0:00:33s\n",
            "epoch 24 | loss: 23.87121| val_0_mse: 24.27616|  0:00:34s\n",
            "epoch 25 | loss: 23.94791| val_0_mse: 23.54039|  0:00:36s\n",
            "epoch 26 | loss: 23.28233| val_0_mse: 23.57151|  0:00:37s\n",
            "epoch 27 | loss: 22.64858| val_0_mse: 23.79212|  0:00:39s\n",
            "epoch 28 | loss: 23.11007| val_0_mse: 25.13217|  0:00:40s\n",
            "epoch 29 | loss: 22.53915| val_0_mse: 24.06417|  0:00:41s\n",
            "epoch 30 | loss: 22.88781| val_0_mse: 24.13643|  0:00:43s\n",
            "epoch 31 | loss: 22.30037| val_0_mse: 24.47935|  0:00:44s\n",
            "epoch 32 | loss: 21.95287| val_0_mse: 24.4345 |  0:00:45s\n",
            "epoch 33 | loss: 21.74927| val_0_mse: 24.19432|  0:00:47s\n",
            "epoch 34 | loss: 21.67417| val_0_mse: 24.34161|  0:00:48s\n",
            "epoch 35 | loss: 21.97472| val_0_mse: 23.20125|  0:00:50s\n",
            "epoch 36 | loss: 22.44987| val_0_mse: 23.65922|  0:00:51s\n",
            "epoch 37 | loss: 22.36757| val_0_mse: 23.81458|  0:00:52s\n",
            "epoch 38 | loss: 22.3942 | val_0_mse: 23.83704|  0:00:54s\n",
            "epoch 39 | loss: 21.60992| val_0_mse: 23.95891|  0:00:55s\n",
            "epoch 40 | loss: 21.59599| val_0_mse: 23.84455|  0:00:57s\n",
            "epoch 41 | loss: 21.30098| val_0_mse: 23.07899|  0:00:58s\n",
            "epoch 42 | loss: 20.92452| val_0_mse: 23.57078|  0:00:59s\n",
            "epoch 43 | loss: 20.59038| val_0_mse: 24.13572|  0:01:01s\n",
            "epoch 44 | loss: 21.20836| val_0_mse: 22.94328|  0:01:02s\n",
            "epoch 45 | loss: 22.00645| val_0_mse: 23.14993|  0:01:04s\n",
            "epoch 46 | loss: 21.62176| val_0_mse: 23.25323|  0:01:05s\n",
            "epoch 47 | loss: 21.65263| val_0_mse: 22.86278|  0:01:06s\n",
            "epoch 48 | loss: 21.45319| val_0_mse: 22.94913|  0:01:08s\n",
            "epoch 49 | loss: 20.96787| val_0_mse: 22.8869 |  0:01:09s\n",
            "epoch 50 | loss: 20.85439| val_0_mse: 23.18127|  0:01:11s\n",
            "epoch 51 | loss: 21.91959| val_0_mse: 23.91048|  0:01:12s\n",
            "epoch 52 | loss: 20.84897| val_0_mse: 22.74688|  0:01:13s\n",
            "epoch 53 | loss: 21.1171 | val_0_mse: 23.8722 |  0:01:15s\n",
            "epoch 54 | loss: 20.88776| val_0_mse: 23.11323|  0:01:16s\n",
            "epoch 55 | loss: 21.17997| val_0_mse: 23.02773|  0:01:18s\n",
            "epoch 56 | loss: 20.78592| val_0_mse: 23.08854|  0:01:19s\n",
            "epoch 57 | loss: 20.52434| val_0_mse: 22.75743|  0:01:20s\n",
            "epoch 58 | loss: 21.05716| val_0_mse: 23.54561|  0:01:22s\n",
            "epoch 59 | loss: 20.53159| val_0_mse: 23.58609|  0:01:23s\n",
            "epoch 60 | loss: 20.4957 | val_0_mse: 22.88098|  0:01:24s\n",
            "epoch 61 | loss: 20.49927| val_0_mse: 23.20411|  0:01:26s\n",
            "epoch 62 | loss: 20.68924| val_0_mse: 22.73301|  0:01:27s\n",
            "epoch 63 | loss: 20.75075| val_0_mse: 22.82154|  0:01:29s\n",
            "epoch 64 | loss: 20.7786 | val_0_mse: 23.36258|  0:01:30s\n",
            "epoch 65 | loss: 21.02284| val_0_mse: 23.57508|  0:01:31s\n",
            "epoch 66 | loss: 20.24522| val_0_mse: 23.74902|  0:01:33s\n",
            "epoch 67 | loss: 20.57508| val_0_mse: 23.31744|  0:01:34s\n",
            "epoch 68 | loss: 20.64884| val_0_mse: 23.49646|  0:01:36s\n",
            "epoch 69 | loss: 20.32295| val_0_mse: 23.59731|  0:01:37s\n",
            "epoch 70 | loss: 19.68488| val_0_mse: 23.89427|  0:01:38s\n",
            "epoch 71 | loss: 19.54894| val_0_mse: 23.18139|  0:01:40s\n",
            "epoch 72 | loss: 19.91665| val_0_mse: 23.65873|  0:01:41s\n",
            "epoch 73 | loss: 19.51731| val_0_mse: 23.35296|  0:01:43s\n",
            "epoch 74 | loss: 19.25288| val_0_mse: 23.31911|  0:01:44s\n",
            "epoch 75 | loss: 19.22423| val_0_mse: 22.75828|  0:01:45s\n",
            "epoch 76 | loss: 19.07045| val_0_mse: 23.1001 |  0:01:47s\n",
            "epoch 77 | loss: 19.2025 | val_0_mse: 23.89941|  0:01:48s\n",
            "epoch 78 | loss: 18.76897| val_0_mse: 22.99027|  0:01:49s\n",
            "epoch 79 | loss: 18.76906| val_0_mse: 23.61864|  0:01:51s\n",
            "epoch 80 | loss: 18.69291| val_0_mse: 22.95326|  0:01:52s\n",
            "epoch 81 | loss: 18.27462| val_0_mse: 24.41663|  0:01:54s\n",
            "epoch 82 | loss: 18.47687| val_0_mse: 23.10974|  0:01:55s\n",
            "\n",
            "Early stopping occurred at epoch 82 with best_epoch = 62 and best_val_0_mse = 22.73301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Test MAE: 3.4267\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 37.36225| val_0_mse: 32.53722|  0:00:01s\n",
            "epoch 1  | loss: 29.21261| val_0_mse: 28.30908|  0:00:02s\n",
            "epoch 2  | loss: 27.04521| val_0_mse: 26.56868|  0:00:04s\n",
            "epoch 3  | loss: 27.35443| val_0_mse: 26.30419|  0:00:05s\n",
            "epoch 4  | loss: 27.78962| val_0_mse: 25.13286|  0:00:07s\n",
            "epoch 5  | loss: 34.66503| val_0_mse: 29.53809|  0:00:08s\n",
            "epoch 6  | loss: 28.54756| val_0_mse: 26.04079|  0:00:09s\n",
            "epoch 7  | loss: 25.83798| val_0_mse: 24.22595|  0:00:11s\n",
            "epoch 8  | loss: 26.02062| val_0_mse: 24.36502|  0:00:12s\n",
            "epoch 9  | loss: 25.42452| val_0_mse: 25.13346|  0:00:13s\n",
            "epoch 10 | loss: 26.23024| val_0_mse: 23.76187|  0:00:15s\n",
            "epoch 11 | loss: 25.00357| val_0_mse: 23.62053|  0:00:16s\n",
            "epoch 12 | loss: 24.74592| val_0_mse: 24.08061|  0:00:18s\n",
            "epoch 13 | loss: 24.35127| val_0_mse: 22.64741|  0:00:19s\n",
            "epoch 14 | loss: 23.35395| val_0_mse: 25.10043|  0:00:21s\n",
            "epoch 15 | loss: 23.60279| val_0_mse: 22.94308|  0:00:22s\n",
            "epoch 16 | loss: 24.03942| val_0_mse: 23.73272|  0:00:23s\n",
            "epoch 17 | loss: 23.99549| val_0_mse: 23.62692|  0:00:25s\n",
            "epoch 18 | loss: 23.61855| val_0_mse: 23.20419|  0:00:26s\n",
            "epoch 19 | loss: 23.02009| val_0_mse: 23.24562|  0:00:28s\n",
            "epoch 20 | loss: 23.22808| val_0_mse: 23.6501 |  0:00:29s\n",
            "epoch 21 | loss: 23.00818| val_0_mse: 22.1085 |  0:00:30s\n",
            "epoch 22 | loss: 23.72632| val_0_mse: 22.48793|  0:00:32s\n",
            "epoch 23 | loss: 23.59758| val_0_mse: 22.72521|  0:00:33s\n",
            "epoch 24 | loss: 23.23358| val_0_mse: 21.72117|  0:00:35s\n",
            "epoch 25 | loss: 23.09071| val_0_mse: 22.61279|  0:00:36s\n",
            "epoch 26 | loss: 22.58166| val_0_mse: 22.61343|  0:00:37s\n",
            "epoch 27 | loss: 23.33858| val_0_mse: 23.312  |  0:00:39s\n",
            "epoch 28 | loss: 23.43857| val_0_mse: 23.27826|  0:00:40s\n",
            "epoch 29 | loss: 23.33329| val_0_mse: 23.24805|  0:00:42s\n",
            "epoch 30 | loss: 22.87188| val_0_mse: 24.77114|  0:00:43s\n",
            "epoch 31 | loss: 23.02976| val_0_mse: 22.54093|  0:00:44s\n",
            "epoch 32 | loss: 22.89938| val_0_mse: 21.25555|  0:00:46s\n",
            "epoch 33 | loss: 22.86385| val_0_mse: 21.75522|  0:00:47s\n",
            "epoch 34 | loss: 22.93251| val_0_mse: 23.47768|  0:00:48s\n",
            "epoch 35 | loss: 22.75695| val_0_mse: 22.45837|  0:00:50s\n",
            "epoch 36 | loss: 23.3671 | val_0_mse: 22.79109|  0:00:51s\n",
            "epoch 37 | loss: 23.54494| val_0_mse: 22.73741|  0:00:53s\n",
            "epoch 38 | loss: 22.9472 | val_0_mse: 22.66668|  0:00:54s\n",
            "epoch 39 | loss: 23.03008| val_0_mse: 22.70006|  0:00:55s\n",
            "epoch 40 | loss: 23.02416| val_0_mse: 21.84154|  0:00:57s\n",
            "epoch 41 | loss: 23.40074| val_0_mse: 22.38955|  0:00:58s\n",
            "epoch 42 | loss: 23.17594| val_0_mse: 22.45506|  0:01:00s\n",
            "epoch 43 | loss: 22.88676| val_0_mse: 21.93517|  0:01:01s\n",
            "epoch 44 | loss: 22.50669| val_0_mse: 21.7921 |  0:01:02s\n",
            "epoch 45 | loss: 23.16048| val_0_mse: 21.2535 |  0:01:04s\n",
            "epoch 46 | loss: 22.78042| val_0_mse: 21.53155|  0:01:05s\n",
            "epoch 47 | loss: 22.61692| val_0_mse: 22.15696|  0:01:07s\n",
            "epoch 48 | loss: 22.98553| val_0_mse: 21.7464 |  0:01:08s\n",
            "epoch 49 | loss: 23.18818| val_0_mse: 23.79847|  0:01:09s\n",
            "epoch 50 | loss: 23.93198| val_0_mse: 22.15749|  0:01:11s\n",
            "epoch 51 | loss: 23.0867 | val_0_mse: 22.48043|  0:01:12s\n",
            "epoch 52 | loss: 22.32606| val_0_mse: 21.89255|  0:01:14s\n",
            "epoch 53 | loss: 22.97198| val_0_mse: 21.93242|  0:01:15s\n",
            "epoch 54 | loss: 22.0218 | val_0_mse: 21.75573|  0:01:16s\n",
            "epoch 55 | loss: 22.82326| val_0_mse: 22.17082|  0:01:18s\n",
            "epoch 56 | loss: 22.09245| val_0_mse: 22.11462|  0:01:19s\n",
            "epoch 57 | loss: 22.23106| val_0_mse: 22.47298|  0:01:20s\n",
            "epoch 58 | loss: 22.30578| val_0_mse: 22.10629|  0:01:22s\n",
            "epoch 59 | loss: 21.50043| val_0_mse: 21.72721|  0:01:23s\n",
            "epoch 60 | loss: 21.63203| val_0_mse: 22.31577|  0:01:25s\n",
            "epoch 61 | loss: 22.25721| val_0_mse: 21.94609|  0:01:26s\n",
            "epoch 62 | loss: 21.86518| val_0_mse: 21.98945|  0:01:27s\n",
            "epoch 63 | loss: 21.53715| val_0_mse: 22.76243|  0:01:29s\n",
            "epoch 64 | loss: 21.98285| val_0_mse: 22.23411|  0:01:30s\n",
            "epoch 65 | loss: 21.74766| val_0_mse: 21.89831|  0:01:32s\n",
            "\n",
            "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_mse = 21.2535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Test MAE: 3.3391\n",
            "\n",
            "Average MAE across folds: 3.3507\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from pytorch_tabnet.tab_model import TabNetRegressor\n",
        "import optuna\n",
        "\n",
        "# 시드 고정\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# 데이터 준비\n",
        "target = '우울증_지수'\n",
        "features = [col for col in df.columns if col != target]\n",
        "\n",
        "X = df[features].values\n",
        "y = df[target].values.reshape(-1, 1)\n",
        "\n",
        "# 데이터 정규화\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "kf = KFold(n_splits=3, shuffle=True, random_state=seed)\n",
        "\n",
        "# Optuna를 사용한 TabNet 하이퍼파라미터 튜닝\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        \"n_d\": trial.suggest_int(\"n_d\", 8, 64, step=8),\n",
        "        \"n_a\": trial.suggest_int(\"n_a\", 8, 64, step=8),\n",
        "        \"n_steps\": trial.suggest_int(\"n_steps\", 3, 10),\n",
        "        \"gamma\": trial.suggest_float(\"gamma\", 1.0, 2.0),\n",
        "        \"lambda_sparse\": trial.suggest_float(\"lambda_sparse\", 0.0001, 0.01, log=True),\n",
        "        \"momentum\": trial.suggest_float(\"momentum\", 0.02, 0.4),\n",
        "        \"optimizer_params\": {\"lr\": 0.02}\n",
        "    }\n",
        "\n",
        "    fold_mae_scores = []\n",
        "    fold = 1\n",
        "\n",
        "    for train_idx, test_idx in kf.split(X, y):\n",
        "        print(f\"\\nFold {fold}:\")\n",
        "\n",
        "        X_train, X_test = X[train_idx], X[test_idx]\n",
        "        y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "        # TabNet 모델 초기화\n",
        "        model = TabNetRegressor(**params)\n",
        "\n",
        "        # 모델 학습\n",
        "        model.fit(\n",
        "            X_train, y_train,\n",
        "            eval_set=[(X_test, y_test)],\n",
        "            patience=20, max_epochs=200,\n",
        "            batch_size=128, virtual_batch_size=32\n",
        "        )\n",
        "\n",
        "        # 예측 및 MAE 계산\n",
        "        y_pred = model.predict(X_test)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "        print(f\"Fold {fold} Test MAE: {mae:.4f}\")\n",
        "        fold_mae_scores.append(mae)\n",
        "        fold += 1\n",
        "\n",
        "    return np.mean(fold_mae_scores)\n",
        "\n",
        "# Optuna 실행\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=5)\n",
        "\n",
        "# 최적 하이퍼파라미터 출력\n",
        "print(\"Best Hyperparameters:\", study.best_params)\n",
        "\n",
        "# 최적 하이퍼파라미터로 모델 학습 및 평가\n",
        "best_params = study.best_params\n",
        "fold_mae_scores = []\n",
        "fold = 1\n",
        "\n",
        "for train_idx, test_idx in kf.split(X, y):\n",
        "    print(f\"\\nFold {fold}:\")\n",
        "\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    # 최적 하이퍼파라미터 기반 TabNet 모델 생성\n",
        "    model = TabNetRegressor(**best_params)\n",
        "\n",
        "    # 모델 학습\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_test, y_test)],\n",
        "        patience=20, max_epochs=200,\n",
        "        batch_size=128, virtual_batch_size=32\n",
        "    )\n",
        "\n",
        "    # 예측 및 MAE 계산\n",
        "    y_pred = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "    print(f\"Fold {fold} Test MAE: {mae:.4f}\")\n",
        "    fold_mae_scores.append(mae)\n",
        "    fold += 1\n",
        "\n",
        "# 최종 평균 MAE 출력\n",
        "print(f\"\\nAverage MAE across folds: {np.mean(fold_mae_scores):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🚀 NODE 저장소를 클론하고 폴더로 이동\n",
        "!git clone https://github.com/Qwicen/node.git\n",
        "%cd node\n",
        "\n",
        "# 🚀 필요 패키지 설치\n",
        "!pip install -r requirements.txt\n",
        "!pip install category_encoders numpy pandas scikit-learn matplotlib tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ev6-VYMlNh9",
        "outputId": "8448810a-2437-48f6-e0be-772cdbe16f0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'node'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 33 (delta 4), reused 4 (delta 4), pack-reused 22 (from 1)\u001b[K\n",
            "Receiving objects: 100% (33/33), 242.00 KiB | 995.00 KiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n",
            "/content/node/node/node\n",
            "Collecting https://github.com/facebookresearch/qhoptim/archive/master.zip (from -r requirements.txt (line 14))\n",
            "  Using cached https://github.com/facebookresearch/qhoptim/archive/master.zip\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.5.1+cu124)\n",
            "Requirement already satisfied: numpy>=0.13 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.17 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (1.6.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement catboost==0.12.2 (from versions: 1.2, 1.2.1, 1.2.1.1, 1.2.2, 1.2.3, 1.2.5, 1.2.6, 1.2.7)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for catboost==0.12.2\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: category_encoders in /usr/local/lib/python3.11/dist-packages (2.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.13.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/node\")\n"
      ],
      "metadata": {
        "id": "UA36wvb-pRK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!grep -i \"class \" /content/node/lib/*.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xru7REMjpUgW",
        "outputId": "f7280bb7-cf84-4590-fd0b-4c6302d4f0f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/node/lib/arch.py:class DenseBlock(nn.Sequential):\n",
            "/content/node/lib/data.py:class Dataset:\n",
            "/content/node/lib/data.py:        Dataset is a dataclass that contains all training and evaluation data required for an experiment\n",
            "/content/node/lib/nn_utils.py:class SparsemaxFunction(Function):\n",
            "/content/node/lib/nn_utils.py:class Entmax15Function(Function):\n",
            "/content/node/lib/nn_utils.py:class Entmoid15(Function):\n",
            "/content/node/lib/nn_utils.py:class Lambda(nn.Module):\n",
            "/content/node/lib/nn_utils.py:class ModuleWithInit(nn.Module):\n",
            "/content/node/lib/nn_utils.py:    \"\"\" Base class for pytorch module with data-aware initializer on first batch \"\"\"\n",
            "/content/node/lib/odst.py:class ODST(ModuleWithInit):\n",
            "/content/node/lib/trainer.py:class Trainer(nn.Module):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -30 /content/node/lib/odst.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIFXrEoUprSj",
        "outputId": "c97c379c-5650-4def-bb8d-30e0a4bd9029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import torch\n",
            "import torch.nn as nn\n",
            "import torch.nn.functional as F\n",
            "import numpy as np\n",
            "\n",
            "from .nn_utils import sparsemax, sparsemoid, ModuleWithInit\n",
            "from .utils import check_numpy\n",
            "from warnings import warn\n",
            "\n",
            "\n",
            "class ODST(ModuleWithInit):\n",
            "    def __init__(self, in_features, num_trees, depth=6, tree_dim=1, flatten_output=True,\n",
            "                 choice_function=sparsemax, bin_function=sparsemoid,\n",
            "                 initialize_response_=nn.init.normal_, initialize_selection_logits_=nn.init.uniform_,\n",
            "                 threshold_init_beta=1.0, threshold_init_cutoff=1.0,\n",
            "                 ):\n",
            "        \"\"\"\n",
            "        Oblivious Differentiable Sparsemax Trees. http://tinyurl.com/odst-readmore\n",
            "        One can drop (sic!) this module anywhere instead of nn.Linear\n",
            "        :param in_features: number of features in the input tensor\n",
            "        :param num_trees: number of trees in this layer\n",
            "        :param tree_dim: number of response channels in the response of individual tree\n",
            "        :param depth: number of splits in every tree\n",
            "        :param flatten_output: if False, returns [..., num_trees, tree_dim],\n",
            "            by default returns [..., num_trees * tree_dim]\n",
            "        :param choice_function: f(tensor, dim) -> R_simplex computes feature weights s.t. f(tensor, dim).sum(dim) == 1\n",
            "        :param bin_function: f(tensor) -> R[0, 1], computes tree leaf weights\n",
            "\n",
            "        :param initialize_response_: in-place initializer for tree output tensor\n",
            "        :param initialize_selection_logits_: in-place initializer for logits that select features for the tree\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m48ixgWJnhEt",
        "outputId": "0aca492c-0948-4150-a7d1-b936f0bdda61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.11/dist-packages (2.8.0)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.13.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (24.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (4.25.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lib.odst import ODST\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "yhYRQXW-m4kY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# NODE 라이브러리 불러오기\n",
        "from lib.odst import ODST\n",
        "\n",
        "# ✅ 시드 고정\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# ✅ 데이터 준비 (사용자 제공 데이터 그대로 사용)\n",
        "target = '우울증_지수'\n",
        "features = [col for col in df.columns if col != target]\n",
        "\n",
        "X = df[features].values\n",
        "y = df[target].values.reshape(-1, 1)\n",
        "\n",
        "# ✅ 데이터 정규화\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# ✅ K-Fold 설정\n",
        "kf = KFold(n_splits=3, shuffle=True, random_state=seed)\n",
        "\n",
        "# ✅ GPU 사용 가능 여부 확인\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ✅ ODST 기반 NODE 모델 정의\n",
        "class NODEModel(nn.Module):\n",
        "    def __init__(self, input_dim, num_trees=1024, depth=6, tree_dim=1, dropout=0.2):\n",
        "        super(NODEModel, self).__init__()\n",
        "        self.odst = ODST(\n",
        "            in_features=input_dim,  # 입력 특징 개수\n",
        "            num_trees=num_trees,  # 트리 개수\n",
        "            depth=depth,  # 트리 깊이\n",
        "            tree_dim=tree_dim,\n",
        "            flatten_output=True\n",
        "        )\n",
        "        self.output_layer = nn.Linear(num_trees * tree_dim, 1)  # 최종 출력 레이어\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.odst(x)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "# ✅ 기본 하이퍼파라미터 설정\n",
        "params = {\n",
        "    \"num_trees\": 16,\n",
        "    \"depth\": 2,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"epochs\": 100,\n",
        "    \"batch_size\": 16,\n",
        "    \"patience\": 10  # Early Stopping patience (10 epoch 동안 개선 없으면 중단)\n",
        "}\n",
        "\n",
        "# ✅ 모델 학습 및 평가\n",
        "fold_mae_scores = []\n",
        "fold = 1\n",
        "\n",
        "for train_idx, test_idx in kf.split(X, y):\n",
        "    print(f\"\\nFold {fold}:\")\n",
        "\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    # ✅ NumPy 데이터를 PyTorch 텐서로 변환 (GPU 사용 가능)\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "    X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1).to(device)\n",
        "    y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1).to(device)\n",
        "\n",
        "    # ✅ NODE 모델 초기화\n",
        "    model = NODEModel(\n",
        "        input_dim=X_train.shape[1],\n",
        "        num_trees=params[\"num_trees\"],\n",
        "        depth=params[\"depth\"],\n",
        "    ).to(device)\n",
        "\n",
        "    # ✅ 옵티마이저 및 손실 함수 설정\n",
        "    optimizer = optim.Adam(model.parameters(), lr=params[\"learning_rate\"])\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # ✅ 데이터 로더\n",
        "    train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
        "\n",
        "    # ✅ Early Stopping 설정\n",
        "    best_mae = float(\"inf\")\n",
        "    best_epoch = 0\n",
        "    patience_counter = 0\n",
        "\n",
        "    # ✅ 모델 학습\n",
        "    for epoch in range(params[\"epochs\"]):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        # ✅ 검증\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred = model(X_test).cpu().detach().numpy()\n",
        "            y_test_original = y_test.cpu().detach().numpy()\n",
        "            mae = mean_absolute_error(y_test_original, y_pred)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss = {epoch_loss / len(train_loader):.4f}, Test MAE = {mae:.4f}\")\n",
        "\n",
        "        # ✅ Early Stopping 체크\n",
        "        if mae < best_mae:\n",
        "            best_mae = mae\n",
        "            best_epoch = epoch\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= params[\"patience\"]:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break  # Early Stopping 적용\n",
        "\n",
        "    print(f\"Best Epoch: {best_epoch+1}, Best MAE: {best_mae:.4f}\")\n",
        "    fold_mae_scores.append(best_mae)\n",
        "    fold += 1\n",
        "\n",
        "# ✅ 최종 평균 MAE 출력\n",
        "print(f\"\\n🔥 최종 평균 MAE: {np.mean(fold_mae_scores):.4f}\")\n"
      ],
      "metadata": {
        "id": "013kIcDA4xlN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b5f32bd-9a0c-43dc-dcb3-b65139ad86df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
            "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss = 26.2945, Test MAE = 3.4925\n",
            "Epoch 2: Train Loss = 22.0095, Test MAE = 3.5747\n",
            "Epoch 3: Train Loss = 21.1557, Test MAE = 3.2908\n",
            "Epoch 4: Train Loss = 20.5295, Test MAE = 3.7173\n",
            "Epoch 5: Train Loss = 20.4546, Test MAE = 3.4578\n",
            "Epoch 6: Train Loss = 20.2250, Test MAE = 3.2158\n",
            "Epoch 7: Train Loss = 20.1936, Test MAE = 3.5252\n",
            "Epoch 8: Train Loss = 20.2296, Test MAE = 3.2897\n",
            "Epoch 9: Train Loss = 20.1829, Test MAE = 3.3128\n",
            "Epoch 10: Train Loss = 20.2112, Test MAE = 3.4522\n",
            "Epoch 11: Train Loss = 20.0608, Test MAE = 3.2693\n",
            "Epoch 12: Train Loss = 20.0677, Test MAE = 3.3411\n",
            "Epoch 13: Train Loss = 19.9298, Test MAE = 3.3131\n",
            "Epoch 14: Train Loss = 19.9675, Test MAE = 3.2879\n",
            "Epoch 15: Train Loss = 19.9276, Test MAE = 3.2714\n",
            "Epoch 16: Train Loss = 19.8906, Test MAE = 3.3483\n",
            "Early stopping at epoch 16\n",
            "Best Epoch: 6, Best MAE: 3.2158\n",
            "\n",
            "Fold 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
            "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss = 26.0795, Test MAE = 3.5218\n",
            "Epoch 2: Train Loss = 21.4973, Test MAE = 3.3714\n",
            "Epoch 3: Train Loss = 20.6715, Test MAE = 3.3414\n",
            "Epoch 4: Train Loss = 20.2983, Test MAE = 3.4560\n",
            "Epoch 5: Train Loss = 20.0092, Test MAE = 3.2354\n",
            "Epoch 6: Train Loss = 19.9583, Test MAE = 3.4887\n",
            "Epoch 7: Train Loss = 19.9017, Test MAE = 3.3949\n",
            "Epoch 8: Train Loss = 19.8386, Test MAE = 3.3469\n",
            "Epoch 9: Train Loss = 19.6566, Test MAE = 3.5505\n",
            "Epoch 10: Train Loss = 19.6642, Test MAE = 3.4755\n",
            "Epoch 11: Train Loss = 19.4991, Test MAE = 3.4789\n",
            "Epoch 12: Train Loss = 19.6271, Test MAE = 3.3029\n",
            "Epoch 13: Train Loss = 19.4902, Test MAE = 3.4916\n",
            "Epoch 14: Train Loss = 19.5341, Test MAE = 3.3092\n",
            "Epoch 15: Train Loss = 19.5584, Test MAE = 3.3398\n",
            "Early stopping at epoch 15\n",
            "Best Epoch: 5, Best MAE: 3.2354\n",
            "\n",
            "Fold 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/node/lib/odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
            "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss = 25.5133, Test MAE = 3.3969\n",
            "Epoch 2: Train Loss = 21.9201, Test MAE = 3.3008\n",
            "Epoch 3: Train Loss = 21.2855, Test MAE = 3.4099\n",
            "Epoch 4: Train Loss = 21.0327, Test MAE = 3.2208\n",
            "Epoch 5: Train Loss = 20.8404, Test MAE = 3.5158\n",
            "Epoch 6: Train Loss = 20.6219, Test MAE = 3.2949\n",
            "Epoch 7: Train Loss = 20.4546, Test MAE = 3.2521\n",
            "Epoch 8: Train Loss = 20.4716, Test MAE = 3.3559\n",
            "Epoch 9: Train Loss = 20.2943, Test MAE = 3.3293\n",
            "Epoch 10: Train Loss = 20.4233, Test MAE = 3.3821\n",
            "Epoch 11: Train Loss = 20.3247, Test MAE = 3.3150\n",
            "Epoch 12: Train Loss = 20.2427, Test MAE = 3.2595\n",
            "Epoch 13: Train Loss = 20.3373, Test MAE = 3.2888\n",
            "Epoch 14: Train Loss = 20.1641, Test MAE = 3.3097\n",
            "Early stopping at epoch 14\n",
            "Best Epoch: 4, Best MAE: 3.2208\n",
            "\n",
            "🔥 최종 평균 MAE: 3.2240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "\n",
        "!pip install dnfnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPuQs6841Cpm",
        "outputId": "b12e25fb-7b5e-4556-a554-48831a23ea42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement dnfnet (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for dnfnet\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ✅ 시드 고정\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# ✅ 데이터 준비\n",
        "target = '우울증_지수'\n",
        "features = [col for col in df.columns if col != target]\n",
        "\n",
        "X = df[features].values\n",
        "y = df[target].values.reshape(-1, 1)\n",
        "\n",
        "# ✅ 데이터 정규화\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# ✅ K-Fold 설정\n",
        "kf = KFold(n_splits=3, shuffle=True, random_state=seed)\n",
        "\n",
        "# ✅ GPU 사용 가능 여부 확인\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ✅ 1D-CNN 모델 정의\n",
        "class CNN1D(nn.Module):\n",
        "    def __init__(self, input_dim, num_filters=32, kernel_size=3, hidden_dim=64):\n",
        "        super(CNN1D, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=num_filters, kernel_size=kernel_size, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
        "\n",
        "        # ✅ Fully Connected 입력 크기 자동 계산\n",
        "        conv_out_dim = input_dim // 2  # MaxPool 적용 후 크기 조정\n",
        "        self.fc1 = nn.Linear(num_filters * conv_out_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# ✅ 기본 하이퍼파라미터 설정\n",
        "num_filters = 32\n",
        "kernel_size = 3\n",
        "hidden_dim = 64\n",
        "learning_rate = 0.001\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "early_stopping_rounds = 10  # 조기 종료 기준\n",
        "\n",
        "# ✅ 3-Fold 교차검증\n",
        "fold_mae_scores = []\n",
        "fold = 1\n",
        "\n",
        "for train_idx, test_idx in kf.split(X, y):\n",
        "    print(f\"\\n🚀 Fold {fold} 시작:\")\n",
        "\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    # ✅ PyTorch 텐서 변환 및 차원 추가 (1D-CNN을 위해)\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "    X_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1).to(device)\n",
        "    y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1).to(device)\n",
        "\n",
        "    # ✅ 1D-CNN 모델 초기화\n",
        "    model = CNN1D(X_train.shape[2], num_filters, kernel_size, hidden_dim).to(device)\n",
        "\n",
        "    # ✅ 옵티마이저 및 손실 함수 설정\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # ✅ 데이터 로더\n",
        "    train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # ✅ 조기 종료 변수\n",
        "    best_mae = float(\"inf\")\n",
        "    early_stop_counter = 0\n",
        "\n",
        "    # ✅ 모델 학습\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        # ✅ 평가 (매 에포크마다 테스트)\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred = model(X_test).cpu().numpy()\n",
        "            y_test_original = y_test.cpu().numpy()\n",
        "\n",
        "        mae = mean_absolute_error(y_test_original, y_pred)\n",
        "        print(f\"Epoch {epoch + 1}: Train Loss = {epoch_loss / len(train_loader):.4f}, Test MAE = {mae:.4f}\")\n",
        "\n",
        "        # ✅ 조기 종료 조건 확인\n",
        "        if mae < best_mae:\n",
        "            best_mae = mae\n",
        "            early_stop_counter = 0\n",
        "        else:\n",
        "            early_stop_counter += 1\n",
        "\n",
        "        if early_stop_counter >= early_stopping_rounds:\n",
        "            print(f\"⏹ Early stopping at epoch {epoch + 1}\")\n",
        "            break\n",
        "\n",
        "    print(f\"✅ Fold {fold} 완료: Best MAE = {best_mae:.4f}\")\n",
        "    fold_mae_scores.append(best_mae)\n",
        "    fold += 1\n",
        "\n",
        "# ✅ 최종 평균 MAE 출력\n",
        "print(f\"\\n🔥 최종 평균 MAE: {np.mean(fold_mae_scores):.4f}\")\n"
      ],
      "metadata": {
        "id": "xoP_Hp8k5IVI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ff21e86-3ef7-4ea0-e32d-b2340e95f7bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Fold 1 시작:\n",
            "Epoch 1: Train Loss = 24.6942, Test MAE = 3.3558\n",
            "Epoch 2: Train Loss = 21.3555, Test MAE = 3.2549\n",
            "Epoch 3: Train Loss = 20.6278, Test MAE = 3.2743\n",
            "Epoch 4: Train Loss = 20.2719, Test MAE = 3.4271\n",
            "Epoch 5: Train Loss = 20.0946, Test MAE = 3.4008\n",
            "Epoch 6: Train Loss = 19.8338, Test MAE = 3.3113\n",
            "Epoch 7: Train Loss = 19.8887, Test MAE = 3.4095\n",
            "Epoch 8: Train Loss = 19.7852, Test MAE = 3.4854\n",
            "Epoch 9: Train Loss = 19.2611, Test MAE = 3.4602\n",
            "Epoch 10: Train Loss = 19.1771, Test MAE = 3.3147\n",
            "Epoch 11: Train Loss = 19.0200, Test MAE = 3.3005\n",
            "Epoch 12: Train Loss = 18.8879, Test MAE = 3.3628\n",
            "⏹ Early stopping at epoch 12\n",
            "✅ Fold 1 완료: Best MAE = 3.2549\n",
            "\n",
            "🚀 Fold 2 시작:\n",
            "Epoch 1: Train Loss = 25.8502, Test MAE = 3.5748\n",
            "Epoch 2: Train Loss = 21.5779, Test MAE = 3.3136\n",
            "Epoch 3: Train Loss = 20.9900, Test MAE = 3.2913\n",
            "Epoch 4: Train Loss = 20.5157, Test MAE = 3.3966\n",
            "Epoch 5: Train Loss = 20.1164, Test MAE = 3.2499\n",
            "Epoch 6: Train Loss = 20.2979, Test MAE = 3.4521\n",
            "Epoch 7: Train Loss = 19.7706, Test MAE = 3.2441\n",
            "Epoch 8: Train Loss = 19.4880, Test MAE = 3.2878\n",
            "Epoch 9: Train Loss = 19.5177, Test MAE = 3.4275\n",
            "Epoch 10: Train Loss = 19.1036, Test MAE = 3.3030\n",
            "Epoch 11: Train Loss = 18.8804, Test MAE = 3.3174\n",
            "Epoch 12: Train Loss = 18.9609, Test MAE = 3.2606\n",
            "Epoch 13: Train Loss = 18.7210, Test MAE = 3.3379\n",
            "Epoch 14: Train Loss = 18.3433, Test MAE = 3.3948\n",
            "Epoch 15: Train Loss = 18.4545, Test MAE = 3.3489\n",
            "Epoch 16: Train Loss = 18.3066, Test MAE = 3.3788\n",
            "Epoch 17: Train Loss = 18.2527, Test MAE = 3.6410\n",
            "⏹ Early stopping at epoch 17\n",
            "✅ Fold 2 완료: Best MAE = 3.2441\n",
            "\n",
            "🚀 Fold 3 시작:\n",
            "Epoch 1: Train Loss = 24.7169, Test MAE = 3.5398\n",
            "Epoch 2: Train Loss = 21.7547, Test MAE = 3.2091\n",
            "Epoch 3: Train Loss = 21.0616, Test MAE = 3.1501\n",
            "Epoch 4: Train Loss = 20.6727, Test MAE = 3.3997\n",
            "Epoch 5: Train Loss = 20.4369, Test MAE = 3.3169\n",
            "Epoch 6: Train Loss = 20.1897, Test MAE = 3.2420\n",
            "Epoch 7: Train Loss = 20.0119, Test MAE = 3.1913\n",
            "Epoch 8: Train Loss = 19.6921, Test MAE = 3.4607\n",
            "Epoch 9: Train Loss = 19.5337, Test MAE = 3.3396\n",
            "Epoch 10: Train Loss = 19.3675, Test MAE = 3.2229\n",
            "Epoch 11: Train Loss = 19.1089, Test MAE = 3.3352\n",
            "Epoch 12: Train Loss = 19.0642, Test MAE = 3.3165\n",
            "Epoch 13: Train Loss = 18.8924, Test MAE = 3.5133\n",
            "⏹ Early stopping at epoch 13\n",
            "✅ Fold 3 완료: Best MAE = 3.1501\n",
            "\n",
            "🔥 최종 평균 MAE: 3.2163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import xgboost as xgb\n",
        "from pytorch_tabnet.tab_model import TabNetRegressor\n",
        "\n",
        "# 시드 고정\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "# 원하는 배치 크기로 설정\n",
        "batch_size = 32  # 예: 기존 32에서 16으로 변경\n",
        "\n",
        "# PyTorch DataLoader 설정 시 batch_size 적용\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 데이터 준비\n",
        "target = '우울증_지수'\n",
        "features = [col for col in df.columns if col != target]\n",
        "\n",
        "X = df[features].values\n",
        "y = df[target].values.reshape(-1, 1)\n",
        "\n",
        "# 데이터 정규화\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "kf = KFold(n_splits=3, shuffle=True, random_state=seed)\n",
        "\n",
        "# 개별 모델의 예측값 및 MAE 저장 리스트\n",
        "preds_XGB, preds_TabNet, preds_NODE, preds_CNN, y_true_list = [], [], [], [], []\n",
        "mae_scores = {}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "for train_idx, test_idx in kf.split(X, y):\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "    y_true_list.append(y_test)\n",
        "\n",
        "    # 🔹 XGBoost 모델 학습 및 예측\n",
        "    model_xgb = xgb.XGBRegressor(\n",
        "        alpha=1, colsample_bytree=1.0, lambda_=10, learning_rate=0.05,\n",
        "        max_depth=7, n_estimators=100, subsample=0.5\n",
        "    )\n",
        "    model_xgb.fit(X_train, y_train.ravel())\n",
        "    pred_xgb = model_xgb.predict(X_test)\n",
        "    preds_XGB.append(pred_xgb)\n",
        "    mae_scores[\"XGBoost\"] = mean_absolute_error(y_test, pred_xgb)\n",
        "\n",
        "    # 🔹 TabNet 모델 학습 및 예측\n",
        "    model_tabnet = TabNetRegressor(\n",
        "        n_d=48, n_a=32, n_steps=7, gamma=1.27,\n",
        "        lambda_sparse=0.00065, momentum=0.105\n",
        "    )\n",
        "    model_tabnet.fit(X_train, y_train, eval_set=[(X_test, y_test)], max_epochs=100, patience=10)\n",
        "    pred_tabnet = model_tabnet.predict(X_test).squeeze()\n",
        "    preds_TabNet.append(pred_tabnet)\n",
        "    mae_scores[\"TabNet\"] = mean_absolute_error(y_test, pred_tabnet)\n",
        "\n",
        "    # 🔹 NODE 모델 학습 및 예측\n",
        "    model_node = NODEModel(input_dim=X_train.shape[1], num_trees=16, depth=2).to(device)\n",
        "    optimizer = optim.Adam(model_node.parameters(), lr=0.01)\n",
        "    criterion = nn.MSELoss()\n",
        "    train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "    test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1).to(device)\n",
        "\n",
        "    for epoch in range(100):\n",
        "        model_node.train()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_node(train_tensor)\n",
        "        loss = criterion(outputs, y_train_tensor)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model_node.eval()\n",
        "    with torch.no_grad():\n",
        "        pred_node = model_node(test_tensor).cpu().numpy().squeeze()\n",
        "        preds_NODE.append(pred_node)\n",
        "        mae_scores[\"NODE\"] = mean_absolute_error(y_test, pred_node)\n",
        "\n",
        "    # 🔹 1D-CNN 모델 학습 및 예측\n",
        "    model_cnn = CNN1D(X_train.shape[1], 32, 3, 64).to(device)\n",
        "    optimizer_cnn = optim.Adam(model_cnn.parameters(), lr=0.001)\n",
        "    train_cnn_tensor = train_tensor.unsqueeze(1)\n",
        "    test_cnn_tensor = test_tensor.unsqueeze(1)\n",
        "\n",
        "    for epoch in range(100):\n",
        "        model_cnn.train()\n",
        "        optimizer_cnn.zero_grad()\n",
        "        outputs_cnn = model_cnn(train_cnn_tensor)\n",
        "        loss = criterion(outputs_cnn, y_train_tensor)\n",
        "        loss.backward()\n",
        "        optimizer_cnn.step()\n",
        "\n",
        "    model_cnn.eval()\n",
        "    with torch.no_grad():\n",
        "        pred_cnn = model_cnn(test_cnn_tensor).cpu().numpy().squeeze()\n",
        "        preds_CNN.append(pred_cnn)\n",
        "        mae_scores[\"1D-CNN\"] = mean_absolute_error(y_test, pred_cnn)\n",
        "\n",
        "# ✅ MAE 기반 가중치 자동 계산\n",
        "inverse_mae = {k: 1 / v for k, v in mae_scores.items()}  # MAE의 역수 (낮을수록 높은 가중치)\n",
        "total_inv_mae = sum(inverse_mae.values())  # 정규화 기준\n",
        "\n",
        "weights = {k: v / total_inv_mae for k, v in inverse_mae.items()}  # 정규화된 가중치\n",
        "print(f\"🚀 자동 계산된 가중치: {weights}\")\n",
        "\n",
        "# ✅ 최종 가중 앙상블 예측\n",
        "ensemble_preds = []\n",
        "y_true_final = np.concatenate(y_true_list)\n",
        "\n",
        "for i in range(len(preds_XGB)):\n",
        "    y_pred_ensemble = (\n",
        "        weights[\"XGBoost\"] * preds_XGB[i] +\n",
        "        weights[\"TabNet\"] * preds_TabNet[i] +\n",
        "        weights[\"NODE\"] * preds_NODE[i] +\n",
        "        weights[\"1D-CNN\"] * preds_CNN[i]\n",
        "    )\n",
        "    ensemble_preds.append(y_pred_ensemble)\n",
        "\n",
        "ensemble_preds = np.concatenate(ensemble_preds)\n",
        "final_mae = mean_absolute_error(y_true_final, ensemble_preds)\n",
        "\n",
        "print(f\"🔥 최종 가중치 앙상블 MAE: {final_mae:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQZWOgXHAUuC",
        "outputId": "2192844a-97b0-4d8a-f582-1813b8d8c39a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:18:52] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"lambda_\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 50.09723| val_0_mse: 32.63522|  0:00:00s\n",
            "epoch 1  | loss: 34.84437| val_0_mse: 34.48961|  0:00:00s\n",
            "epoch 2  | loss: 33.22643| val_0_mse: 31.89543|  0:00:00s\n",
            "epoch 3  | loss: 27.67261| val_0_mse: 31.39692|  0:00:01s\n",
            "epoch 4  | loss: 28.99846| val_0_mse: 28.63995|  0:00:01s\n",
            "epoch 5  | loss: 26.21933| val_0_mse: 27.66517|  0:00:01s\n",
            "epoch 6  | loss: 27.53365| val_0_mse: 28.69342|  0:00:01s\n",
            "epoch 7  | loss: 25.08959| val_0_mse: 28.69568|  0:00:02s\n",
            "epoch 8  | loss: 25.61911| val_0_mse: 28.7043 |  0:00:02s\n",
            "epoch 9  | loss: 23.7905 | val_0_mse: 26.91342|  0:00:02s\n",
            "epoch 10 | loss: 23.88861| val_0_mse: 27.66913|  0:00:02s\n",
            "epoch 11 | loss: 25.15065| val_0_mse: 28.55071|  0:00:03s\n",
            "epoch 12 | loss: 25.38397| val_0_mse: 27.38991|  0:00:03s\n",
            "epoch 13 | loss: 24.80045| val_0_mse: 25.778  |  0:00:03s\n",
            "epoch 14 | loss: 24.00399| val_0_mse: 26.68838|  0:00:04s\n",
            "epoch 15 | loss: 24.77407| val_0_mse: 25.82235|  0:00:04s\n",
            "epoch 16 | loss: 23.79518| val_0_mse: 26.64012|  0:00:04s\n",
            "epoch 17 | loss: 23.52296| val_0_mse: 26.3201 |  0:00:04s\n",
            "epoch 18 | loss: 23.86645| val_0_mse: 25.7707 |  0:00:05s\n",
            "epoch 19 | loss: 23.2086 | val_0_mse: 24.6771 |  0:00:05s\n",
            "epoch 20 | loss: 22.71458| val_0_mse: 24.63716|  0:00:05s\n",
            "epoch 21 | loss: 23.63722| val_0_mse: 24.48201|  0:00:05s\n",
            "epoch 22 | loss: 23.33504| val_0_mse: 24.37311|  0:00:06s\n",
            "epoch 23 | loss: 23.34988| val_0_mse: 24.60575|  0:00:06s\n",
            "epoch 24 | loss: 22.82568| val_0_mse: 24.20386|  0:00:06s\n",
            "epoch 25 | loss: 22.358  | val_0_mse: 25.40582|  0:00:06s\n",
            "epoch 26 | loss: 22.50827| val_0_mse: 25.52063|  0:00:07s\n",
            "epoch 27 | loss: 22.70261| val_0_mse: 25.1004 |  0:00:07s\n",
            "epoch 28 | loss: 23.45444| val_0_mse: 24.68447|  0:00:07s\n",
            "epoch 29 | loss: 23.80982| val_0_mse: 24.71721|  0:00:07s\n",
            "epoch 30 | loss: 23.43381| val_0_mse: 25.51661|  0:00:08s\n",
            "epoch 31 | loss: 23.55004| val_0_mse: 25.32593|  0:00:08s\n",
            "epoch 32 | loss: 24.0007 | val_0_mse: 26.03036|  0:00:08s\n",
            "epoch 33 | loss: 23.75668| val_0_mse: 25.2846 |  0:00:08s\n",
            "epoch 34 | loss: 22.44919| val_0_mse: 25.01011|  0:00:09s\n",
            "\n",
            "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_mse = 24.20386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:19:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"lambda_\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 51.48784| val_0_mse: 29.83645|  0:00:00s\n",
            "epoch 1  | loss: 38.02229| val_0_mse: 32.87148|  0:00:00s\n",
            "epoch 2  | loss: 36.00107| val_0_mse: 29.20362|  0:00:00s\n",
            "epoch 3  | loss: 29.32714| val_0_mse: 32.6339 |  0:00:01s\n",
            "epoch 4  | loss: 32.04841| val_0_mse: 31.92286|  0:00:01s\n",
            "epoch 5  | loss: 29.85668| val_0_mse: 29.60757|  0:00:01s\n",
            "epoch 6  | loss: 26.69147| val_0_mse: 26.87645|  0:00:01s\n",
            "epoch 7  | loss: 28.95467| val_0_mse: 26.5677 |  0:00:02s\n",
            "epoch 8  | loss: 27.50335| val_0_mse: 26.03762|  0:00:02s\n",
            "epoch 9  | loss: 26.1206 | val_0_mse: 26.57207|  0:00:02s\n",
            "epoch 10 | loss: 25.09419| val_0_mse: 26.10122|  0:00:02s\n",
            "epoch 11 | loss: 25.11197| val_0_mse: 25.72283|  0:00:03s\n",
            "epoch 12 | loss: 25.76796| val_0_mse: 25.08861|  0:00:03s\n",
            "epoch 13 | loss: 24.58597| val_0_mse: 25.70245|  0:00:03s\n",
            "epoch 14 | loss: 22.96366| val_0_mse: 26.3454 |  0:00:04s\n",
            "epoch 15 | loss: 24.68211| val_0_mse: 24.86407|  0:00:04s\n",
            "epoch 16 | loss: 24.68716| val_0_mse: 25.16132|  0:00:04s\n",
            "epoch 17 | loss: 24.89486| val_0_mse: 25.38824|  0:00:04s\n",
            "epoch 18 | loss: 24.44433| val_0_mse: 25.10085|  0:00:05s\n",
            "epoch 19 | loss: 23.78413| val_0_mse: 24.96839|  0:00:05s\n",
            "epoch 20 | loss: 23.93046| val_0_mse: 25.71244|  0:00:05s\n",
            "epoch 21 | loss: 24.16052| val_0_mse: 24.70991|  0:00:05s\n",
            "epoch 22 | loss: 24.27465| val_0_mse: 24.72342|  0:00:06s\n",
            "epoch 23 | loss: 23.45992| val_0_mse: 24.48458|  0:00:06s\n",
            "epoch 24 | loss: 24.57896| val_0_mse: 25.29766|  0:00:06s\n",
            "epoch 25 | loss: 23.63893| val_0_mse: 25.55708|  0:00:06s\n",
            "epoch 26 | loss: 23.7567 | val_0_mse: 24.61357|  0:00:07s\n",
            "epoch 27 | loss: 23.86242| val_0_mse: 24.32879|  0:00:07s\n",
            "epoch 28 | loss: 23.57677| val_0_mse: 24.0896 |  0:00:07s\n",
            "epoch 29 | loss: 24.10323| val_0_mse: 24.13311|  0:00:07s\n",
            "epoch 30 | loss: 23.39603| val_0_mse: 23.99106|  0:00:08s\n",
            "epoch 31 | loss: 23.67568| val_0_mse: 23.45606|  0:00:08s\n",
            "epoch 32 | loss: 23.85058| val_0_mse: 23.78592|  0:00:08s\n",
            "epoch 33 | loss: 24.2879 | val_0_mse: 24.15617|  0:00:08s\n",
            "epoch 34 | loss: 24.74345| val_0_mse: 24.46272|  0:00:09s\n",
            "epoch 35 | loss: 24.01468| val_0_mse: 26.65691|  0:00:09s\n",
            "epoch 36 | loss: 25.43356| val_0_mse: 26.11074|  0:00:09s\n",
            "epoch 37 | loss: 24.39968| val_0_mse: 24.78397|  0:00:09s\n",
            "epoch 38 | loss: 24.92597| val_0_mse: 24.76077|  0:00:10s\n",
            "epoch 39 | loss: 23.74831| val_0_mse: 23.67163|  0:00:10s\n",
            "epoch 40 | loss: 23.0553 | val_0_mse: 24.62147|  0:00:10s\n",
            "epoch 41 | loss: 22.8941 | val_0_mse: 24.51779|  0:00:11s\n",
            "\n",
            "Early stopping occurred at epoch 41 with best_epoch = 31 and best_val_0_mse = 23.45606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:19:14] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"lambda_\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 51.99469| val_0_mse: 30.56776|  0:00:00s\n",
            "epoch 1  | loss: 37.45315| val_0_mse: 29.75164|  0:00:00s\n",
            "epoch 2  | loss: 31.95845| val_0_mse: 27.82928|  0:00:00s\n",
            "epoch 3  | loss: 31.50772| val_0_mse: 26.04602|  0:00:01s\n",
            "epoch 4  | loss: 28.47763| val_0_mse: 25.54813|  0:00:01s\n",
            "epoch 5  | loss: 27.62939| val_0_mse: 25.2227 |  0:00:01s\n",
            "epoch 6  | loss: 26.07982| val_0_mse: 26.64657|  0:00:01s\n",
            "epoch 7  | loss: 27.19856| val_0_mse: 25.91579|  0:00:02s\n",
            "epoch 8  | loss: 26.22141| val_0_mse: 26.08469|  0:00:02s\n",
            "epoch 9  | loss: 26.38806| val_0_mse: 26.11087|  0:00:02s\n",
            "epoch 10 | loss: 25.09766| val_0_mse: 26.58925|  0:00:02s\n",
            "epoch 11 | loss: 25.90118| val_0_mse: 25.06038|  0:00:03s\n",
            "epoch 12 | loss: 26.12252| val_0_mse: 24.59375|  0:00:03s\n",
            "epoch 13 | loss: 26.2149 | val_0_mse: 24.02092|  0:00:03s\n",
            "epoch 14 | loss: 25.72353| val_0_mse: 25.0421 |  0:00:03s\n",
            "epoch 15 | loss: 24.34222| val_0_mse: 24.67271|  0:00:04s\n",
            "epoch 16 | loss: 24.19027| val_0_mse: 24.31518|  0:00:04s\n",
            "epoch 17 | loss: 24.83083| val_0_mse: 24.47639|  0:00:04s\n",
            "epoch 18 | loss: 24.38607| val_0_mse: 23.52714|  0:00:04s\n",
            "epoch 19 | loss: 24.26072| val_0_mse: 26.65342|  0:00:05s\n",
            "epoch 20 | loss: 25.71295| val_0_mse: 24.33164|  0:00:05s\n",
            "epoch 21 | loss: 24.3809 | val_0_mse: 24.41824|  0:00:05s\n",
            "epoch 22 | loss: 24.70568| val_0_mse: 22.77338|  0:00:05s\n",
            "epoch 23 | loss: 23.78649| val_0_mse: 23.3699 |  0:00:06s\n",
            "epoch 24 | loss: 24.30262| val_0_mse: 23.04063|  0:00:06s\n",
            "epoch 25 | loss: 22.78417| val_0_mse: 23.6119 |  0:00:06s\n",
            "epoch 26 | loss: 22.88962| val_0_mse: 24.76124|  0:00:06s\n",
            "epoch 27 | loss: 24.23458| val_0_mse: 24.42001|  0:00:07s\n",
            "epoch 28 | loss: 23.85355| val_0_mse: 24.86683|  0:00:07s\n",
            "epoch 29 | loss: 22.60834| val_0_mse: 25.67323|  0:00:07s\n",
            "epoch 30 | loss: 22.86359| val_0_mse: 25.4735 |  0:00:07s\n",
            "epoch 31 | loss: 24.30628| val_0_mse: 25.17476|  0:00:08s\n",
            "epoch 32 | loss: 24.47787| val_0_mse: 24.79689|  0:00:08s\n",
            "\n",
            "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_mse = 22.77338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 자동 계산된 가중치: {'XGBoost': 0.2575830143993143, 'TabNet': 0.24110313425659743, 'NODE': 0.24896214421363197, '1D-CNN': 0.2523517071304563}\n",
            "🔥 최종 가중치 앙상블 MAE: 3.3441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Jp0q5KYImvj",
        "outputId": "d52b21cd-617c-45ae-c4b0-1e39780584fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'XGBoost': 3.31392502784729,\n",
              " 'TabNet': 3.540438413619995,\n",
              " 'NODE': 3.4286770820617676,\n",
              " '1D-CNN': 3.3826234340667725}"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from catboost import CatBoostRegressor  # ✅ XGBoost → CatBoost 변경\n",
        "from pytorch_tabnet.tab_model import TabNetRegressor\n",
        "\n",
        "# 시드 고정\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# 데이터 준비\n",
        "target = '우울증_지수'\n",
        "features = [col for col in df.columns if col != target]\n",
        "\n",
        "X = df[features].values\n",
        "y = df[target].values.reshape(-1, 1)\n",
        "\n",
        "# 데이터 정규화\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "kf = KFold(n_splits=3, shuffle=True, random_state=seed)\n",
        "\n",
        "# 개별 모델의 예측값 및 MAE 저장 리스트\n",
        "preds_CatBoost, preds_TabNet, preds_NODE, preds_CNN, y_true_list = [], [], [], [], []\n",
        "mae_scores = {}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "for train_idx, test_idx in kf.split(X, y):\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "    y_true_list.append(y_test)\n",
        "\n",
        "    # 🔹 CatBoost 모델 학습 및 예측 (XGBoost → CatBoost 변경)\n",
        "    model_catboost = CatBoostRegressor(\n",
        "        iterations=600, learning_rate=0.042855489611658415, depth=6,\n",
        "        l2_leaf_reg=9.228806605999832, bagging_temperature=0.44508157297941464,\n",
        "        border_count=218, random_strength=0.8497266891308358,\n",
        "        verbose=0  # 학습 로그 출력 최소화\n",
        "    )\n",
        "    model_catboost.fit(X_train, y_train.ravel())\n",
        "    pred_catboost = model_catboost.predict(X_test)\n",
        "    preds_CatBoost.append(pred_catboost)\n",
        "    mae_scores[\"CatBoost\"] = mean_absolute_error(y_test, pred_catboost)\n",
        "\n",
        "    # 🔹 TabNet 모델 학습 및 예측\n",
        "    model_tabnet = TabNetRegressor(\n",
        "        n_d=48, n_a=32, n_steps=7, gamma=1.27,\n",
        "        lambda_sparse=0.00065, momentum=0.105\n",
        "    )\n",
        "    model_tabnet.fit(X_train, y_train, eval_set=[(X_test, y_test)], max_epochs=100, patience=10)\n",
        "    pred_tabnet = model_tabnet.predict(X_test).squeeze()\n",
        "    preds_TabNet.append(pred_tabnet)\n",
        "    mae_scores[\"TabNet\"] = mean_absolute_error(y_test, pred_tabnet)\n",
        "\n",
        "    # 🔹 NODE 모델 학습 및 예측\n",
        "    model_node = NODEModel(input_dim=X_train.shape[1], num_trees=512, depth=6).to(device)\n",
        "    optimizer = optim.Adam(model_node.parameters(), lr=0.01)\n",
        "    criterion = nn.MSELoss()\n",
        "    train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "    test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1).to(device)\n",
        "\n",
        "    for epoch in range(100):\n",
        "        model_node.train()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_node(train_tensor)\n",
        "        loss = criterion(outputs, y_train_tensor)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model_node.eval()\n",
        "    with torch.no_grad():\n",
        "        pred_node = model_node(test_tensor).cpu().numpy().squeeze()\n",
        "        preds_NODE.append(pred_node)\n",
        "        mae_scores[\"NODE\"] = mean_absolute_error(y_test, pred_node)\n",
        "\n",
        "    # 🔹 1D-CNN 모델 학습 및 예측\n",
        "    model_cnn = CNN1D(X_train.shape[1], 32, 3, 64).to(device)\n",
        "    optimizer_cnn = optim.Adam(model_cnn.parameters(), lr=0.001)\n",
        "    train_cnn_tensor = train_tensor.unsqueeze(1)\n",
        "    test_cnn_tensor = test_tensor.unsqueeze(1)\n",
        "\n",
        "    for epoch in range(100):\n",
        "        model_cnn.train()\n",
        "        optimizer_cnn.zero_grad()\n",
        "        outputs_cnn = model_cnn(train_cnn_tensor)\n",
        "        loss = criterion(outputs_cnn, y_train_tensor)\n",
        "        loss.backward()\n",
        "        optimizer_cnn.step()\n",
        "\n",
        "    model_cnn.eval()\n",
        "    with torch.no_grad():\n",
        "        pred_cnn = model_cnn(test_cnn_tensor).cpu().numpy().squeeze()\n",
        "        preds_CNN.append(pred_cnn)\n",
        "        mae_scores[\"1D-CNN\"] = mean_absolute_error(y_test, pred_cnn)\n",
        "\n",
        "# ✅ MAE 기반 가중치 자동 계산\n",
        "inverse_mae = {k: 1 / v for k, v in mae_scores.items()}  # MAE의 역수 (낮을수록 높은 가중치)\n",
        "total_inv_mae = sum(inverse_mae.values())  # 정규화 기준\n",
        "\n",
        "weights = {k: v / total_inv_mae for k, v in inverse_mae.items()}  # 정규화된 가중치\n",
        "print(f\"🚀 자동 계산된 가중치: {weights}\")\n",
        "\n",
        "# ✅ 최종 가중 앙상블 예측\n",
        "ensemble_preds = []\n",
        "y_true_final = np.concatenate(y_true_list)\n",
        "\n",
        "for i in range(len(preds_CatBoost)):\n",
        "    y_pred_ensemble = (\n",
        "        weights[\"CatBoost\"] * preds_CatBoost[i] +\n",
        "        weights[\"TabNet\"] * preds_TabNet[i] +\n",
        "        weights[\"NODE\"] * preds_NODE[i] +\n",
        "        weights[\"1D-CNN\"] * preds_CNN[i]\n",
        "    )\n",
        "    ensemble_preds.append(y_pred_ensemble)\n",
        "\n",
        "ensemble_preds = np.concatenate(ensemble_preds)\n",
        "final_mae = mean_absolute_error(y_true_final, ensemble_preds)\n",
        "\n",
        "print(f\"🔥 최종 가중치 앙상블 MAE: {final_mae:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaEz2LAqKFJb",
        "outputId": "6a64b6e4-dc66-4ab5-d63b-0a0b1b7ffec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 50.09723| val_0_mse: 32.63522|  0:00:00s\n",
            "epoch 1  | loss: 34.84437| val_0_mse: 34.48961|  0:00:00s\n",
            "epoch 2  | loss: 33.22643| val_0_mse: 31.89543|  0:00:00s\n",
            "epoch 3  | loss: 27.67261| val_0_mse: 31.39692|  0:00:01s\n",
            "epoch 4  | loss: 28.99846| val_0_mse: 28.63995|  0:00:01s\n",
            "epoch 5  | loss: 26.21933| val_0_mse: 27.66517|  0:00:01s\n",
            "epoch 6  | loss: 27.53365| val_0_mse: 28.69342|  0:00:01s\n",
            "epoch 7  | loss: 25.08959| val_0_mse: 28.69568|  0:00:02s\n",
            "epoch 8  | loss: 25.61911| val_0_mse: 28.7043 |  0:00:02s\n",
            "epoch 9  | loss: 23.7905 | val_0_mse: 26.91342|  0:00:02s\n",
            "epoch 10 | loss: 23.88861| val_0_mse: 27.66913|  0:00:03s\n",
            "epoch 11 | loss: 25.15065| val_0_mse: 28.55071|  0:00:03s\n",
            "epoch 12 | loss: 25.38397| val_0_mse: 27.38991|  0:00:03s\n",
            "epoch 13 | loss: 24.80045| val_0_mse: 25.778  |  0:00:03s\n",
            "epoch 14 | loss: 24.00399| val_0_mse: 26.68838|  0:00:04s\n",
            "epoch 15 | loss: 24.77407| val_0_mse: 25.82235|  0:00:04s\n",
            "epoch 16 | loss: 23.79518| val_0_mse: 26.64012|  0:00:04s\n",
            "epoch 17 | loss: 23.52296| val_0_mse: 26.3201 |  0:00:04s\n",
            "epoch 18 | loss: 23.86645| val_0_mse: 25.7707 |  0:00:05s\n",
            "epoch 19 | loss: 23.2086 | val_0_mse: 24.6771 |  0:00:05s\n",
            "epoch 20 | loss: 22.71458| val_0_mse: 24.63716|  0:00:05s\n",
            "epoch 21 | loss: 23.63722| val_0_mse: 24.48201|  0:00:05s\n",
            "epoch 22 | loss: 23.33504| val_0_mse: 24.37311|  0:00:06s\n",
            "epoch 23 | loss: 23.34988| val_0_mse: 24.60575|  0:00:06s\n",
            "epoch 24 | loss: 22.82568| val_0_mse: 24.20386|  0:00:06s\n",
            "epoch 25 | loss: 22.358  | val_0_mse: 25.40582|  0:00:06s\n",
            "epoch 26 | loss: 22.50827| val_0_mse: 25.52063|  0:00:07s\n",
            "epoch 27 | loss: 22.70261| val_0_mse: 25.1004 |  0:00:07s\n",
            "epoch 28 | loss: 23.45444| val_0_mse: 24.68447|  0:00:07s\n",
            "epoch 29 | loss: 23.80982| val_0_mse: 24.71721|  0:00:07s\n",
            "epoch 30 | loss: 23.43381| val_0_mse: 25.51661|  0:00:08s\n",
            "epoch 31 | loss: 23.55004| val_0_mse: 25.32593|  0:00:08s\n",
            "epoch 32 | loss: 24.0007 | val_0_mse: 26.03036|  0:00:08s\n",
            "epoch 33 | loss: 23.75668| val_0_mse: 25.2846 |  0:00:08s\n",
            "epoch 34 | loss: 22.44919| val_0_mse: 25.01011|  0:00:09s\n",
            "\n",
            "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_mse = 24.20386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 51.48784| val_0_mse: 29.83645|  0:00:00s\n",
            "epoch 1  | loss: 38.02229| val_0_mse: 32.87148|  0:00:00s\n",
            "epoch 2  | loss: 36.00107| val_0_mse: 29.20362|  0:00:00s\n",
            "epoch 3  | loss: 29.32714| val_0_mse: 32.6339 |  0:00:01s\n",
            "epoch 4  | loss: 32.04841| val_0_mse: 31.92286|  0:00:01s\n",
            "epoch 5  | loss: 29.85668| val_0_mse: 29.60757|  0:00:01s\n",
            "epoch 6  | loss: 26.69147| val_0_mse: 26.87645|  0:00:01s\n",
            "epoch 7  | loss: 28.95467| val_0_mse: 26.5677 |  0:00:02s\n",
            "epoch 8  | loss: 27.50335| val_0_mse: 26.03762|  0:00:02s\n",
            "epoch 9  | loss: 26.1206 | val_0_mse: 26.57207|  0:00:02s\n",
            "epoch 10 | loss: 25.09419| val_0_mse: 26.10122|  0:00:02s\n",
            "epoch 11 | loss: 25.11197| val_0_mse: 25.72283|  0:00:03s\n",
            "epoch 12 | loss: 25.76796| val_0_mse: 25.08861|  0:00:03s\n",
            "epoch 13 | loss: 24.58597| val_0_mse: 25.70245|  0:00:03s\n",
            "epoch 14 | loss: 22.96366| val_0_mse: 26.3454 |  0:00:03s\n",
            "epoch 15 | loss: 24.68211| val_0_mse: 24.86407|  0:00:04s\n",
            "epoch 16 | loss: 24.68716| val_0_mse: 25.16132|  0:00:04s\n",
            "epoch 17 | loss: 24.89486| val_0_mse: 25.38824|  0:00:04s\n",
            "epoch 18 | loss: 24.44433| val_0_mse: 25.10085|  0:00:04s\n",
            "epoch 19 | loss: 23.78413| val_0_mse: 24.96839|  0:00:05s\n",
            "epoch 20 | loss: 23.93046| val_0_mse: 25.71244|  0:00:05s\n",
            "epoch 21 | loss: 24.16052| val_0_mse: 24.70991|  0:00:05s\n",
            "epoch 22 | loss: 24.27465| val_0_mse: 24.72342|  0:00:06s\n",
            "epoch 23 | loss: 23.45992| val_0_mse: 24.48458|  0:00:06s\n",
            "epoch 24 | loss: 24.57896| val_0_mse: 25.29766|  0:00:06s\n",
            "epoch 25 | loss: 23.63893| val_0_mse: 25.55708|  0:00:06s\n",
            "epoch 26 | loss: 23.7567 | val_0_mse: 24.61357|  0:00:07s\n",
            "epoch 27 | loss: 23.86242| val_0_mse: 24.32879|  0:00:07s\n",
            "epoch 28 | loss: 23.57677| val_0_mse: 24.0896 |  0:00:07s\n",
            "epoch 29 | loss: 24.10323| val_0_mse: 24.13311|  0:00:07s\n",
            "epoch 30 | loss: 23.39603| val_0_mse: 23.99106|  0:00:08s\n",
            "epoch 31 | loss: 23.67568| val_0_mse: 23.45606|  0:00:08s\n",
            "epoch 32 | loss: 23.85058| val_0_mse: 23.78592|  0:00:08s\n",
            "epoch 33 | loss: 24.2879 | val_0_mse: 24.15617|  0:00:08s\n",
            "epoch 34 | loss: 24.74345| val_0_mse: 24.46272|  0:00:09s\n",
            "epoch 35 | loss: 24.01468| val_0_mse: 26.65691|  0:00:09s\n",
            "epoch 36 | loss: 25.43356| val_0_mse: 26.11074|  0:00:09s\n",
            "epoch 37 | loss: 24.39968| val_0_mse: 24.78397|  0:00:09s\n",
            "epoch 38 | loss: 24.92597| val_0_mse: 24.76077|  0:00:10s\n",
            "epoch 39 | loss: 23.74831| val_0_mse: 23.67163|  0:00:10s\n",
            "epoch 40 | loss: 23.0553 | val_0_mse: 24.62147|  0:00:10s\n",
            "epoch 41 | loss: 22.8941 | val_0_mse: 24.51779|  0:00:10s\n",
            "\n",
            "Early stopping occurred at epoch 41 with best_epoch = 31 and best_val_0_mse = 23.45606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 51.99469| val_0_mse: 30.56776|  0:00:00s\n",
            "epoch 1  | loss: 37.45315| val_0_mse: 29.75164|  0:00:00s\n",
            "epoch 2  | loss: 31.95845| val_0_mse: 27.82928|  0:00:00s\n",
            "epoch 3  | loss: 31.50772| val_0_mse: 26.04602|  0:00:01s\n",
            "epoch 4  | loss: 28.47763| val_0_mse: 25.54813|  0:00:01s\n",
            "epoch 5  | loss: 27.62939| val_0_mse: 25.2227 |  0:00:01s\n",
            "epoch 6  | loss: 26.07982| val_0_mse: 26.64657|  0:00:01s\n",
            "epoch 7  | loss: 27.19856| val_0_mse: 25.91579|  0:00:02s\n",
            "epoch 8  | loss: 26.22141| val_0_mse: 26.08469|  0:00:02s\n",
            "epoch 9  | loss: 26.38806| val_0_mse: 26.11087|  0:00:02s\n",
            "epoch 10 | loss: 25.09766| val_0_mse: 26.58925|  0:00:02s\n",
            "epoch 11 | loss: 25.90118| val_0_mse: 25.06038|  0:00:03s\n",
            "epoch 12 | loss: 26.12252| val_0_mse: 24.59375|  0:00:03s\n",
            "epoch 13 | loss: 26.2149 | val_0_mse: 24.02092|  0:00:03s\n",
            "epoch 14 | loss: 25.72353| val_0_mse: 25.0421 |  0:00:03s\n",
            "epoch 15 | loss: 24.34222| val_0_mse: 24.67271|  0:00:04s\n",
            "epoch 16 | loss: 24.19027| val_0_mse: 24.31518|  0:00:04s\n",
            "epoch 17 | loss: 24.83083| val_0_mse: 24.47639|  0:00:04s\n",
            "epoch 18 | loss: 24.38607| val_0_mse: 23.52714|  0:00:04s\n",
            "epoch 19 | loss: 24.26072| val_0_mse: 26.65342|  0:00:05s\n",
            "epoch 20 | loss: 25.71295| val_0_mse: 24.33164|  0:00:05s\n",
            "epoch 21 | loss: 24.3809 | val_0_mse: 24.41824|  0:00:05s\n",
            "epoch 22 | loss: 24.70568| val_0_mse: 22.77338|  0:00:05s\n",
            "epoch 23 | loss: 23.78649| val_0_mse: 23.3699 |  0:00:06s\n",
            "epoch 24 | loss: 24.30262| val_0_mse: 23.04063|  0:00:06s\n",
            "epoch 25 | loss: 22.78417| val_0_mse: 23.6119 |  0:00:06s\n",
            "epoch 26 | loss: 22.88962| val_0_mse: 24.76124|  0:00:06s\n",
            "epoch 27 | loss: 24.23458| val_0_mse: 24.42001|  0:00:07s\n",
            "epoch 28 | loss: 23.85355| val_0_mse: 24.86683|  0:00:07s\n",
            "epoch 29 | loss: 22.60834| val_0_mse: 25.67323|  0:00:07s\n",
            "epoch 30 | loss: 22.86359| val_0_mse: 25.4735 |  0:00:07s\n",
            "epoch 31 | loss: 24.30628| val_0_mse: 25.17476|  0:00:08s\n",
            "epoch 32 | loss: 24.47787| val_0_mse: 24.79689|  0:00:08s\n",
            "\n",
            "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_mse = 22.77338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 자동 계산된 가중치: {'CatBoost': 0.2815458479334993, 'TabNet': 0.25869133278501155, 'NODE': 0.23496024050487826, '1D-CNN': 0.22480257877661108}\n",
            "🔥 최종 가중치 앙상블 MAE: 3.3717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W6qFB7kK957",
        "outputId": "98d08df2-6f67-4506-e12d-4610a0c66a42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CatBoost': 3.2530429362927,\n",
              " 'TabNet': 3.540438413619995,\n",
              " 'NODE': 3.898024320602417,\n",
              " '1D-CNN': 4.074155807495117}"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GY6cqd0YSG2s"
      },
      "outputs": [],
      "source": [
        "#############################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALWzxWzUSDg5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QT_ntOfAuJOj"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 평가 후 예측값과 실제값을 시각화\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_test).numpy()  # 예측값\n",
        "    y_true = y_test.numpy()         # 실제값\n",
        "\n",
        "# 시각화\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_true, y_pred, alpha=0.6, label='예측 vs 실제값')\n",
        "plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], color='red', linestyle='--', label='Perfect Prediction')\n",
        "plt.title('예측값 vs 실제값', fontsize=16)\n",
        "plt.xlabel('real', fontsize=14)\n",
        "plt.ylabel('pred', fontsize=14)\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jccIYEHfuhAl"
      },
      "outputs": [],
      "source": [
        "# 예측값만 시각화\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(y_pred, label='예측값', color='blue')\n",
        "plt.title('예측값 시각화', fontsize=16)\n",
        "plt.xlabel('index', fontsize=14)\n",
        "plt.ylabel('pred', fontsize=14)\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMNkL8Y0uxv1"
      },
      "outputs": [],
      "source": [
        "# 예측값과 실제값 시각화\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(y_pred, label='예측값', color='blue', linestyle='--')\n",
        "plt.plot(y_true, label='실제값', color='green', alpha=0.7)\n",
        "plt.title('예측값 vs 실제값', fontsize=16)\n",
        "plt.xlabel('데이터 인덱스', fontsize=14)\n",
        "plt.ylabel('값', fontsize=14)\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZOGbMQSu6Md"
      },
      "outputs": [],
      "source": [
        "# 실제값만 시각화\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(y_true, label='실제값', color='green')\n",
        "plt.title('실제값 시각화', fontsize=16)\n",
        "plt.xlabel('데이터 인덱스', fontsize=14)\n",
        "plt.ylabel('값', fontsize=14)\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJrjiEItK3rt"
      },
      "outputs": [],
      "source": [
        "##!pip uninstall -y scikit-learn\n",
        "##!pip install scikit-learn==1.3.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzUeQ9O8Ogpp"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pandas as pd\n",
        "\n",
        "# 데이터 로드 (df는 이미 불러와져 있다고 가정)\n",
        "# df = pd.read_csv(\"your_data.csv\")\n",
        "\n",
        "# 연속형 변수 목록\n",
        "continuous_features = [\n",
        "    '연령대(6범주)', '최종학력', '장해등급(15범주)', '요양기간', '최종학교', '자격증 보유 개수',\n",
        "    '최초 의료기관 방문시점', '치료기간 적정 여부', '현재 업무수행능력', '한 달 평균 임금/소득',\n",
        "    '한 달 평균 근무일수', '하루 평균 근무시간', '직장 동료들과의 관계', '직장동료 도움지지여부',\n",
        "    '직장상사 도움지지여부', '일자리 만족도', '산재 이후 건강회복 정도', '산재 이후 통증 느끼는 횟수',\n",
        "    '산재로 인한 통증이 일상 및 삶을 방해하는 정도', '현재 전반적인 건강상태',\n",
        "    '산재 이후 일상생활에서 가족이나 타인의 도움 필요 정도', '1주 평균 운동일 수', '가구원 수'\n",
        "]\n",
        "\n",
        "# 타겟 변수 생성 및 원본 타겟 제거\n",
        "df_class = df.copy()\n",
        "df_class['우울증_범주'] = df_class['우울증_지수'].apply(lambda x: 0 if x <= 20 else 1)\n",
        "y = df_class['우울증_범주'].values  # 타겟 변수 분리\n",
        "df_class = df_class.drop(columns=['우울증_지수', '우울증_범주'])  # 타겟 변수 제거\n",
        "\n",
        "# 연속형 변수 표준화\n",
        "scaler = StandardScaler()\n",
        "X_continuous_scaled = scaler.fit_transform(df_class[continuous_features])\n",
        "\n",
        "# 원핫인코딩된 변수 생성 (타겟 변수 제외)\n",
        "X_onehot = df_class.drop(columns=continuous_features).values\n",
        "\n",
        "# 최종 입력 데이터 생성\n",
        "X_scaled = np.hstack([X_continuous_scaled, X_onehot])\n",
        "\n",
        "# 타겟 변수 설정\n",
        "\n",
        "X = torch.tensor(X_scaled, dtype=torch.float32)  # 표준화된 데이터 사용\n",
        "y = torch.tensor(y, dtype=torch.long)  # Classification 타겟은 long 타입이어야 함\n",
        "\n",
        "# SMOTE 설정\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "# Stratified K-Fold 설정\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# MLP 모델 정의\n",
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(MLPClassifier, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 2)  # 이진 분류이므로 출력 노드 2개\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# 학습 및 평가 루프\n",
        "num_epochs = 200\n",
        "batch_size = 16\n",
        "learning_rate = 0.01\n",
        "\n",
        "fold_accuracies = []\n",
        "fold_f1_scores = []\n",
        "fold_precisions = []\n",
        "fold_recalls = []\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(skf.split(X.numpy(), y.numpy()), 1):\n",
        "    print(f\"\\nFold {fold}\")\n",
        "\n",
        "    # Train-Test 분할\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    # SMOTE로 학습 데이터 증강\n",
        "    X_train_np, y_train_np = X_train.numpy(), y_train.numpy()\n",
        "    X_train_smote, y_train_smote = smote.fit_resample(X_train_np, y_train_np)\n",
        "    X_train_smote = torch.tensor(X_train_smote, dtype=torch.float32)\n",
        "    y_train_smote = torch.tensor(y_train_smote, dtype=torch.long)\n",
        "\n",
        "    # 클래스 비율 확인\n",
        "    print(f\"After SMOTE: Class 0 = {np.sum(y_train_smote.numpy() == 0)}, Class 1 = {np.sum(y_train_smote.numpy() == 1)}\")\n",
        "\n",
        "    # 모델 초기화\n",
        "    input_dim = X_train_smote.shape[1]\n",
        "    model = MLPClassifier(input_dim)\n",
        "\n",
        "    # 손실 함수 및 옵티마이저\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # DataLoader 생성\n",
        "    train_dataset = torch.utils.data.TensorDataset(X_train_smote, y_train_smote)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # 학습 루프\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # 평가\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        y_pred = model(X_test)\n",
        "        y_pred_labels = torch.argmax(y_pred, axis=1)\n",
        "\n",
        "        accuracy = accuracy_score(y_test.numpy(), y_pred_labels.numpy())\n",
        "        f1 = f1_score(y_test.numpy(), y_pred_labels.numpy())\n",
        "        precision = precision_score(y_test.numpy(), y_pred_labels.numpy())\n",
        "        recall = recall_score(y_test.numpy(), y_pred_labels.numpy())\n",
        "\n",
        "        fold_accuracies.append(accuracy)\n",
        "        fold_f1_scores.append(f1)\n",
        "        fold_precisions.append(precision)\n",
        "        fold_recalls.append(recall)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
        "\n",
        "# 평균 결과 출력\n",
        "print(\"\\nOverall Results:\")\n",
        "print(f\"Average Accuracy: {np.mean(fold_accuracies):.4f}\")\n",
        "print(f\"Average F1-Score: {np.mean(fold_f1_scores):.4f}\")\n",
        "print(f\"Average Precision: {np.mean(fold_precisions):.4f}\")\n",
        "print(f\"Average Recall: {np.mean(fold_recalls):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqh3eHVaRE0K"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "# 데이터 로드 (df는 이미 불러와져 있다고 가정)\n",
        "# df = pd.read_csv(\"your_data.csv\")\n",
        "\n",
        "# 연속형 변수 목록\n",
        "continuous_features = [\n",
        "    '연령대(6범주)', '최종학력', '장해등급(15범주)', '요양기간', '최종학교', '자격증 보유 개수',\n",
        "    '최초 의료기관 방문시점', '치료기간 적정 여부', '현재 업무수행능력', '한 달 평균 임금/소득',\n",
        "    '한 달 평균 근무일수', '하루 평균 근무시간', '직장 동료들과의 관계', '직장동료 도움지지여부',\n",
        "    '직장상사 도움지지여부', '일자리 만족도', '산재 이후 건강회복 정도', '산재 이후 통증 느끼는 횟수',\n",
        "    '산재로 인한 통증이 일상 및 삶을 방해하는 정도', '현재 전반적인 건강상태',\n",
        "    '산재 이후 일상생활에서 가족이나 타인의 도움 필요 정도', '1주 평균 운동일 수', '가구원 수'\n",
        "]\n",
        "\n",
        "# 타겟 변수 생성 및 원본 타겟 제거\n",
        "df_class = df.copy()\n",
        "df_class['우울증_범주'] = df_class['우울증_지수'].apply(lambda x: 0 if x <= 10 else 1)\n",
        "y = df_class['우울증_범주'].values  # 타겟 변수 분리\n",
        "df_class = df_class.drop(columns=['우울증_지수', '우울증_범주'])  # 타겟 변수 제거\n",
        "\n",
        "# 연속형 변수 표준화\n",
        "scaler = StandardScaler()\n",
        "X_continuous_scaled = scaler.fit_transform(df_class[continuous_features])\n",
        "\n",
        "# 원핫인코딩된 변수 생성 (타겟 변수 제외)\n",
        "X_onehot = df_class.drop(columns=continuous_features).values\n",
        "\n",
        "# 최종 입력 데이터 생성\n",
        "X_scaled = np.hstack([X_continuous_scaled, X_onehot])\n",
        "\n",
        "# PyTorch 텐서 변환\n",
        "X = torch.tensor(X_scaled, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "# Stratified K-Fold 설정\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# MLP 모델 정의\n",
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(MLPClassifier, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 2)  # 이진 분류이므로 출력 노드 2개\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# 학습 및 평가 루프\n",
        "num_epochs = 100\n",
        "batch_size = 16\n",
        "learning_rate = 0.005\n",
        "\n",
        "fold_accuracies = []\n",
        "fold_f1_scores = []\n",
        "fold_precisions = []\n",
        "fold_recalls = []\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(skf.split(X.numpy(), y.numpy()), 1):\n",
        "    print(f\"\\nFold {fold}\")\n",
        "\n",
        "    # Train-Test 분할\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    # 클래스 가중치 계산 (SMOTE를 사용하지 않음)\n",
        "    class_counts = Counter(y_train.numpy())  # 클래스별 개수\n",
        "    total_samples = sum(class_counts.values())\n",
        "    class_weights = {cls: total_samples / (len(class_counts) * count) for cls, count in class_counts.items()}\n",
        "\n",
        "    # PyTorch Tensor로 변환\n",
        "    class_weights_tensor = torch.tensor([class_weights[0], class_weights[1]], dtype=torch.float32)\n",
        "\n",
        "    # 모델 초기화\n",
        "    input_dim = X_train.shape[1]\n",
        "    model = MLPClassifier(input_dim)\n",
        "\n",
        "    # 손실 함수 및 옵티마이저\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)  # 가중치 적용\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # DataLoader 생성\n",
        "    train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # 학습 루프\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # 평가\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        y_pred = model(X_test)\n",
        "        y_pred_labels = torch.argmax(y_pred, axis=1)\n",
        "\n",
        "        accuracy = accuracy_score(y_test.numpy(), y_pred_labels.numpy())\n",
        "        f1 = f1_score(y_test.numpy(), y_pred_labels.numpy())\n",
        "        precision = precision_score(y_test.numpy(), y_pred_labels.numpy())\n",
        "        recall = recall_score(y_test.numpy(), y_pred_labels.numpy())\n",
        "\n",
        "        fold_accuracies.append(accuracy)\n",
        "        fold_f1_scores.append(f1)\n",
        "        fold_precisions.append(precision)\n",
        "        fold_recalls.append(recall)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
        "\n",
        "# 평균 결과 출력\n",
        "print(\"\\nOverall Results:\")\n",
        "print(f\"Average Accuracy: {np.mean(fold_accuracies):.4f}\")\n",
        "print(f\"Average F1-Score: {np.mean(fold_f1_scores):.4f}\")\n",
        "print(f\"Average Precision: {np.mean(fold_precisions):.4f}\")\n",
        "print(f\"Average Recall: {np.mean(fold_recalls):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXGoyFYwZH57"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}